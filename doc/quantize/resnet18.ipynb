{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TVM 自动量化过程剖析\n",
    "\n",
    "以 PyTorch 的 resnet18 模型为例剖析 TVM 自动量化过程。\n",
    "\n",
    "## PyTorch 模型翻译为 relay 模型\n",
    "\n",
    "加载 PyTorch 模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(input_shape):\n",
    "    from torchvision.models import resnet18, ResNet18_Weights\n",
    "    import torch\n",
    "    model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "    data = torch.randn(*input_shape)\n",
    "    model = torch.jit.trace(model.eval(), data)\n",
    "    return model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 模型翻译为 relay 模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "\n",
    "input_shape = 1, 3, 224, 224\n",
    "input_name = \"data\"\n",
    "traced_model = load_model(input_shape)\n",
    "mod, params = relay.frontend.from_pytorch(\n",
    "    traced_model, \n",
    "    [(input_name, input_shape)], \n",
    "    # use_parser_friendly_name=True\n",
    ")\n",
    "with tvm.transform.PassContext(opt_level=3): # 预处理\n",
    "    opt_mod = relay.quantize.prerequisite_optimize(mod, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{rubric} 加载数据\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm.testing\n",
    "from tvm import relay\n",
    "from tvm.relay import transform, build_module\n",
    "from tvm.relay.testing import run_opt_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from tvm_book.data.classification import ImageFolderDataset\n",
    "\n",
    "def preprocess_image(\n",
    "        image: np.ndarray,\n",
    "        size: tuple[int] = (224, 224),\n",
    "        mean: tuple[float] = (0.485, 0.456, 0.406),\n",
    "        std: tuple[float] = (0.229, 0.224, 0.225)\n",
    "    ):\n",
    "    im = Image.fromarray(image)\n",
    "    im = im.resize((256, 256), Image.Resampling.BILINEAR)\n",
    "    ori_H, ori_W = im.size\n",
    "    H, W = size\n",
    "    space_W, space_H = (ori_W - W)//2, (ori_H - H)//2\n",
    "    im = im.crop((space_W, space_H, ori_W-space_W, ori_H-space_H))\n",
    "    image = np.array(im, dtype=\"float32\")\n",
    "    im.close()\n",
    "    image = image/256\n",
    "    image -= mean\n",
    "    image /= std\n",
    "    return image.astype(np.float32)\n",
    "\n",
    "@dataclass\n",
    "class ImageNet:\n",
    "    root: str\n",
    "    size: tuple[int] = (224, 224)\n",
    "    mean: tuple[float] = (0.485, 0.456, 0.406)\n",
    "    std: tuple[float] = (0.229, 0.224, 0.225)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.root = Path(self.root) # 数据根目录\n",
    "        self.valset = ImageFolderDataset(f\"{self.root}/val\")\n",
    "        self.trainset = ImageFolderDataset(f\"{self.root}/train\")\n",
    "\n",
    "    def calibrateset(self, calibrate_num: int = 200):\n",
    "        \"\"\"用于 TVM 量化的校准数据集\n",
    "        \"\"\"\n",
    "        for k, (data, label) in tqdm(enumerate(self.trainset)):\n",
    "            if k >= calibrate_num:\n",
    "                break\n",
    "            image = preprocess_image(data, self.size, self.mean, self.std)\n",
    "            images = np.expand_dims(image, 0)\n",
    "            images = images.transpose((0, 3, 1, 2))\n",
    "            yield {\"data\": images}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageNet(\"/media/pc/data/lxw/home/data/datasets/ILSVRC/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resnet18 算子融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.relay import Call\n",
    "from tvm.relay.function import Function, FunctionWithFields\n",
    "from tvm.relay.quantize._partition import QPartitionExpr\n",
    "\n",
    "@tvm.relay.transform.function_pass(opt_level=1)\n",
    "class QPartitionTransform:\n",
    "    \"\"\"为融合的函数添加 QPartitionExpr\n",
    "    \"\"\"\n",
    "    def transform_function(self, func, mod, ctx):\n",
    "        class Replace(tvm.relay.ExprMutator):\n",
    "            def visit_function(self, fn):\n",
    "                new_params = [self.visit(x) for x in fn.params]\n",
    "                new_body = self.visit(fn.body)\n",
    "                if not isinstance(new_body.op, Function): # 防止循环添加 QPartitionExpr\n",
    "                    new_body = QPartitionExpr(new_body).realize()\n",
    "                if new_params == list(fn.params) and new_body == fn.body:\n",
    "                    new_fn =  fn\n",
    "                else:\n",
    "                    new_fn = FunctionWithFields(fn, list(new_params), new_body)\n",
    "                return new_fn\n",
    "        return Replace().visit(func)\n",
    "    \n",
    "@tvm.relay.transform.function_pass(opt_level=1)\n",
    "class SplitGraphTransform:\n",
    "    \"\"\"保存子图到不同是子函数\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self._func_index = 0\n",
    "\n",
    "    def transform_function(self, func, mod, ctx):\n",
    "        obj = self\n",
    "        class Replace(tvm.relay.ExprMutator):\n",
    "            def visit_call(self, call):\n",
    "                new_fn = self.visit(call.op)\n",
    "                new_args = [self.visit(arg) for arg in call.args]\n",
    "                if isinstance(new_fn, Function):\n",
    "                    func_name = f\"f_{obj._func_index:04d}\"\n",
    "                    new_fn = run_opt_pass(new_fn, relay.transform.FoldConstant())\n",
    "                    # print(new_fn)\n",
    "                    mod[func_name] = new_fn\n",
    "                    new_fn = mod.get_global_var(func_name)\n",
    "                    obj._func_index += 1\n",
    "                if new_fn == call.op and new_args == list(call.args):\n",
    "                    new_call = call\n",
    "                else:\n",
    "                    new_call = Call(new_fn, new_args, call.attrs, call.type_args, call.span)\n",
    "                return new_call\n",
    "        return Replace().visit(func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm_book.tvm_utils.relay_pattern import *\n",
    "# 配置融合规则\n",
    "compiler_name = \"ccompiler\"\n",
    "pattern_table = [\n",
    "    (f\"{compiler_name}.conv_add_relu_max_pool2d\", make_conv_add_relu_max_pool2d_pattern()),\n",
    "    (f\"{compiler_name}.conv2d_transpose_add_activate\", make_conv2d_transpose_add_activate_pattern()),\n",
    "    (f\"{compiler_name}.conv_add_activate\", make_conv_add_activate_pattern()),\n",
    "    (f\"{compiler_name}.max_pool2d\", make_max_pool2d_pattern()),\n",
    "    (f\"{compiler_name}.dense_add\", make_dense_add_pattern()),\n",
    "    (f\"{compiler_name}.adaptive_avg_pool2d\", make_adaptive_avg_pool2d_pattern()),\n",
    "    (f\"{compiler_name}.avg_pool2dd\", make_avg_pool2d_pattern()),\n",
    "    (f\"{compiler_name}.add_multiply_add\", make_add_multiply_add_pattern()),\n",
    "    (f\"{compiler_name}.add\", make_add_pattern()),\n",
    "    (f\"{compiler_name}.multiply\", make_multiply_pattern()),\n",
    "    # (f\"{compiler_name}.strided_slice\", make_strided_slice_pattern()),\n",
    "]\n",
    "merge_passes = tvm.transform.Sequential([\n",
    "    relay.transform.InferType(),\n",
    "    relay.transform.MergeComposite(pattern_table),\n",
    "    QPartitionTransform(), # 为融合函数添加 `QPartitionExpr` 算子\n",
    "    # relay.transform.DefuseOps(),\n",
    "    # relay.transform.MergeComposite(pattern_table),\n",
    "    SplitGraphTransform(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    run_mod = merge_passes(opt_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn (%FunctionVar_19_0: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %FunctionVar_19_1: Tensor[(64, 3, 7, 7), float32] /* ty=Tensor[(64, 3, 7, 7), float32] */, %FunctionVar_19_2: Tensor[(64, 1, 1), float32] /* ty=Tensor[(64, 1, 1), float32] */, PartitionedFromPattern=\"nn.conv2d_add_nn.relu_\", Composite=\"ccompiler.conv_add_activate\") -> Tensor[(1, 64, 112, 112), float32] {\n",
      "  %0 = nn.conv2d(%FunctionVar_19_0, %FunctionVar_19_1, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %1 = add(%0, %FunctionVar_19_2) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %2 = nn.relu(%1) /* ty=Tensor[(1, 64, 112, 112), float32] span=aten::relu__0:0:0 */;\n",
      "  %3 = annotation.cast_hint(%2, dtype=\"int8\") /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  annotation.stop_fusion(%3) /* ty=Tensor[(1, 64, 112, 112), float32] */\n",
      "} /* ty=fn (Tensor[(1, 3, 224, 224), float32], Tensor[(64, 3, 7, 7), float32], Tensor[(64, 1, 1), float32]) -> Tensor[(1, 64, 112, 112), float32] */\n"
     ]
    }
   ],
   "source": [
    "print(run_mod[\"f_0000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn (%data: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] span=aten::_convolution_0.data:0:0 */) -> Tensor[(1, 1000), float32] {\n",
      "  %0 = @f_0000(%data, meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), float32] */, meta[relay.Constant][1] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %1 = @f_0001(%0) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %2 = @f_0002(%1, meta[relay.Constant][2] /* ty=Tensor[(64, 64, 3, 3), float32] */, meta[relay.Constant][3] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %3 = @f_0003(%2, meta[relay.Constant][4] /* ty=Tensor[(64, 64, 3, 3), float32] */, meta[relay.Constant][5] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %4 = @f_0004(%3, %1) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %5 = @f_0005(%4, meta[relay.Constant][6] /* ty=Tensor[(64, 64, 3, 3), float32] */, meta[relay.Constant][7] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %6 = @f_0006(%5, meta[relay.Constant][8] /* ty=Tensor[(64, 64, 3, 3), float32] */, meta[relay.Constant][9] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %7 = @f_0007(%6, %4) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %8 = @f_0008(%7, meta[relay.Constant][10] /* ty=Tensor[(128, 64, 3, 3), float32] */, meta[relay.Constant][11] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %9 = @f_0009(%8, meta[relay.Constant][12] /* ty=Tensor[(128, 128, 3, 3), float32] */, meta[relay.Constant][13] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %10 = @f_0010(%7, meta[relay.Constant][14] /* ty=Tensor[(128, 64, 1, 1), float32] */, meta[relay.Constant][15] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %11 = @f_0011(%9, %10) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %12 = @f_0012(%11, meta[relay.Constant][16] /* ty=Tensor[(128, 128, 3, 3), float32] */, meta[relay.Constant][17] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %13 = @f_0013(%12, meta[relay.Constant][18] /* ty=Tensor[(128, 128, 3, 3), float32] */, meta[relay.Constant][19] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %14 = @f_0014(%13, %11) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %15 = @f_0015(%14, meta[relay.Constant][20] /* ty=Tensor[(256, 128, 3, 3), float32] */, meta[relay.Constant][21] /* ty=Tensor[(256, 1, 1), float32] */) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %16 = @f_0016(%15, meta[relay.Constant][22] /* ty=Tensor[(256, 256, 3, 3), float32] */, meta[relay.Constant][23] /* ty=Tensor[(256, 1, 1), float32] */) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %17 = @f_0017(%14, meta[relay.Constant][24] /* ty=Tensor[(256, 128, 1, 1), float32] */, meta[relay.Constant][25] /* ty=Tensor[(256, 1, 1), float32] */) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %18 = @f_0018(%16, %17) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %19 = @f_0019(%18, meta[relay.Constant][26] /* ty=Tensor[(256, 256, 3, 3), float32] */, meta[relay.Constant][27] /* ty=Tensor[(256, 1, 1), float32] */) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %20 = @f_0020(%19, meta[relay.Constant][28] /* ty=Tensor[(256, 256, 3, 3), float32] */, meta[relay.Constant][29] /* ty=Tensor[(256, 1, 1), float32] */) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %21 = @f_0021(%20, %18) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %22 = @f_0022(%21, meta[relay.Constant][30] /* ty=Tensor[(512, 256, 3, 3), float32] */, meta[relay.Constant][31] /* ty=Tensor[(512, 1, 1), float32] */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %23 = @f_0023(%22, meta[relay.Constant][32] /* ty=Tensor[(512, 512, 3, 3), float32] */, meta[relay.Constant][33] /* ty=Tensor[(512, 1, 1), float32] */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %24 = @f_0024(%21, meta[relay.Constant][34] /* ty=Tensor[(512, 256, 1, 1), float32] */, meta[relay.Constant][35] /* ty=Tensor[(512, 1, 1), float32] */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %25 = @f_0025(%23, %24) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %26 = @f_0026(%25, meta[relay.Constant][36] /* ty=Tensor[(512, 512, 3, 3), float32] */, meta[relay.Constant][37] /* ty=Tensor[(512, 1, 1), float32] */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %27 = @f_0027(%26, meta[relay.Constant][38] /* ty=Tensor[(512, 512, 3, 3), float32] */, meta[relay.Constant][39] /* ty=Tensor[(512, 1, 1), float32] */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %28 = @f_0028(%27, %25) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %29 = @f_0029(%28) /* ty=Tensor[(1, 512, 1, 1), float32] */;\n",
      "  %30 = reshape(%29, newshape=[0, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] span=aten::flatten_0:0:0 */;\n",
      "  %31 = squeeze(%30, axis=[2, 3]) /* ty=Tensor[(1, 512), float32] span=aten::flatten_0:0:0 */;\n",
      "  @f_0030(%31, meta[relay.Constant][40] /* ty=Tensor[(1000, 512), float32] */, meta[relay.Constant][41] /* ty=Tensor[(1000), float32] */) /* ty=Tensor[(1, 1000), float32] */\n",
      "} /* ty=fn (Tensor[(1, 3, 224, 224), float32]) -> Tensor[(1, 1000), float32] */\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(run_mod[\"main\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注解 resnet18 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    run_mod = merge_passes(opt_mod)\n",
    "\n",
    "    # run_mod = relay.quantize.annotate()(run_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run_mod[\"f_0000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tvm.ir import IRModule, structural_equal\n",
    "import tvm\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    with relay.quantize.qconfig(\n",
    "        skip_conv_layers=[],\n",
    "        calibrate_mode=\"kl_divergence\", \n",
    "        weight_scale=\"max\",\n",
    "        round_for_shift=True,\n",
    "        # rounding=\"TONEAREST\", # \"UPWARD\" or \"TONEAREST\"\n",
    "        calibrate_skip_layers=[],\n",
    "        skip_dense_layer=False,\n",
    "    ):\n",
    "        qmod = relay.quantize.quantize(mod, params, dataset.calibrateset(calibrate_num=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{rubric} 度量 resnet18 结果\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from tvm.runtime.vm import VirtualMachine\n",
    "from tvm_book.metric.classification import Accuracy, TopKAccuracy\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    vm_exec = relay.vm.compile(run_mod, target=\"llvm\", params=params)\n",
    "vm = VirtualMachine(vm_exec, tvm.cpu())\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    qvm_exec = relay.vm.compile(qmod, target=\"llvm\", params=params)\n",
    "qvm = VirtualMachine(qvm_exec, tvm.cpu())\n",
    "\n",
    "metric_top1 = Accuracy(\"浮点\")\n",
    "metric_top5 = TopKAccuracy(top_k=5)\n",
    "qmetric_top1 = Accuracy(\"量化\")\n",
    "qmetric_top5 = TopKAccuracy(top_k=5)\n",
    "for k, (data, label) in tqdm(enumerate(dataset.valset)):\n",
    "    image = preprocess_image(data, dataset.size, dataset.mean, dataset.std)\n",
    "    images = np.expand_dims(image, 0)\n",
    "    images = images.transpose((0, 3, 1, 2))\n",
    "    input_dict = {\"data\": images}\n",
    "    output = vm.run(**input_dict).asnumpy()\n",
    "    quant_output = qvm.run(**input_dict).asnumpy()\n",
    "    label = np.array([label])\n",
    "    # 精度度量\n",
    "    metric_top1.update(preds = output, labels = label)\n",
    "    metric_top5.update(preds = output, labels = label)\n",
    "    qmetric_top1.update(preds = quant_output, labels = label)\n",
    "    qmetric_top5.update(preds = quant_output, labels = label)\n",
    "    if k % 1000 == 0:\n",
    "        print(f\"浮点: {metric_top1.get(), metric_top5.get()}||量化: {qmetric_top1.get(), qmetric_top5.get()}\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
