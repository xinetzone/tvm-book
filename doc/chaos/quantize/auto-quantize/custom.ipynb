{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义 TVM 自动量化\n",
    "\n",
    "[](partition) 量化分区（或融合）逻辑很脆弱，可能会引入一些不可预知的问题，为了提供更加健壮的分区逻辑，下面采用模板匹配的策略进行量化分区。\n",
    "\n",
    "```{admonition} 显式定义融合规则的好处\n",
    "1. 更加精细控制融合算子的规则\n",
    "2. 更好的适配诸如 VTA 等后端。\n",
    "```\n",
    "\n",
    "以 resnet18 模型为例说明如何自定义量化过程。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tvm import relay\n",
    "import tvm\n",
    "from tvm_book.tvm_utils.llvm_utils import run_llvm_graph\n",
    "\n",
    "def load_model(input_shape=[1, 3, 224, 224]):\n",
    "    \"\"\"加载前端模型\"\"\"\n",
    "    import torch\n",
    "    from torchvision.models import resnet18\n",
    "    from torchvision.models.resnet import ResNet18_Weights\n",
    "    model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "    data = torch.randn(*input_shape)\n",
    "    return torch.jit.trace(model.eval(), data)\n",
    "\n",
    "size = 224, 224\n",
    "input_shape = (1, 3, *size)\n",
    "input_name = \"data\"\n",
    "traced_model = load_model(input_shape).eval()\n",
    "# 将前端模型翻译为 relay 模型\n",
    "origin_mod, origin_params = relay.frontend.from_pytorch(traced_model, [(input_name, input_shape)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "先以 `mod` 子图为例研究定义量化过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm_book.tvm_utils.split_graph import graph_split\n",
    "\n",
    "split_conf = [{\"op_name\": \"add\", \"op_index\": 0}]\n",
    "mod = graph_split(origin_mod[\"main\"], split_conf)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中 `split_conf = [{\"op_name\": \"add\", \"op_index\": 0}]` 取出第一个残差结构所在子图。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此时的 `mod` 存在 `nn.batch_norm` 算子以及常量表达式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn (%data: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] span=aten::_convolution_0.data:0:0 */, %aten::_convolution_0.weight: Tensor[(64, 3, 7, 7), float32] /* ty=Tensor[(64, 3, 7, 7), float32] span=aten::_convolution_0.weight:0:0 */, %aten::batch_norm_0.weight: Tensor[(64), float32] /* ty=Tensor[(64), float32] span=aten::batch_norm_0.weight:0:0 */, %aten::batch_norm_0.bias: Tensor[(64), float32] /* ty=Tensor[(64), float32] span=aten::batch_norm_0.bias:0:0 */, %aten::batch_norm_0.running_mean: Tensor[(64), float32] /* ty=Tensor[(64), float32] span=aten::batch_norm_0.running_mean:0:0 */, %aten::batch_norm_0.running_var: Tensor[(64), float32] /* ty=Tensor[(64), float32] span=aten::batch_norm_0.running_var:0:0 */, %aten::_convolution_1.weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] span=aten::_convolution_1.weight:0:0 */, %aten::batch_norm_1.weight: Tensor[(64), float32] /* ty=Tensor[(64), float32] span=aten::batch_norm_1.weight:0:0 */, %aten::batch_norm_1.bias: Tensor[(64), float32] /* ty=Tensor[(64), float32] span=aten::batch_norm_1.bias:0:0 */, %aten::batch_norm_1.running_mean: Tensor[(64), float32] /* ty=Tensor[(64), float32] span=aten::batch_norm_1.running_mean:0:0 */, %aten::batch_norm_1.running_var: Tensor[(64), float32] /* ty=Tensor[(64), float32] span=aten::batch_norm_1.running_var:0:0 */, %aten::_convolution_2.weight: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] span=aten::_convolution_2.weight:0:0 */, %aten::batch_norm_2.weight: Tensor[(64), float32] /* ty=Tensor[(64), float32] span=aten::batch_norm_2.weight:0:0 */, %aten::batch_norm_2.bias: Tensor[(64), float32] /* ty=Tensor[(64), float32] span=aten::batch_norm_2.bias:0:0 */, %aten::batch_norm_2.running_mean: Tensor[(64), float32] /* ty=Tensor[(64), float32] span=aten::batch_norm_2.running_mean:0:0 */, %aten::batch_norm_2.running_var: Tensor[(64), float32] /* ty=Tensor[(64), float32] span=aten::batch_norm_2.running_var:0:0 */) {\n",
      "  %0 = nn.conv2d(%data, %aten::_convolution_0.weight, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %1 = nn.batch_norm(%0, %aten::batch_norm_0.weight, %aten::batch_norm_0.bias, %aten::batch_norm_0.running_mean, %aten::batch_norm_0.running_var) /* ty=(Tensor[(1, 64, 112, 112), float32], Tensor[(64), float32], Tensor[(64), float32]) */;\n",
      "  %2 = %1.0 /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %3 = nn.relu(%2) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %4 = nn.max_pool2d(%3, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %5 = nn.conv2d(%4, %aten::_convolution_1.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %6 = nn.batch_norm(%5, %aten::batch_norm_1.weight, %aten::batch_norm_1.bias, %aten::batch_norm_1.running_mean, %aten::batch_norm_1.running_var) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64), float32], Tensor[(64), float32]) */;\n",
      "  %7 = %6.0 /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %8 = nn.relu(%7) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %9 = nn.conv2d(%8, %aten::_convolution_2.weight, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %10 = nn.batch_norm(%9, %aten::batch_norm_2.weight, %aten::batch_norm_2.bias, %aten::batch_norm_2.running_mean, %aten::batch_norm_2.running_var) /* ty=(Tensor[(1, 64, 56, 56), float32], Tensor[(64), float32], Tensor[(64), float32]) */;\n",
      "  %11 = %10.0 /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  add(%11, %4) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(mod[\"main\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行如下代码便可将 `nn.batch_norm` 进行融合，同时将其模型参数替换掉常量表达式(还有一些其他操作，此时不展开了)："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    with relay.quantize.qconfig(\n",
    "        calibrate_mode=\"kl_divergence\",\n",
    "        weight_scale=\"max\",\n",
    "        skip_conv_layers=[],\n",
    "        skip_dense_layer=False\n",
    "    ):\n",
    "        # 量化前准备\n",
    "        run_mod = relay.quantize.prerequisite_optimize(mod, origin_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn (%data: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] span=aten::_convolution_0.data:0:0 */) -> Tensor[(1, 64, 56, 56), float32] {\n",
      "  %0 = nn.conv2d(%data, meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), float32] */, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %1 = add(%0, meta[relay.Constant][1] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %2 = nn.relu(%1) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %3 = nn.max_pool2d(%2, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %4 = nn.conv2d(%3, meta[relay.Constant][2] /* ty=Tensor[(64, 64, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %5 = add(%4, meta[relay.Constant][3] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %6 = nn.relu(%5) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %7 = nn.conv2d(%6, meta[relay.Constant][4] /* ty=Tensor[(64, 64, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %8 = add(%7, meta[relay.Constant][5] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  add(%8, %3) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "} /* ty=fn (Tensor[(1, 3, 224, 224), float32]) -> Tensor[(1, 64, 56, 56), float32] */\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(run_mod[\"main\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义融合规则"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "想要融合 `conv2d+add+relu` 结构，可以定义融合函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.relay.dataflow_pattern import is_op, wildcard\n",
    "\n",
    "def make_conv_add_relu_pattern():\n",
    "    \"\"\"创建如下模式\n",
    "\n",
    "     conv2d\n",
    "        |\n",
    "      (add)\n",
    "        |\n",
    "      (relu)\n",
    "    \"\"\"\n",
    "    x = wildcard()\n",
    "    w = wildcard()\n",
    "    bias = wildcard()\n",
    "    r = is_op(\"nn.conv2d\")(x, w)\n",
    "    r = is_op(\"add\")(r, bias) | r\n",
    "    # 激活函数\n",
    "    r = r.optional(lambda x: is_op(\"nn.relu\")(x))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上述结构模式可以用来匹配 `conv2d`、`conv2d+add`、`conv2d+add+relu`、`conv2d+relu` 四种模式。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "执行融合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%data: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] span=aten::_convolution_0.data:0:0 */) -> Tensor[(1, 64, 56, 56), float32] {\n",
      "  %5 = fn (%FunctionVar_2_0: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %FunctionVar_2_1: Tensor[(64, 3, 7, 7), float32] /* ty=Tensor[(64, 3, 7, 7), float32] */, %FunctionVar_2_2: Tensor[(64, 1, 1), float32] /* ty=Tensor[(64, 1, 1), float32] */, PartitionedFromPattern=\"nn.conv2d_add_nn.relu_\", Composite=\"ccompiler.conv_add_relu\") -> Tensor[(1, 64, 112, 112), float32] {\n",
      "    %3 = nn.conv2d(%FunctionVar_2_0, %FunctionVar_2_1, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "    %4 = add(%3, %FunctionVar_2_2) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "    nn.relu(%4) /* ty=Tensor[(1, 64, 112, 112), float32] */\n",
      "  } /* ty=fn (Tensor[(1, 3, 224, 224), float32], Tensor[(64, 3, 7, 7), float32], Tensor[(64, 1, 1), float32]) -> Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %6 = %5(%data, meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), float32] */, meta[relay.Constant][1] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %7 = nn.max_pool2d(%6, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %8 = fn (%FunctionVar_1_0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %FunctionVar_1_1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(64, 1, 1), float32] /* ty=Tensor[(64, 1, 1), float32] */, PartitionedFromPattern=\"nn.conv2d_add_nn.relu_\", Composite=\"ccompiler.conv_add_relu\") -> Tensor[(1, 64, 56, 56), float32] {\n",
      "    %1 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "    %2 = add(%1, %FunctionVar_1_2) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "    nn.relu(%2) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(64, 1, 1), float32]) -> Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %9 = %8(%7, meta[relay.Constant][2] /* ty=Tensor[(64, 64, 3, 3), float32] */, meta[relay.Constant][3] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %10 = fn (%FunctionVar_0_0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %FunctionVar_0_1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(64, 1, 1), float32] /* ty=Tensor[(64, 1, 1), float32] */, PartitionedFromPattern=\"nn.conv2d_add_\", Composite=\"ccompiler.conv_add_relu\") -> Tensor[(1, 64, 56, 56), float32] {\n",
      "    %0 = nn.conv2d(%FunctionVar_0_0, %FunctionVar_0_1, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "    add(%0, %FunctionVar_0_2) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(64, 1, 1), float32]) -> Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %11 = %10(%9, meta[relay.Constant][4] /* ty=Tensor[(64, 64, 3, 3), float32] */, meta[relay.Constant][5] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  add(%11, %7) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "compiler_name = \"ccompiler\"\n",
    "pattern_table = [\n",
    "    (f\"{compiler_name}.conv_add_relu\", make_conv_add_relu_pattern()),\n",
    "]\n",
    "merge_passes = tvm.transform.Sequential([\n",
    "    relay.transform.InferType(),\n",
    "    relay.transform.MergeComposite(pattern_table),\n",
    "    # # relay.transform.AnnotateTarget([compiler_name]),\n",
    "    relay.transform.PartitionGraph(),\n",
    "])\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    with relay.quantize.qconfig(\n",
    "        calibrate_mode=\"kl_divergence\",\n",
    "        weight_scale=\"max\",\n",
    "        skip_conv_layers=[],\n",
    "        skip_dense_layer=False\n",
    "    ):\n",
    "        run_mod_f = merge_passes(run_mod)\n",
    "print(run_mod_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出，上述剩余 `nn.max_pool2d` 和残差 `add` 没有被融合，故此可以添加规则："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%data: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] span=aten::_convolution_0.data:0:0 */) -> Tensor[(1, 64, 56, 56), float32] {\n",
      "  %5 = fn (%FunctionVar_2_0: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %FunctionVar_2_1: Tensor[(64, 3, 7, 7), float32] /* ty=Tensor[(64, 3, 7, 7), float32] */, %FunctionVar_2_2: Tensor[(64, 1, 1), float32] /* ty=Tensor[(64, 1, 1), float32] */, PartitionedFromPattern=\"nn.conv2d_add_nn.relu_\", Composite=\"ccompiler.conv_add_relu\") -> Tensor[(1, 64, 112, 112), float32] {\n",
      "    %3 = nn.conv2d(%FunctionVar_2_0, %FunctionVar_2_1, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "    %4 = add(%3, %FunctionVar_2_2) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "    nn.relu(%4) /* ty=Tensor[(1, 64, 112, 112), float32] */\n",
      "  } /* ty=fn (Tensor[(1, 3, 224, 224), float32], Tensor[(64, 3, 7, 7), float32], Tensor[(64, 1, 1), float32]) -> Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %6 = %5(%data, meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), float32] */, meta[relay.Constant][1] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %7 = fn (%FunctionVar_0_02: Tensor[(1, 64, 112, 112), float32] /* ty=Tensor[(1, 64, 112, 112), float32] */, PartitionedFromPattern=\"nn.max_pool2d_\", Composite=\"ccompiler.max_pool2d\") -> Tensor[(1, 64, 56, 56), float32] {\n",
      "    nn.max_pool2d(%FunctionVar_0_02, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  } /* ty=fn (Tensor[(1, 64, 112, 112), float32]) -> Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %8 = %7(%6) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %9 = fn (%FunctionVar_1_0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %FunctionVar_1_1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(64, 1, 1), float32] /* ty=Tensor[(64, 1, 1), float32] */, PartitionedFromPattern=\"nn.conv2d_add_nn.relu_\", Composite=\"ccompiler.conv_add_relu\") -> Tensor[(1, 64, 56, 56), float32] {\n",
      "    %1 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "    %2 = add(%1, %FunctionVar_1_2) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "    nn.relu(%2) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(64, 1, 1), float32]) -> Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %10 = %9(%8, meta[relay.Constant][2] /* ty=Tensor[(64, 64, 3, 3), float32] */, meta[relay.Constant][3] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %11 = fn (%FunctionVar_0_01: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %FunctionVar_0_11: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(64, 1, 1), float32] /* ty=Tensor[(64, 1, 1), float32] */, PartitionedFromPattern=\"nn.conv2d_add_\", Composite=\"ccompiler.conv_add_relu\") -> Tensor[(1, 64, 56, 56), float32] {\n",
      "    %0 = nn.conv2d(%FunctionVar_0_01, %FunctionVar_0_11, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "    add(%0, %FunctionVar_0_2) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(64, 1, 1), float32]) -> Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %12 = %11(%10, meta[relay.Constant][4] /* ty=Tensor[(64, 64, 3, 3), float32] */, meta[relay.Constant][5] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %13 = fn (%FunctionVar_0_0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %FunctionVar_0_1: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, PartitionedFromPattern=\"add_\", Composite=\"ccompiler.add\") -> Tensor[(1, 64, 56, 56), float32] {\n",
      "    add(%FunctionVar_0_0, %FunctionVar_0_1) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(1, 64, 56, 56), float32]) -> Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %13(%12, %8) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def make_max_pool2d_pattern():\n",
    "    x = wildcard()\n",
    "    r = is_op(\"nn.max_pool2d\")(x)\n",
    "    return r\n",
    "\n",
    "def make_add_pattern():\n",
    "    return wildcard() + wildcard()\n",
    "\n",
    "\n",
    "compiler_name = \"ccompiler\"\n",
    "# 按照顺序依次执行匹配工作\n",
    "pattern_table = [\n",
    "    (f\"{compiler_name}.conv_add_relu\", make_conv_add_relu_pattern()),\n",
    "    (f\"{compiler_name}.max_pool2d\", make_max_pool2d_pattern()),\n",
    "    (f\"{compiler_name}.add\", make_add_pattern()),\n",
    "]\n",
    "merge_passes = tvm.transform.Sequential([\n",
    "    relay.transform.InferType(),\n",
    "    relay.transform.MergeComposite(pattern_table),\n",
    "    # # relay.transform.AnnotateTarget([compiler_name]),\n",
    "    relay.transform.PartitionGraph(),\n",
    "])\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    with relay.quantize.qconfig(\n",
    "        calibrate_mode=\"kl_divergence\",\n",
    "        weight_scale=\"max\",\n",
    "        skip_conv_layers=[],\n",
    "        skip_dense_layer=False\n",
    "    ):\n",
    "        run_mod_f = merge_passes(run_mod)\n",
    "print(run_mod_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "符合期望结构。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 为融合函数添加 `QPartitionExpr` 算子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.relay import Call\n",
    "from tvm.relay.function import Function, FunctionWithFields\n",
    "from tvm.relay.quantize._partition import QPartitionExpr\n",
    "\n",
    "@tvm.relay.transform.function_pass(opt_level=1)\n",
    "class MergeGraphTransform:\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self.nodes = []\n",
    "\n",
    "    def transform_function(self, func, mod, ctx):\n",
    "        obj = self\n",
    "        class Replace(tvm.relay.ExprMutator):\n",
    "            def visit_function(self, fn):\n",
    "                new_params = [self.visit(x) for x in fn.params]\n",
    "                new_body = self.visit(fn.body)\n",
    "                if not isinstance(new_body.op, Function): # 防止循环添加 QPartitionExpr\n",
    "                    new_body = QPartitionExpr(new_body).realize()\n",
    "                if new_params == list(fn.params) and new_body == fn.body:\n",
    "                    new_fn =  fn\n",
    "                else:\n",
    "                    new_fn = FunctionWithFields(fn, list(new_params), new_body)\n",
    "                obj.nodes.append(new_fn)\n",
    "                return new_fn\n",
    "        return Replace().visit(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "def @main(%data: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] span=aten::_convolution_0.data:0:0 */) -> Tensor[(1, 64, 56, 56), float32] {\n",
       "  %15 = fn (%FunctionVar_2_0: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %FunctionVar_2_1: Tensor[(64, 3, 7, 7), float32] /* ty=Tensor[(64, 3, 7, 7), float32] */, %FunctionVar_2_2: Tensor[(64, 1, 1), float32] /* ty=Tensor[(64, 1, 1), float32] */, PartitionedFromPattern=\"nn.conv2d_add_nn.relu_\", Composite=\"ccompiler.conv_add_relu\") -> Tensor[(1, 64, 112, 112), float32] {\n",
       "    %11 = nn.conv2d(%FunctionVar_2_0, %FunctionVar_2_1, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
       "    %12 = add(%11, %FunctionVar_2_2) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
       "    %13 = nn.relu(%12) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
       "    %14 = annotation.cast_hint(%13, dtype=\"int8\") /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
       "    annotation.stop_fusion(%14) /* ty=Tensor[(1, 64, 112, 112), float32] */\n",
       "  } /* ty=fn (Tensor[(1, 3, 224, 224), float32], Tensor[(64, 3, 7, 7), float32], Tensor[(64, 1, 1), float32]) -> Tensor[(1, 64, 112, 112), float32] */;\n",
       "  %16 = %15(%data, meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), float32] */, meta[relay.Constant][1] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
       "  %17 = fn (%FunctionVar_0_02: Tensor[(1, 64, 112, 112), float32] /* ty=Tensor[(1, 64, 112, 112), float32] */, PartitionedFromPattern=\"nn.max_pool2d_\", Composite=\"ccompiler.max_pool2d\") -> Tensor[(1, 64, 56, 56), float32] {\n",
       "    %9 = nn.max_pool2d(%FunctionVar_0_02, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "    %10 = annotation.cast_hint(%9, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "    annotation.stop_fusion(%10) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
       "  } /* ty=fn (Tensor[(1, 64, 112, 112), float32]) -> Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %18 = %17(%16) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %19 = fn (%FunctionVar_1_0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %FunctionVar_1_1: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %FunctionVar_1_2: Tensor[(64, 1, 1), float32] /* ty=Tensor[(64, 1, 1), float32] */, PartitionedFromPattern=\"nn.conv2d_add_nn.relu_\", Composite=\"ccompiler.conv_add_relu\") -> Tensor[(1, 64, 56, 56), float32] {\n",
       "    %5 = nn.conv2d(%FunctionVar_1_0, %FunctionVar_1_1, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "    %6 = add(%5, %FunctionVar_1_2) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "    %7 = nn.relu(%6) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "    %8 = annotation.cast_hint(%7, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "    annotation.stop_fusion(%8) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
       "  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(64, 1, 1), float32]) -> Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %20 = %19(%18, meta[relay.Constant][2] /* ty=Tensor[(64, 64, 3, 3), float32] */, meta[relay.Constant][3] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %21 = fn (%FunctionVar_0_01: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %FunctionVar_0_11: Tensor[(64, 64, 3, 3), float32] /* ty=Tensor[(64, 64, 3, 3), float32] */, %FunctionVar_0_2: Tensor[(64, 1, 1), float32] /* ty=Tensor[(64, 1, 1), float32] */, PartitionedFromPattern=\"nn.conv2d_add_\", Composite=\"ccompiler.conv_add_relu\") -> Tensor[(1, 64, 56, 56), float32] {\n",
       "    %2 = nn.conv2d(%FunctionVar_0_01, %FunctionVar_0_11, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "    %3 = add(%2, %FunctionVar_0_2) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "    %4 = annotation.cast_hint(%3, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "    annotation.stop_fusion(%4) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
       "  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(64, 64, 3, 3), float32], Tensor[(64, 1, 1), float32]) -> Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %22 = %21(%20, meta[relay.Constant][4] /* ty=Tensor[(64, 64, 3, 3), float32] */, meta[relay.Constant][5] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %23 = fn (%FunctionVar_0_0: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %FunctionVar_0_1: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, PartitionedFromPattern=\"add_\", Composite=\"ccompiler.add\") -> Tensor[(1, 64, 56, 56), float32] {\n",
       "    %0 = add(%FunctionVar_0_0, %FunctionVar_0_1) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "    %1 = annotation.cast_hint(%0, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "    annotation.stop_fusion(%1) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
       "  } /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(1, 64, 56, 56), float32]) -> Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %23(%22, %18) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
       "}\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = MergeGraphTransform()\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    with relay.quantize.qconfig(\n",
    "        calibrate_mode=\"kl_divergence\",\n",
    "        weight_scale=\"max\",\n",
    "        skip_conv_layers=[],\n",
    "        skip_dense_layer=False\n",
    "    ):\n",
    "        mod_sq = transform(run_mod_f)\n",
    "mod_sq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 变换计算图为原语计算图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于 {class}`tvm.contrib.graph_executor.GraphModule` 不支持对 {class}`tvm.relay.function.Function` 进行推理，需要分解其为原语函数，以支持后续的校准过程："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "def @main(%data: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] span=aten::_convolution_0.data:0:0 */) -> Tensor[(1, 64, 56, 56), float32] {\n",
       "  %0 = nn.conv2d(%data, meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), float32] */, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
       "  %1 = add(%0, meta[relay.Constant][1] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
       "  %2 = nn.relu(%1) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
       "  %3 = annotation.cast_hint(%2, dtype=\"int8\") /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
       "  %4 = annotation.stop_fusion(%3) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
       "  %5 = nn.max_pool2d(%4, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %6 = annotation.cast_hint(%5, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %7 = annotation.stop_fusion(%6) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %8 = nn.conv2d(%7, meta[relay.Constant][2] /* ty=Tensor[(64, 64, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %9 = add(%8, meta[relay.Constant][3] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %10 = nn.relu(%9) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %11 = annotation.cast_hint(%10, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %12 = annotation.stop_fusion(%11) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %13 = nn.conv2d(%12, meta[relay.Constant][4] /* ty=Tensor[(64, 64, 3, 3), float32] */, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %14 = add(%13, meta[relay.Constant][5] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %15 = annotation.cast_hint(%14, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %16 = annotation.stop_fusion(%15) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %17 = add(%16, %7) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %18 = annotation.cast_hint(%17, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  annotation.stop_fusion(%18) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
       "}\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    with relay.quantize.qconfig(\n",
    "        calibrate_mode=\"kl_divergence\",\n",
    "        weight_scale=\"max\",\n",
    "        skip_conv_layers=[],\n",
    "        skip_dense_layer=False\n",
    "    ):\n",
    "        run_mod_sq = relay.transform.DefuseOps()(mod_sq)\n",
    "run_mod_sq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注解计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%data: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] span=aten::_convolution_0.data:0:0 */, %dom_scale: float32 /* ty=float32 */, %clip_min: float32 /* ty=float32 */, %clip_max: float32 /* ty=float32 */, %dom_scale1: float32 /* ty=float32 */, %clip_min1: float32 /* ty=float32 */, %clip_max1: float32 /* ty=float32 */, %dom_scale2: float32 /* ty=float32 */, %clip_min2: float32 /* ty=float32 */, %clip_max2: float32 /* ty=float32 */, %dom_scale3: float32 /* ty=float32 */, %clip_min3: float32 /* ty=float32 */, %clip_max3: float32 /* ty=float32 */, %dom_scale4: float32 /* ty=float32 */, %clip_min4: float32 /* ty=float32 */, %clip_max4: float32 /* ty=float32 */, %dom_scale5: float32 /* ty=float32 */, %clip_min5: float32 /* ty=float32 */, %clip_max5: float32 /* ty=float32 */, %dom_scale6: float32 /* ty=float32 */, %clip_min6: float32 /* ty=float32 */, %clip_max6: float32 /* ty=float32 */, %dom_scale7: float32 /* ty=float32 */, %clip_min7: float32 /* ty=float32 */, %clip_max7: float32 /* ty=float32 */, %dom_scale8: float32 /* ty=float32 */, %clip_min8: float32 /* ty=float32 */, %clip_max8: float32 /* ty=float32 */, %dom_scale9: float32 /* ty=float32 */, %clip_min9: float32 /* ty=float32 */, %clip_max9: float32 /* ty=float32 */, %dom_scale10: float32 /* ty=float32 */, %clip_min10: float32 /* ty=float32 */, %clip_max10: float32 /* ty=float32 */, %dom_scale11: float32 /* ty=float32 */, %clip_min11: float32 /* ty=float32 */, %clip_max11: float32 /* ty=float32 */) -> Tensor[(1, 64, 56, 56), float32] {\n",
      "  %0 = relay.op.annotation.simulated_quantize(%data, %dom_scale, %clip_min, %clip_max, kind=1) /* ty=Tensor[(1, 3, 224, 224), float32] */;\n",
      "  %1 = relay.op.annotation.simulated_quantize(meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), float32] */, %dom_scale1, %clip_min1, %clip_max1, kind=2) /* ty=Tensor[(64, 3, 7, 7), float32] */;\n",
      "  %2 = nn.conv2d(%0, %1, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %3 = relay.op.annotation.simulated_quantize(meta[relay.Constant][1] /* ty=Tensor[(64, 1, 1), float32] */, %dom_scale2, %clip_min2, %clip_max2, kind=2) /* ty=Tensor[(64, 1, 1), float32] */;\n",
      "  %4 = add(%2, %3) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %5 = nn.relu(%4) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %6 = relay.op.annotation.simulated_quantize(%5, %dom_scale3, %clip_min3, %clip_max3, kind=1) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %7 = annotation.cast_hint(%6, dtype=\"int8\") /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %8 = annotation.stop_fusion(%7) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %9 = nn.max_pool2d(%8, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %10 = annotation.cast_hint(%9, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %11 = annotation.stop_fusion(%10) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %12 = relay.op.annotation.simulated_quantize(%11, %dom_scale4, %clip_min4, %clip_max4, kind=1) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %13 = relay.op.annotation.simulated_quantize(meta[relay.Constant][2] /* ty=Tensor[(64, 64, 3, 3), float32] */, %dom_scale5, %clip_min5, %clip_max5, kind=2) /* ty=Tensor[(64, 64, 3, 3), float32] */;\n",
      "  %14 = nn.conv2d(%12, %13, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %15 = relay.op.annotation.simulated_quantize(meta[relay.Constant][3] /* ty=Tensor[(64, 1, 1), float32] */, %dom_scale6, %clip_min6, %clip_max6, kind=2) /* ty=Tensor[(64, 1, 1), float32] */;\n",
      "  %16 = add(%14, %15) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %17 = nn.relu(%16) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %18 = relay.op.annotation.simulated_quantize(%17, %dom_scale7, %clip_min7, %clip_max7, kind=1) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %19 = annotation.cast_hint(%18, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %20 = annotation.stop_fusion(%19) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %21 = relay.op.annotation.simulated_quantize(meta[relay.Constant][4] /* ty=Tensor[(64, 64, 3, 3), float32] */, %dom_scale8, %clip_min8, %clip_max8, kind=2) /* ty=Tensor[(64, 64, 3, 3), float32] */;\n",
      "  %22 = nn.conv2d(%20, %21, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %23 = relay.op.annotation.simulated_quantize(meta[relay.Constant][5] /* ty=Tensor[(64, 1, 1), float32] */, %dom_scale9, %clip_min9, %clip_max9, kind=2) /* ty=Tensor[(64, 1, 1), float32] */;\n",
      "  %24 = add(%22, %23) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %25 = relay.op.annotation.simulated_quantize(%24, %dom_scale10, %clip_min10, %clip_max10, kind=1) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %26 = annotation.cast_hint(%25, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %27 = annotation.stop_fusion(%26) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %28 = add(%27, %12) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %29 = relay.op.annotation.simulated_quantize(%28, %dom_scale11, %clip_min11, %clip_max11, kind=1) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %30 = annotation.cast_hint(%29, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  annotation.stop_fusion(%30) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    with relay.quantize.qconfig(\n",
    "        calibrate_mode=\"kl_divergence\",\n",
    "        weight_scale=\"max\",\n",
    "        skip_conv_layers=[],\n",
    "        skip_dense_layer=False\n",
    "    ):\n",
    "        annotate_mod = relay.quantize.annotate()(run_mod_sq)\n",
    "print(annotate_mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模拟量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "def @main(%data: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] span=aten::_convolution_0.data:0:0 */) -> Tensor[(1, 64, 56, 56), float32] {\n",
       "  %0 = relay.op.annotation.simulated_quantize(%data, 0.0318054f, -127f, 127f, kind=1) /* ty=Tensor[(1, 3, 224, 224), float32] */;\n",
       "  %1 = relay.op.annotation.simulated_quantize(meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), float32] */, 0.00307715f, -127f, 127f, kind=2) /* ty=Tensor[(64, 3, 7, 7), float32] */;\n",
       "  %2 = nn.conv2d(%0, %1, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
       "  %3 = relay.op.annotation.simulated_quantize(meta[relay.Constant][1] /* ty=Tensor[(64, 1, 1), float32] */, 0.00541632f, -127f, 127f, kind=2) /* ty=Tensor[(64, 1, 1), float32] */;\n",
       "  %4 = add(%2, %3) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
       "  %5 = nn.relu(%4) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
       "  %6 = relay.op.annotation.simulated_quantize(%5, 0.0290262f, -127f, 127f, kind=1) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
       "  %7 = annotation.cast_hint(%6, dtype=\"int8\") /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
       "  %8 = annotation.stop_fusion(%7) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
       "  %9 = nn.max_pool2d(%8, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %10 = annotation.cast_hint(%9, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %11 = annotation.stop_fusion(%10) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %12 = relay.op.annotation.simulated_quantize(%11, 0.0290262f, -127f, 127f, kind=1) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %13 = relay.op.annotation.simulated_quantize(meta[relay.Constant][2] /* ty=Tensor[(64, 64, 3, 3), float32] */, 0.00292581f, -127f, 127f, kind=2) /* ty=Tensor[(64, 64, 3, 3), float32] */;\n",
       "  %14 = nn.conv2d(%12, %13, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %15 = relay.op.annotation.simulated_quantize(meta[relay.Constant][3] /* ty=Tensor[(64, 1, 1), float32] */, 0.00861102f, -127f, 127f, kind=2) /* ty=Tensor[(64, 1, 1), float32] */;\n",
       "  %16 = add(%14, %15) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %17 = nn.relu(%16) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %18 = relay.op.annotation.simulated_quantize(%17, 0.011434f, -127f, 127f, kind=1) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %19 = annotation.cast_hint(%18, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %20 = annotation.stop_fusion(%19) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %21 = relay.op.annotation.simulated_quantize(meta[relay.Constant][4] /* ty=Tensor[(64, 64, 3, 3), float32] */, 0.00602173f, -127f, 127f, kind=2) /* ty=Tensor[(64, 64, 3, 3), float32] */;\n",
       "  %22 = nn.conv2d(%20, %21, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3]) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %23 = relay.op.annotation.simulated_quantize(meta[relay.Constant][5] /* ty=Tensor[(64, 1, 1), float32] */, 0.0139479f, -127f, 127f, kind=2) /* ty=Tensor[(64, 1, 1), float32] */;\n",
       "  %24 = add(%22, %23) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %25 = relay.op.annotation.simulated_quantize(%24, 0.0183486f, -127f, 127f, kind=1) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %26 = annotation.cast_hint(%25, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %27 = annotation.stop_fusion(%26) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %28 = add(%27, %12) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %29 = relay.op.annotation.simulated_quantize(%28, 0.0320906f, -127f, 127f, kind=1) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  %30 = annotation.cast_hint(%29, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  annotation.stop_fusion(%30) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
       "}\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tvm.relay.quantize import calibrate\n",
    "\n",
    "# 定义校准数据集\n",
    "def data_iter(input_name, input_shape, num=1):\n",
    "    for _ in range(num):\n",
    "        yield {input_name: np.random.normal(size=input_shape)}\n",
    "\n",
    "dataset = data_iter(input_name, input_shape)\n",
    "\n",
    "calibrate_pass = tvm.transform.module_pass(\n",
    "    calibrate(dataset), opt_level=1, name=\"QuantizeCalibrate\"\n",
    ")\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    with relay.quantize.qconfig(\n",
    "        calibrate_mode=\"kl_divergence\",\n",
    "        weight_scale=\"max\",\n",
    "        skip_conv_layers=[],\n",
    "        skip_dense_layer=False\n",
    "    ):\n",
    "        calibrate_mod = calibrate_pass(annotate_mod)\n",
    "calibrate_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 量化实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "def @main(%data: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] span=aten::_convolution_0.data:0:0 */) -> Tensor[(1, 64, 56, 56), float32] {\n",
       "  %0 = multiply(%data, 31.4412f /* ty=float32 */) /* ty=Tensor[(1, 3, 224, 224), float32] */;\n",
       "  %1 = round(%0) /* ty=Tensor[(1, 3, 224, 224), float32] */;\n",
       "  %2 = clip(%1, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 3, 224, 224), float32] */;\n",
       "  %3 = multiply(meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), float32] */, 324.976f /* ty=float32 */) /* ty=Tensor[(64, 3, 7, 7), float32] */;\n",
       "  %4 = round(%3) /* ty=Tensor[(64, 3, 7, 7), float32] */;\n",
       "  %5 = clip(%4, a_min=-127f, a_max=127f) /* ty=Tensor[(64, 3, 7, 7), float32] */;\n",
       "  %6 = cast(%2, dtype=\"int8\") /* ty=Tensor[(1, 3, 224, 224), int8] */;\n",
       "  %7 = cast(%5, dtype=\"int8\") /* ty=Tensor[(64, 3, 7, 7), int8] */;\n",
       "  %8 = multiply(meta[relay.Constant][1] /* ty=Tensor[(64, 1, 1), float32] */, 184.627f /* ty=float32 */) /* ty=Tensor[(64, 1, 1), float32] */;\n",
       "  %9 = round(%8) /* ty=Tensor[(64, 1, 1), float32] */;\n",
       "  %10 = clip(%9, a_min=-127f, a_max=127f) /* ty=Tensor[(64, 1, 1), float32] */;\n",
       "  %11 = cast(%10, dtype=\"int32\") /* ty=Tensor[(64, 1, 1), int32] */;\n",
       "  %12 = fixed_point_multiply(%11, multiplier=1856966272, shift=6) /* ty=Tensor[(64, 1, 1), int32] */;\n",
       "  %13 = cast(%12, dtype=\"int32\") /* ty=Tensor[(64, 1, 1), int32] */;\n",
       "  %14 = nn.conv2d(%6, %7, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7], out_dtype=\"int32\") /* ty=Tensor[(1, 64, 112, 112), int32] */;\n",
       "  %15 = annotation.stop_fusion(%13) /* ty=Tensor[(64, 1, 1), int32] */;\n",
       "  %16 = add(%14, %15) /* ty=Tensor[(1, 64, 112, 112), int32] */;\n",
       "  %17 = nn.relu(%16) /* ty=Tensor[(1, 64, 112, 112), int32] */;\n",
       "  %18 = cast(%17, dtype=\"int64\") /* ty=Tensor[(1, 64, 112, 112), int64] */;\n",
       "  %19 = fixed_point_multiply(%18, multiplier=1853661184, shift=-8) /* ty=Tensor[(1, 64, 112, 112), int64] */;\n",
       "  %20 = clip(%19, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 112, 112), int64] */;\n",
       "  %21 = cast(%20, dtype=\"int32\") /* ty=Tensor[(1, 64, 112, 112), int32] */;\n",
       "  %22 = cast(%21, dtype=\"int8\") /* ty=Tensor[(1, 64, 112, 112), int8] */;\n",
       "  %23 = annotation.stop_fusion(%22) /* ty=Tensor[(1, 64, 112, 112), int8] */;\n",
       "  %24 = cast(%23, dtype=\"int8\") /* ty=Tensor[(1, 64, 112, 112), int8] */;\n",
       "  %25 = nn.max_pool2d(%24, pool_size=[3, 3], strides=[2, 2], padding=[1, 1, 1, 1]) /* ty=Tensor[(1, 64, 56, 56), int8] */;\n",
       "  %26 = cast(%25, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), int8] */;\n",
       "  %27 = annotation.stop_fusion(%26) /* ty=Tensor[(1, 64, 56, 56), int8] */;\n",
       "  %28 = multiply(meta[relay.Constant][2] /* ty=Tensor[(64, 64, 3, 3), float32] */, 341.785f /* ty=float32 */) /* ty=Tensor[(64, 64, 3, 3), float32] */;\n",
       "  %29 = round(%28) /* ty=Tensor[(64, 64, 3, 3), float32] */;\n",
       "  %30 = clip(%29, a_min=-127f, a_max=127f) /* ty=Tensor[(64, 64, 3, 3), float32] */;\n",
       "  %31 = clip(%27, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 56, 56), int8] */;\n",
       "  %32 = cast(%30, dtype=\"int8\") /* ty=Tensor[(64, 64, 3, 3), int8] */;\n",
       "  %33 = multiply(meta[relay.Constant][3] /* ty=Tensor[(64, 1, 1), float32] */, 116.13f /* ty=float32 */) /* ty=Tensor[(64, 1, 1), float32] */;\n",
       "  %34 = round(%33) /* ty=Tensor[(64, 1, 1), float32] */;\n",
       "  %35 = clip(%34, a_min=-127f, a_max=127f) /* ty=Tensor[(64, 1, 1), float32] */;\n",
       "  %36 = cast(%35, dtype=\"int32\") /* ty=Tensor[(64, 1, 1), int32] */;\n",
       "  %37 = fixed_point_multiply(%36, multiplier=1701132288, shift=7) /* ty=Tensor[(64, 1, 1), int32] */;\n",
       "  %38 = cast(%37, dtype=\"int32\") /* ty=Tensor[(64, 1, 1), int32] */;\n",
       "  %39 = nn.conv2d(%31, %32, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
       "  %40 = annotation.stop_fusion(%38) /* ty=Tensor[(64, 1, 1), int32] */;\n",
       "  %41 = add(%39, %40) /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
       "  %42 = nn.relu(%41) /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
       "  %43 = cast(%42, dtype=\"int64\") /* ty=Tensor[(1, 64, 56, 56), int64] */;\n",
       "  %44 = fixed_point_multiply(%43, multiplier=2041626496, shift=-7) /* ty=Tensor[(1, 64, 56, 56), int64] */;\n",
       "  %45 = clip(%44, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 56, 56), int64] */;\n",
       "  %46 = cast(%45, dtype=\"int32\") /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
       "  %47 = cast(%46, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), int8] */;\n",
       "  %48 = multiply(meta[relay.Constant][4] /* ty=Tensor[(64, 64, 3, 3), float32] */, 166.065f /* ty=float32 */) /* ty=Tensor[(64, 64, 3, 3), float32] */;\n",
       "  %49 = round(%48) /* ty=Tensor[(64, 64, 3, 3), float32] */;\n",
       "  %50 = clip(%49, a_min=-127f, a_max=127f) /* ty=Tensor[(64, 64, 3, 3), float32] */;\n",
       "  %51 = annotation.stop_fusion(%47) /* ty=Tensor[(1, 64, 56, 56), int8] */;\n",
       "  %52 = cast(%50, dtype=\"int8\") /* ty=Tensor[(64, 64, 3, 3), int8] */;\n",
       "  %53 = multiply(meta[relay.Constant][5] /* ty=Tensor[(64, 1, 1), float32] */, 71.6953f /* ty=float32 */) /* ty=Tensor[(64, 1, 1), float32] */;\n",
       "  %54 = round(%53) /* ty=Tensor[(64, 1, 1), float32] */;\n",
       "  %55 = clip(%54, a_min=-127f, a_max=127f) /* ty=Tensor[(64, 1, 1), float32] */;\n",
       "  %56 = cast(%55, dtype=\"int32\") /* ty=Tensor[(64, 1, 1), int32] */;\n",
       "  %57 = fixed_point_multiply(%56, multiplier=1699332736, shift=8) /* ty=Tensor[(64, 1, 1), int32] */;\n",
       "  %58 = cast(%57, dtype=\"int32\") /* ty=Tensor[(64, 1, 1), int32] */;\n",
       "  %59 = nn.conv2d(%51, %52, padding=[1, 1, 1, 1], channels=64, kernel_size=[3, 3], out_dtype=\"int32\") /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
       "  %60 = annotation.stop_fusion(%58) /* ty=Tensor[(64, 1, 1), int32] */;\n",
       "  %61 = add(%59, %60) /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
       "  %62 = cast(%61, dtype=\"int64\") /* ty=Tensor[(1, 64, 56, 56), int64] */;\n",
       "  %63 = fixed_point_multiply(%62, multiplier=2062943744, shift=-8) /* ty=Tensor[(1, 64, 56, 56), int64] */;\n",
       "  %64 = clip(%63, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 56, 56), int64] */;\n",
       "  %65 = cast(%64, dtype=\"int32\") /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
       "  %66 = cast(%65, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), int8] */;\n",
       "  %67 = annotation.stop_fusion(%66) /* ty=Tensor[(1, 64, 56, 56), int8] */;\n",
       "  %68 = cast(%31, dtype=\"int32\") /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
       "  %69 = fixed_point_multiply(%68, multiplier=1698580352, shift=1) /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
       "  %70 = cast(%67, dtype=\"int32\") /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
       "  %71 = cast(%69, dtype=\"int32\") /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
       "  %72 = add(%70, %71) /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
       "  %73 = cast(%72, dtype=\"int64\") /* ty=Tensor[(1, 64, 56, 56), int64] */;\n",
       "  %74 = fixed_point_multiply(%73, multiplier=1227879168, shift=0) /* ty=Tensor[(1, 64, 56, 56), int64] */;\n",
       "  %75 = clip(%74, a_min=-127f, a_max=127f) /* ty=Tensor[(1, 64, 56, 56), int64] */;\n",
       "  %76 = cast(%75, dtype=\"int32\") /* ty=Tensor[(1, 64, 56, 56), int32] */;\n",
       "  %77 = cast(%76, dtype=\"int8\") /* ty=Tensor[(1, 64, 56, 56), int8] */;\n",
       "  %78 = annotation.stop_fusion(%77) /* ty=Tensor[(1, 64, 56, 56), int8] */;\n",
       "  %79 = cast(%78, dtype=\"float32\") /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
       "  multiply(%79, 0.0320906f /* ty=float32 */) /* ty=Tensor[(1, 64, 56, 56), float32] */\n",
       "}\n"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    with relay.quantize.qconfig(\n",
    "        calibrate_mode=\"kl_divergence\",\n",
    "        weight_scale=\"max\",\n",
    "        skip_conv_layers=[],\n",
    "        skip_dense_layer=False\n",
    "    ):\n",
    "        run_mod_r = relay.quantize.realize()(calibrate_mod)\n",
    "run_mod_r"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
