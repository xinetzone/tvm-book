{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定点乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试浮点数到定点的转换。\n",
    "\n",
    "构造具有大范围浮点值的 numpy 数组来实现。使用 {func}`tvm.topi.hexagon.utils.get_fixed_point_value` 将这些值转换为定点值。接着，使用函数提供的 `scale_factor` 将这些值转换回浮点数。然后将这些转换后的浮点值与原始值进行比较，如果它们恰好超出了预期的容差，就会触发断言。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import struct\n",
    "import math\n",
    "import tvm\n",
    "from tvm.topi.hexagon.utils import get_fixed_point_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构造具有广泛值范围的数组\n",
    "fp1 = np.random.uniform(0.00001, 0.0002, size=(10))\n",
    "fp2 = np.random.uniform(0.001, 0.02, size=(10))\n",
    "fp3 = np.random.uniform(1, 20, size=(10))\n",
    "fp4 = np.random.uniform(900, 1000, size=(10))\n",
    "fp5 = np.random.uniform(1e9, 1e10, size=(10))\n",
    "\n",
    "# 根据 IEEE-754 浮点标准测试具有最大可能指数的值(实际 exp 值 = 127，存储 exp 值 = 254)\n",
    "fp6 = np.random.uniform(2.4e38, 2.5e38, size=(1))\n",
    "# 测试非常小的浮点值\n",
    "fp7 = np.random.uniform(1.4e-34, 1.7e-34, size=(1))\n",
    "\n",
    "float_arr = np.concatenate((fp1, fp2, fp3, fp4, fp5, fp6, fp7))\n",
    "for flp in float_arr:\n",
    "    fxp, rsh = get_fixed_point_value(flp, \"int16\")\n",
    "    # 使用 rsh 计算 scale_factor (rsh 是 scale_factor 的log2)。\n",
    "    # 这样做的时候，使用IEEE-754浮点表示，因为 rsh 可以是负数或正数。\n",
    "\n",
    "    scale = ((rsh + 127) & 0xFF) << 23 # 添加偏置 (127) 并将其定位到指数位\n",
    "    scale_i = struct.pack(\"I\", scale)  # Pack 作为整数\n",
    "    scale_f = struct.unpack(\"f\", scale_i)  # Unpack 作为浮点数\n",
    "\n",
    "    converted_flp = fxp / scale_f[0]\n",
    "    assert math.isclose(flp, converted_flp, rel_tol=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义一些辅助函数用于推理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "\n",
    "def update_lib(lib, lib_name=\"lib.so\"):\n",
    "    tmp_path = tvm.contrib.utils.tempdir()\n",
    "    lib_path = tmp_path.relpath(lib_name)\n",
    "    lib.export_library(lib_path, fcompile=False)\n",
    "    return tvm.runtime.load_module(lib_path)\n",
    "\n",
    "def run_llvm(run_mod, params, input_dict, lib_name=\"lib.so\"):\n",
    "    with tvm.transform.PassContext(opt_level=3, disabled_pass={\"AlterOpLayout\"}):\n",
    "        lib = relay.build(run_mod, target=\"llvm\", params=params)\n",
    "    lib = update_lib(lib, lib_name=lib_name)\n",
    "    exe = tvm.contrib.graph_executor.GraphModule(lib[\"default\"](tvm.cpu()))\n",
    "    exe.run(**input_dict)\n",
    "    return [\n",
    "        exe.get_output(k).asnumpy()\n",
    "        for k in range(exe.get_num_outputs())\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## relay 定点乘法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>a: Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">2</span>), int32]) {\n",
       "  fixed_point_multiply(<span style=\"color: #AA22FF; font-weight: bold\">%</span>a, multiplier<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1288490240</span>, shift<span style=\"color: #AA22FF; font-weight: bold\">=-</span><span style=\"color: #008000\">2</span>)\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[23. 19.]] [[23 19]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>a: Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">2</span>), int32]) {\n",
       "  fixed_point_multiply(<span style=\"color: #AA22FF; font-weight: bold\">%</span>a, multiplier<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1395864320</span>, shift<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>)\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1104. 1044.]] [[1104 1044]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>a: Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">2</span>), int32]) {\n",
       "  fixed_point_multiply(<span style=\"color: #AA22FF; font-weight: bold\">%</span>a, multiplier<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1288490188</span>, shift<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">0</span>)\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[522. 206.]] [[522 206]]\n"
     ]
    }
   ],
   "source": [
    "ishape = (1, 2)\n",
    "dtype = \"int32\"\n",
    "a = relay.var(\"a\", relay.TensorType(ishape, dtype))\n",
    "for multiplier, shift, float_value in [\n",
    "    (1288490240, -2, 0.15),\n",
    "    (1395864320, 1, 1.3),\n",
    "    (1288490188, 0, 0.6),\n",
    "]:\n",
    "    fpm = relay.fixed_point_multiply(a, multiplier, shift)\n",
    "    run_mod = tvm.IRModule.from_expr(fpm)\n",
    "    run_mod.show()\n",
    "    data_in = np.random.randint(0, 1000, size=ishape, dtype=dtype)\n",
    "    inputs = {\"a\": data_in}\n",
    "    expected_output = run_llvm(run_mod, {}, inputs, lib_name=\"lib.so\")[0]\n",
    "    print(np.round(data_in*float_value), expected_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## relay 逐通道定点乘法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义用于 relay 的表达式："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.relay.op import _make\n",
    "from tvm.relay.expr import Expr\n",
    "\n",
    "def fixed_point_multiply_per_axis(\n",
    "    x: Expr,\n",
    "    y: Expr,\n",
    "    lshift: Expr,\n",
    "    rshift: Expr,\n",
    "    is_lshift_required : int,\n",
    "    is_rshift_required : int,\n",
    "    axes,\n",
    "    ):\n",
    "    \"\"\"Fixed point multiplication between data and a fixed point constant expressed as\n",
    "    multiplier * 2^(-shift), where multiplier is a Q-number with 31 fractional bits\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : Expr\n",
    "        Input argument.\n",
    "    y : Expr\n",
    "        Multiplier of a fixed floating point number described as multiplier*2^(-shift).\n",
    "    lshift : Expr\n",
    "        Left shifts of a fixed floating point number described as multiplier*2^(-shift).\n",
    "    rshift : Expr\n",
    "        Right shifts of a fixed floating point number described as multiplier*2^(-shift).\n",
    "    is_lshift_required : int\n",
    "        Whether we need to do left shift or not.\n",
    "    is_rshift_required : int\n",
    "        Whether we need to do right shift or not.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    z : Expr\n",
    "        The result.\n",
    "    \"\"\"\n",
    "    return _make.fixed_point_multiply_per_axis(x, y, lshift, rshift, is_lshift_required, is_rshift_required, axes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tvm.relay.testing.temp_op_attr import TempOpAttr\n",
    "from tvm import te\n",
    "a_shape = [2, 256, 16]\n",
    "b_shape = [256]\n",
    "shape = a_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify accuracy\n",
    "x_np = (\n",
    "    np.random.randint(-1000, 1000, size=np.prod(a_shape)).reshape(a_shape).astype(\"int32\")\n",
    ")\n",
    "y_np = (\n",
    "    np.random.randint(-1000, 1000, size=np.prod(b_shape)).reshape(b_shape).astype(\"int32\")\n",
    ")\n",
    "lsh_np = np.random.randint(0, 10, size=np.prod(b_shape)).reshape(b_shape).astype(\"int32\")\n",
    "rsh_np = np.random.randint(0, 10, size=np.prod(b_shape)).reshape(b_shape).astype(\"int32\")\n",
    "b_np = (\n",
    "    np.random.randint(-1000, 1000, size=np.prod(a_shape)).reshape(a_shape).astype(\"int32\")\n",
    ")\n",
    "inputs = {\"X\":x_np, \"Y\": y_np, \"l_shift\": lsh_np, \"l_shift\": rsh_np}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>X: Tensor[(<span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">256</span>, <span style=\"color: #008000\">16</span>), int32], <span style=\"color: #AA22FF; font-weight: bold\">%</span>Y: Tensor[(<span style=\"color: #008000\">256</span>), int32], <span style=\"color: #AA22FF; font-weight: bold\">%</span>l_shift: Tensor[(<span style=\"color: #008000\">256</span>), int32], <span style=\"color: #AA22FF; font-weight: bold\">%</span>r_shift: Tensor[(<span style=\"color: #008000\">256</span>), int32]) {\n",
       "  fixed_point_multiply_per_axis(<span style=\"color: #AA22FF; font-weight: bold\">%</span>X, <span style=\"color: #AA22FF; font-weight: bold\">%</span>Y, <span style=\"color: #AA22FF; font-weight: bold\">%</span>l_shift, <span style=\"color: #AA22FF; font-weight: bold\">%</span>r_shift, is_lshift_required<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, is_rshift_required<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000; font-weight: bold\">True</span>, axes<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">256</span>])\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32828693        0]]\n"
     ]
    }
   ],
   "source": [
    "shift_shape = [shape[1]]\n",
    "x = relay.var(\"X\", shape=shape, dtype=\"int32\")\n",
    "y = relay.var(\"Y\", shape=shift_shape, dtype=\"int32\")\n",
    "l_shift = relay.var(\"l_shift\", shape=shift_shape, dtype=\"int32\")\n",
    "r_shift = relay.var(\"r_shift\", shape=shift_shape, dtype=\"int32\")\n",
    "out = fixed_point_multiply_per_axis(x, y, l_shift, r_shift, 31, 1, b_shape)\n",
    "mod = tvm.IRModule.from_expr(out)\n",
    "mod.show()\n",
    "\n",
    "expected_output = run_llvm(run_mod, {}, inputs, lib_name=\"lib.so\")[0]\n",
    "print(expected_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以使用 QNN："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>data: Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), int32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), int32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), int32] {\n",
       "  qnn<span style=\"color: #AA22FF; font-weight: bold\">.</span>requantize(<span style=\"color: #AA22FF; font-weight: bold\">%</span>data, meta[relay<span style=\"color: #AA22FF; font-weight: bold\">.</span>Constant][<span style=\"color: #008000\">0</span>] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">128</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>int32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #008000\">1</span>f <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>float32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>int32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">128</span>, <span style=\"color: #008000\">56</span>, <span style=\"color: #008000\">56</span>), int32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "axis = 1\n",
    "ishape = [1, 128, 56, 56]\n",
    "in_scale_const = (1.7, 0.6)\n",
    "x = relay.var(\"data\", shape=ishape, dtype=\"int32\")\n",
    "if isinstance(in_scale_const, tuple):\n",
    "    in_scale = list(in_scale_const) * (ishape[axis] // len(in_scale_const))\n",
    "else:\n",
    "    in_scale = [in_scale_const] * ishape[axis]\n",
    "assert len(in_scale) == ishape[axis]\n",
    "iscale = relay.const(in_scale)\n",
    "izero = relay.const(0)\n",
    "oscale = relay.const(1.0)\n",
    "ozero = relay.const(0)\n",
    "op = relay.qnn.op.requantize(x, iscale, izero, oscale, ozero, axis=axis, out_dtype=\"int32\")\n",
    "mod = tvm.IRModule.from_expr(op)\n",
    "mod = relay.transform.InferType()(mod)\n",
    "mod.show()\n",
    "x_np = (\n",
    "    np.random.randint(-1000, 1000, size=np.prod(ishape)).reshape(ishape).astype(\"int32\")\n",
    ")\n",
    "inputs = {\"data\": x_np}\n",
    "expected_output = run_llvm(mod, {}, inputs, lib_name=\"lib.so\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm import te, topi, tir as T, relay\n",
    "import tvm\n",
    "from tvm.topi import tag\n",
    "# from tvm.relay.op.op import register_compute, register_shape_func\n",
    "# from tvm.relay.op.op import register_broadcast_schedule, register_injective_schedule\n",
    "# from tvm.relay.op.op import register_pattern, OpPattern\n",
    "\n",
    "@tvm.te.tag_scope(tag=tag.ELEMWISE)\n",
    "def q_multiply_shift(x, y, q, left_shift, right_shift, is_left_shift_required):\n",
    "    # Only int32 types are supported (any number of lanes is allowed)\n",
    "    hp_dtype = \"int64\"\n",
    "    lp_dtype = \"int32\"\n",
    "    assert y.dtype == lp_dtype\n",
    "    assert left_shift.dtype == lp_dtype\n",
    "    assert right_shift.dtype == lp_dtype\n",
    "    one = T.const(1, hp_dtype)\n",
    "    def _compute(*indices):\n",
    "        # 0) 获取值\n",
    "        value = x(*indices)\n",
    "        multiplier = y(*indices)\n",
    "        ls = left_shift(*indices)\n",
    "        rs = right_shift(*indices)\n",
    "\n",
    "        # 1) Cast and Multiply the integer multiplier\n",
    "        value = value.astype(hp_dtype)\n",
    "        multiplier = multiplier.astype(hp_dtype)\n",
    "        value = T.Select(T.const(is_left_shift_required, \"bool\"), \n",
    "                         value << ls, value)\n",
    "\n",
    "        # 2) Perform the multiplication in higher precision.\n",
    "        value = value * multiplier\n",
    "\n",
    "        # 3) Find the rounding scalar\n",
    "        total_right_shift = ls + q\n",
    "        pos_rounding_value = (one << (total_right_shift - 1))\n",
    "        value = value + pos_rounding_value\n",
    "\n",
    "        print(total_right_shift)\n",
    "        # 4) Simply right shift the result to get the final output.\n",
    "        value = value >> total_right_shift\n",
    "        # 5) The fixed point multiplication keeps the value in int32 range. Casting back to int32.\n",
    "        return value.astype(x.dtype)\n",
    "\n",
    "    return te.compute(x.shape, _compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left_shift[i0, i1] + 31\n",
      "[[125333333 125333333]] [[3650000 3650000]] [[213025 213025]]\n"
     ]
    }
   ],
   "source": [
    "shape = 1, 2\n",
    "lp_dtype = \"int32\"\n",
    "x = te.placeholder(shape, name=\"x\", dtype=\"int32\")\n",
    "y = te.placeholder(shape, name=\"y\", dtype=lp_dtype)\n",
    "left_shift = te.placeholder(shape, name=\"left_shift\", dtype=lp_dtype)\n",
    "right_shift = te.placeholder(shape, name=\"right_shift\", dtype=lp_dtype)\n",
    "# multipliers_shifts = te.placeholder(shape, name=\"multipliers_shifts\", dtype=\"int32\")\n",
    "q = 31 # int8\n",
    "# q=8 -> uint8\n",
    "z = q_multiply_shift(x, y, q, left_shift, right_shift, is_left_shift_required=1)\n",
    "s = te.create_schedule(z.op)\n",
    "f = tvm.build(s, [x, y, left_shift, right_shift, z], \"llvm\")\n",
    "dev = tvm.cpu(0)\n",
    "a_np = np.ones(shape).astype(x.dtype) * 125333333\n",
    "multiplier_np = np.ones(shape).astype(lp_dtype) * 3650000\n",
    "ls_np = np.ones(shape).astype(lp_dtype) * 1\n",
    "rs_np = np.ones(shape).astype(lp_dtype) * -1\n",
    "a = tvm.nd.array(a_np, dev) \n",
    "multiplier = tvm.nd.array(multiplier_np, dev)\n",
    "ls = tvm.nd.array(ls_np, dev)\n",
    "rs = tvm.nd.array(rs_np, dev)\n",
    "c = tvm.nd.array(np.zeros(shape, dtype=z.dtype), dev)\n",
    "f(a, multiplier, ls, rs, c)\n",
    "print(a, multiplier, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
