{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TVM 自动量化过程剖析\n",
    "\n",
    "以 PyTorch 的 resnet18 模型为例剖析 TVM 自动量化过程。\n",
    "\n",
    "## PyTorch 模型翻译为 relay 模型\n",
    "\n",
    "加载 PyTorch 模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(input_shape):\n",
    "    from torchvision.models import resnet18, ResNet18_Weights\n",
    "    import torch\n",
    "    model = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "    data = torch.randn(*input_shape)\n",
    "    model = torch.jit.trace(model.eval(), data)\n",
    "    return model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 模型翻译为 relay 模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "\n",
    "input_shape = 1, 3, 224, 224\n",
    "input_name = \"data\"\n",
    "traced_model = load_model(input_shape)\n",
    "mod, params = relay.frontend.from_pytorch(\n",
    "    traced_model, \n",
    "    [(input_name, input_shape)], \n",
    "    # use_parser_friendly_name=True\n",
    ")\n",
    "with tvm.transform.PassContext(opt_level=3): # 预处理\n",
    "    opt_mod = relay.quantize.prerequisite_optimize(mod, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{rubric} 加载数据\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm.testing\n",
    "from tvm import relay\n",
    "from tvm.relay import transform, build_module\n",
    "from tvm.relay.testing import run_opt_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from tvm_book.data.classification import ImageFolderDataset\n",
    "\n",
    "def preprocess_image(\n",
    "        image: np.ndarray,\n",
    "        size: tuple[int] = (224, 224),\n",
    "        mean: tuple[float] = (0.485, 0.456, 0.406),\n",
    "        std: tuple[float] = (0.229, 0.224, 0.225)\n",
    "    ):\n",
    "    im = Image.fromarray(image)\n",
    "    im = im.resize((256, 256), Image.Resampling.BILINEAR)\n",
    "    ori_H, ori_W = im.size\n",
    "    H, W = size\n",
    "    space_W, space_H = (ori_W - W)//2, (ori_H - H)//2\n",
    "    im = im.crop((space_W, space_H, ori_W-space_W, ori_H-space_H))\n",
    "    image = np.array(im, dtype=\"float32\")\n",
    "    im.close()\n",
    "    image = image/256\n",
    "    image -= mean\n",
    "    image /= std\n",
    "    return image.astype(np.float32)\n",
    "\n",
    "@dataclass\n",
    "class ImageNet:\n",
    "    root: str\n",
    "    size: tuple[int] = (224, 224)\n",
    "    mean: tuple[float] = (0.485, 0.456, 0.406)\n",
    "    std: tuple[float] = (0.229, 0.224, 0.225)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.root = Path(self.root) # 数据根目录\n",
    "        self.valset = ImageFolderDataset(f\"{self.root}/val\")\n",
    "        self.trainset = ImageFolderDataset(f\"{self.root}/train\")\n",
    "\n",
    "    def calibrateset(self, calibrate_num: int = 200):\n",
    "        \"\"\"用于 TVM 量化的校准数据集\n",
    "        \"\"\"\n",
    "        for k, (data, label) in tqdm(enumerate(self.trainset)):\n",
    "            if k >= calibrate_num:\n",
    "                break\n",
    "            image = preprocess_image(data, self.size, self.mean, self.std)\n",
    "            images = np.expand_dims(image, 0)\n",
    "            images = images.transpose((0, 3, 1, 2))\n",
    "            yield {\"data\": images}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageNet(\"/media/pc/data/lxw/home/data/datasets/ILSVRC/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resnet18 算子融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.relay import Call\n",
    "from tvm.relay.function import Function, FunctionWithFields\n",
    "from tvm.relay.quantize._partition import QPartitionExpr\n",
    "\n",
    "@tvm.relay.transform.function_pass(opt_level=1)\n",
    "class QPartitionTransform:\n",
    "    \"\"\"为融合的函数添加 QPartitionExpr\n",
    "    \"\"\"\n",
    "    def transform_function(self, func, mod, ctx):\n",
    "        class Replace(tvm.relay.ExprMutator):\n",
    "            def visit_function(self, fn):\n",
    "                new_params = [self.visit(x) for x in fn.params]\n",
    "                new_body = self.visit(fn.body)\n",
    "                if not isinstance(new_body.op, Function): # 防止循环添加 QPartitionExpr\n",
    "                    new_body = QPartitionExpr(new_body).realize()\n",
    "                if new_params == list(fn.params) and new_body == fn.body:\n",
    "                    new_fn =  fn\n",
    "                else:\n",
    "                    new_fn = FunctionWithFields(fn, list(new_params), new_body)\n",
    "                return new_fn\n",
    "        return Replace().visit(func)\n",
    "    \n",
    "@tvm.relay.transform.function_pass(opt_level=1)\n",
    "class SplitGraphTransform:\n",
    "    \"\"\"保存子图到不同是子函数\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        self._func_index = 0\n",
    "\n",
    "    def transform_function(self, func, mod, ctx):\n",
    "        obj = self\n",
    "        class Replace(tvm.relay.ExprMutator):\n",
    "            def visit_call(self, call):\n",
    "                new_fn = self.visit(call.op)\n",
    "                new_args = [self.visit(arg) for arg in call.args]\n",
    "                if isinstance(new_fn, Function):\n",
    "                    func_name = f\"f_{obj._func_index:04d}\"\n",
    "                    new_fn = run_opt_pass(new_fn, relay.transform.FoldConstant())\n",
    "                    # print(new_fn)\n",
    "                    mod[func_name] = new_fn\n",
    "                    new_fn = mod.get_global_var(func_name)\n",
    "                    obj._func_index += 1\n",
    "                if new_fn == call.op and new_args == list(call.args):\n",
    "                    new_call = call\n",
    "                else:\n",
    "                    new_call = Call(new_fn, new_args, call.attrs, call.type_args, call.span)\n",
    "                return new_call\n",
    "        return Replace().visit(func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm_book.tvm_utils.relay_pattern import *\n",
    "# 配置融合规则\n",
    "compiler_name = \"ccompiler\"\n",
    "pattern_table = [\n",
    "    (f\"{compiler_name}.conv_add_relu_max_pool2d\", make_conv_add_relu_max_pool2d_pattern()),\n",
    "    (f\"{compiler_name}.conv2d_transpose_add_activate\", make_conv2d_transpose_add_activate_pattern()),\n",
    "    (f\"{compiler_name}.conv_add_activate\", make_conv_add_activate_pattern()),\n",
    "    (f\"{compiler_name}.max_pool2d\", make_max_pool2d_pattern()),\n",
    "    (f\"{compiler_name}.dense_add\", make_dense_add_pattern()),\n",
    "    (f\"{compiler_name}.adaptive_avg_pool2d\", make_adaptive_avg_pool2d_pattern()),\n",
    "    (f\"{compiler_name}.avg_pool2dd\", make_avg_pool2d_pattern()),\n",
    "    (f\"{compiler_name}.add_multiply_add\", make_add_multiply_add_pattern()),\n",
    "    (f\"{compiler_name}.add\", make_add_pattern()),\n",
    "    (f\"{compiler_name}.multiply\", make_multiply_pattern()),\n",
    "    # (f\"{compiler_name}.strided_slice\", make_strided_slice_pattern()),\n",
    "]\n",
    "merge_passes = tvm.transform.Sequential([\n",
    "    relay.transform.InferType(),\n",
    "    relay.transform.MergeComposite(pattern_table),\n",
    "    QPartitionTransform(), # 为融合函数添加 `QPartitionExpr` 算子\n",
    "    # relay.transform.DefuseOps(),\n",
    "    # relay.transform.MergeComposite(pattern_table),\n",
    "    SplitGraphTransform(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    run_mod = merge_passes(opt_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn (%FunctionVar_19_0: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] */, %FunctionVar_19_1: Tensor[(64, 3, 7, 7), float32] /* ty=Tensor[(64, 3, 7, 7), float32] */, %FunctionVar_19_2: Tensor[(64, 1, 1), float32] /* ty=Tensor[(64, 1, 1), float32] */, PartitionedFromPattern=\"nn.conv2d_add_nn.relu_\", Composite=\"ccompiler.conv_add_activate\") -> Tensor[(1, 64, 112, 112), float32] {\n",
      "  %0 = nn.conv2d(%FunctionVar_19_0, %FunctionVar_19_1, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %1 = add(%0, %FunctionVar_19_2) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %2 = nn.relu(%1) /* ty=Tensor[(1, 64, 112, 112), float32] span=aten::relu__0:0:0 */;\n",
      "  %3 = annotation.cast_hint(%2, dtype=\"int8\") /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  annotation.stop_fusion(%3) /* ty=Tensor[(1, 64, 112, 112), float32] */\n",
      "} /* ty=fn (Tensor[(1, 3, 224, 224), float32], Tensor[(64, 3, 7, 7), float32], Tensor[(64, 1, 1), float32]) -> Tensor[(1, 64, 112, 112), float32] */\n"
     ]
    }
   ],
   "source": [
    "print(run_mod[\"f_0000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn (%data: Tensor[(1, 3, 224, 224), float32] /* ty=Tensor[(1, 3, 224, 224), float32] span=aten::_convolution_0.data:0:0 */) -> Tensor[(1, 1000), float32] {\n",
      "  %0 = @f_0000(%data, meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), float32] */, meta[relay.Constant][1] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 112, 112), float32] */;\n",
      "  %1 = @f_0001(%0) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %2 = @f_0002(%1, meta[relay.Constant][2] /* ty=Tensor[(64, 64, 3, 3), float32] */, meta[relay.Constant][3] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %3 = @f_0003(%2, meta[relay.Constant][4] /* ty=Tensor[(64, 64, 3, 3), float32] */, meta[relay.Constant][5] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %4 = @f_0004(%3, %1) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %5 = @f_0005(%4, meta[relay.Constant][6] /* ty=Tensor[(64, 64, 3, 3), float32] */, meta[relay.Constant][7] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %6 = @f_0006(%5, meta[relay.Constant][8] /* ty=Tensor[(64, 64, 3, 3), float32] */, meta[relay.Constant][9] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %7 = @f_0007(%6, %4) /* ty=Tensor[(1, 64, 56, 56), float32] */;\n",
      "  %8 = @f_0008(%7, meta[relay.Constant][10] /* ty=Tensor[(128, 64, 3, 3), float32] */, meta[relay.Constant][11] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %9 = @f_0009(%8, meta[relay.Constant][12] /* ty=Tensor[(128, 128, 3, 3), float32] */, meta[relay.Constant][13] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %10 = @f_0010(%7, meta[relay.Constant][14] /* ty=Tensor[(128, 64, 1, 1), float32] */, meta[relay.Constant][15] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %11 = @f_0011(%9, %10) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %12 = @f_0012(%11, meta[relay.Constant][16] /* ty=Tensor[(128, 128, 3, 3), float32] */, meta[relay.Constant][17] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %13 = @f_0013(%12, meta[relay.Constant][18] /* ty=Tensor[(128, 128, 3, 3), float32] */, meta[relay.Constant][19] /* ty=Tensor[(128, 1, 1), float32] */) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %14 = @f_0014(%13, %11) /* ty=Tensor[(1, 128, 28, 28), float32] */;\n",
      "  %15 = @f_0015(%14, meta[relay.Constant][20] /* ty=Tensor[(256, 128, 3, 3), float32] */, meta[relay.Constant][21] /* ty=Tensor[(256, 1, 1), float32] */) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %16 = @f_0016(%15, meta[relay.Constant][22] /* ty=Tensor[(256, 256, 3, 3), float32] */, meta[relay.Constant][23] /* ty=Tensor[(256, 1, 1), float32] */) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %17 = @f_0017(%14, meta[relay.Constant][24] /* ty=Tensor[(256, 128, 1, 1), float32] */, meta[relay.Constant][25] /* ty=Tensor[(256, 1, 1), float32] */) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %18 = @f_0018(%16, %17) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %19 = @f_0019(%18, meta[relay.Constant][26] /* ty=Tensor[(256, 256, 3, 3), float32] */, meta[relay.Constant][27] /* ty=Tensor[(256, 1, 1), float32] */) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %20 = @f_0020(%19, meta[relay.Constant][28] /* ty=Tensor[(256, 256, 3, 3), float32] */, meta[relay.Constant][29] /* ty=Tensor[(256, 1, 1), float32] */) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %21 = @f_0021(%20, %18) /* ty=Tensor[(1, 256, 14, 14), float32] */;\n",
      "  %22 = @f_0022(%21, meta[relay.Constant][30] /* ty=Tensor[(512, 256, 3, 3), float32] */, meta[relay.Constant][31] /* ty=Tensor[(512, 1, 1), float32] */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %23 = @f_0023(%22, meta[relay.Constant][32] /* ty=Tensor[(512, 512, 3, 3), float32] */, meta[relay.Constant][33] /* ty=Tensor[(512, 1, 1), float32] */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %24 = @f_0024(%21, meta[relay.Constant][34] /* ty=Tensor[(512, 256, 1, 1), float32] */, meta[relay.Constant][35] /* ty=Tensor[(512, 1, 1), float32] */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %25 = @f_0025(%23, %24) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %26 = @f_0026(%25, meta[relay.Constant][36] /* ty=Tensor[(512, 512, 3, 3), float32] */, meta[relay.Constant][37] /* ty=Tensor[(512, 1, 1), float32] */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %27 = @f_0027(%26, meta[relay.Constant][38] /* ty=Tensor[(512, 512, 3, 3), float32] */, meta[relay.Constant][39] /* ty=Tensor[(512, 1, 1), float32] */) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %28 = @f_0028(%27, %25) /* ty=Tensor[(1, 512, 7, 7), float32] */;\n",
      "  %29 = @f_0029(%28) /* ty=Tensor[(1, 512, 1, 1), float32] */;\n",
      "  %30 = reshape(%29, newshape=[0, -1, 1, 1]) /* ty=Tensor[(1, 512, 1, 1), float32] span=aten::flatten_0:0:0 */;\n",
      "  %31 = squeeze(%30, axis=[2, 3]) /* ty=Tensor[(1, 512), float32] span=aten::flatten_0:0:0 */;\n",
      "  @f_0030(%31, meta[relay.Constant][40] /* ty=Tensor[(1000, 512), float32] */, meta[relay.Constant][41] /* ty=Tensor[(1000), float32] */) /* ty=Tensor[(1, 1000), float32] */\n",
      "} /* ty=fn (Tensor[(1, 3, 224, 224), float32]) -> Tensor[(1, 1000), float32] */\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(run_mod[\"main\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注解 resnet18 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    run_mod = merge_passes(opt_mod)\n",
    "\n",
    "    # run_mod = relay.quantize.annotate()(run_mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Traceback (most recent call last):\n  2: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::BaseFunc (tvm::IRModule, tvm::runtime::String)>::AssignTypedLambda<tvm::{lambda(tvm::IRModule, tvm::runtime::String)#5}>(tvm::{lambda(tvm::IRModule, tvm::runtime::String)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  1: tvm::IRModuleNode::Lookup(tvm::runtime::String const&) const\n  0: tvm::IRModuleNode::GetGlobalVar(tvm::runtime::String const&) const\n  File \"/media/pc/data/lxw/ai/tvm/src/ir/module.cc\", line 176\nValueError: Cannot find global var \"f_0000\" in the Module\ncandidates are: [\"f_0058\", \"main\", \"f_0044\", \"f_0037\", \"f_0056\", \"f_0042\", \"f_0049\", \"f_0061\", \"f_0035\", \"f_0054\", \"f_0040\", \"f_0047\", \"f_0033\", \"f_0052\", \"f_0059\", \"f_0045\", \"f_0031\", \"f_0050\", \"f_0038\", \"f_0057\", \"f_0043\", \"f_0036\", \"f_0055\", \"f_0041\", \"f_0048\", \"f_0060\", \"f_0034\", \"f_0053\", \"f_0046\", \"f_0032\", \"f_0039\", \"f_0051\"]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/chaos/quantize/resnet18.ipynb 单元格 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.16.11.3/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/chaos/quantize/resnet18.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(run_mod[\u001b[39m\"\u001b[39;49m\u001b[39mf_0000\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n",
      "File \u001b[0;32m/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/ir/module.py:124\u001b[0m, in \u001b[0;36mIRModule.__getitem__\u001b[0;34m(self, var)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Lookup a global definition by name or by variable.\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \n\u001b[1;32m    113\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[39m    The definition referenced by :code:`var` (either a function or type).\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(var, string_types):\n\u001b[0;32m--> 124\u001b[0m     \u001b[39mreturn\u001b[39;00m _ffi_api\u001b[39m.\u001b[39;49mModule_Lookup_str(\u001b[39mself\u001b[39;49m, var)\n\u001b[1;32m    125\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(var, _expr\u001b[39m.\u001b[39mGlobalVar):\n\u001b[1;32m    126\u001b[0m     \u001b[39mreturn\u001b[39;00m _ffi_api\u001b[39m.\u001b[39mModule_Lookup(\u001b[39mself\u001b[39m, var)\n",
      "File \u001b[0;32m/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/_ffi/_ctypes/packed_func.py:239\u001b[0m, in \u001b[0;36mPackedFuncBase.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    227\u001b[0m ret_tcode \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_int()\n\u001b[1;32m    228\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    229\u001b[0m     _LIB\u001b[39m.\u001b[39mTVMFuncCall(\n\u001b[1;32m    230\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    238\u001b[0m ):\n\u001b[0;32m--> 239\u001b[0m     raise_last_ffi_error()\n\u001b[1;32m    240\u001b[0m _ \u001b[39m=\u001b[39m temp_args\n\u001b[1;32m    241\u001b[0m _ \u001b[39m=\u001b[39m args\n",
      "File \u001b[0;32m/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/_ffi/base.py:476\u001b[0m, in \u001b[0;36mraise_last_ffi_error\u001b[0;34m()\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[39m# The exception PyObject may contain a large amount of state,\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m# including all stack frames that may be inspected in a later\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m# PDB post-mortem.  Therefore, we must make sure to remove the\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m# underlying PyObject* from the C++ side after we retrieve it.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m _LIB\u001b[39m.\u001b[39mTVMDropLastPythonError()\n\u001b[0;32m--> 476\u001b[0m \u001b[39mraise\u001b[39;00m py_err\n",
      "\u001b[0;31mValueError\u001b[0m: Traceback (most recent call last):\n  2: tvm::runtime::PackedFuncObj::Extractor<tvm::runtime::PackedFuncSubObj<tvm::runtime::TypedPackedFunc<tvm::BaseFunc (tvm::IRModule, tvm::runtime::String)>::AssignTypedLambda<tvm::{lambda(tvm::IRModule, tvm::runtime::String)#5}>(tvm::{lambda(tvm::IRModule, tvm::runtime::String)#5}, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >)::{lambda(tvm::runtime::TVMArgs const&, tvm::runtime::TVMRetValue*)#1}> >::Call(tvm::runtime::PackedFuncObj const*, tvm::runtime::TVMArgs, tvm::runtime::TVMRetValue*)\n  1: tvm::IRModuleNode::Lookup(tvm::runtime::String const&) const\n  0: tvm::IRModuleNode::GetGlobalVar(tvm::runtime::String const&) const\n  File \"/media/pc/data/lxw/ai/tvm/src/ir/module.cc\", line 176\nValueError: Cannot find global var \"f_0000\" in the Module\ncandidates are: [\"f_0058\", \"main\", \"f_0044\", \"f_0037\", \"f_0056\", \"f_0042\", \"f_0049\", \"f_0061\", \"f_0035\", \"f_0054\", \"f_0040\", \"f_0047\", \"f_0033\", \"f_0052\", \"f_0059\", \"f_0045\", \"f_0031\", \"f_0050\", \"f_0038\", \"f_0057\", \"f_0043\", \"f_0036\", \"f_0055\", \"f_0041\", \"f_0048\", \"f_0060\", \"f_0034\", \"f_0053\", \"f_0046\", \"f_0032\", \"f_0039\", \"f_0051\"]"
     ]
    }
   ],
   "source": [
    "print(run_mod[\"f_0000\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "200it [00:10, 19.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# from tvm.ir import IRModule, structural_equal\n",
    "import tvm\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    with relay.quantize.qconfig(\n",
    "        skip_conv_layers=[],\n",
    "        calibrate_mode=\"kl_divergence\", \n",
    "        weight_scale=\"max\",\n",
    "        round_for_shift=True,\n",
    "        # rounding=\"TONEAREST\", # \"UPWARD\" or \"TONEAREST\"\n",
    "        calibrate_skip_layers=[],\n",
    "        skip_dense_layer=False,\n",
    "    ):\n",
    "        qmod = relay.quantize.quantize(mod, params, dataset.calibrateset(calibrate_num=200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{rubric} 度量 resnet18 结果\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:autotvm:One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n",
      "3it [00:00,  7.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.0), ('top_5_accuracy', 0.0))||量化: (('量化', 0.0), ('top_5_accuracy', 0.0))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1003it [01:43,  3.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.8381618381618382), ('top_5_accuracy', 0.954045954045954))||量化: (('量化', 0.8331668331668332), ('top_5_accuracy', 0.954045954045954))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2002it [03:27,  3.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7886056971514243), ('top_5_accuracy', 0.9300349825087456))||量化: (('量化', 0.7831084457771115), ('top_5_accuracy', 0.9300349825087456))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3003it [05:18, 10.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7534155281572809), ('top_5_accuracy', 0.915361546151283))||量化: (('量化', 0.7444185271576141), ('top_5_accuracy', 0.9136954348550483))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4002it [07:21,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7275681079730068), ('top_5_accuracy', 0.9092726818295426))||量化: (('量化', 0.7223194201449638), ('top_5_accuracy', 0.9072731817045738))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5003it [09:29,  9.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7518496300739852), ('top_5_accuracy', 0.9164167166566687))||量化: (('量化', 0.7458508298340332), ('top_5_accuracy', 0.9154169166166767))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6002it [11:48,  8.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7518746875520746), ('top_5_accuracy', 0.9161806365605732))||量化: (('量化', 0.74704215964006), ('top_5_accuracy', 0.9155140809865022))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7001it [13:46,  4.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7587487501785459), ('top_5_accuracy', 0.9190115697757463))||量化: (('量化', 0.7541779745750607), ('top_5_accuracy', 0.9181545493500929))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8003it [15:58,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.762779652543432), ('top_5_accuracy', 0.9220097487814023))||量化: (('量化', 0.7582802149731284), ('top_5_accuracy', 0.9212598425196851))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9002it [17:54,  9.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7561382068659038), ('top_5_accuracy', 0.9223419620042218))||量化: (('量化', 0.7512498611265415), ('top_5_accuracy', 0.9213420731029885))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10002it [19:50, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7503249675032497), ('top_5_accuracy', 0.9234076592340766))||量化: (('量化', 0.7457254274572542), ('top_5_accuracy', 0.922107789221078))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11003it [21:36,  9.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7503863285155895), ('top_5_accuracy', 0.92573402417962))||量化: (('量化', 0.747022997909281), ('top_5_accuracy', 0.9243705117716571))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12001it [24:06,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7462711440713274), ('top_5_accuracy', 0.9252562286476127))||量化: (('量化', 0.7422714773768853), ('top_5_accuracy', 0.9237563536371969))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13003it [28:07,  9.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.745250365356511), ('top_5_accuracy', 0.9276978693946619))||量化: (('量化', 0.7406353357434043), ('top_5_accuracy', 0.9259287747096377))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14002it [30:02,  9.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7438754374687523), ('top_5_accuracy', 0.9284336833083351))||量化: (('量化', 0.7393043354046139), ('top_5_accuracy', 0.9267909435040355))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15003it [32:07,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7448170121991867), ('top_5_accuracy', 0.9284714352376509))||量化: (('量化', 0.7402839810679288), ('top_5_accuracy', 0.9271381907872809))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16001it [34:19,  3.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7429535654021624), ('top_5_accuracy', 0.92819198800075))||量化: (('量化', 0.7378288856946441), ('top_5_accuracy', 0.9270670583088557))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17003it [36:39,  9.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7496029645314981), ('top_5_accuracy', 0.929533556849597))||量化: (('量化', 0.7444856184930299), ('top_5_accuracy', 0.928239515322628))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18002it [38:54,  7.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7482917615688017), ('top_5_accuracy', 0.929892783734237))||量化: (('量化', 0.743236486861841), ('top_5_accuracy', 0.9288372868173991))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19003it [40:37,  8.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7500657860112626), ('top_5_accuracy', 0.9293721383085101))||量化: (('量化', 0.7456449660544182), ('top_5_accuracy', 0.928214304510289))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20003it [42:36,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7497125143742813), ('top_5_accuracy', 0.9290035498225089))||量化: (('量化', 0.7453127343632818), ('top_5_accuracy', 0.9278536073196341))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21002it [44:57,  7.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7441074234560259), ('top_5_accuracy', 0.9260511404218846))||量化: (('量化', 0.7392505118803866), ('top_5_accuracy', 0.9249559544783582))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22002it [47:26,  9.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7413299395482024), ('top_5_accuracy', 0.9241852643061679))||量化: (('量化', 0.7368301440843598), ('top_5_accuracy', 0.9228216899231854))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23002it [49:31,  3.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7370549106560584), ('top_5_accuracy', 0.921090387374462))||量化: (('量化', 0.7328377027085778), ('top_5_accuracy', 0.9199600017390548))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24001it [51:40,  3.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7325944752301987), ('top_5_accuracy', 0.9175034373567768))||量化: (('量化', 0.728719636681805), ('top_5_accuracy', 0.9165451439523353))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25002it [53:54,  9.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7274509019639215), ('top_5_accuracy', 0.9144034238630455))||量化: (('量化', 0.7237310507579697), ('top_5_accuracy', 0.9135634574617015))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "26002it [56:01,  9.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7225875927848929), ('top_5_accuracy', 0.9120803046036691))||量化: (('量化', 0.7190108072766432), ('top_5_accuracy', 0.9112726433598708))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27002it [57:59,  9.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7200103699862967), ('top_5_accuracy', 0.9108551535128329))||量化: (('量化', 0.716306803451724), ('top_5_accuracy', 0.9098922262138439))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28001it [1:00:32,  5.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7173315238741473), ('top_5_accuracy', 0.9092175279454305))||量化: (('量化', 0.7138316488696832), ('top_5_accuracy', 0.9082175636584408))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29001it [1:02:47,  5.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7188717630426537), ('top_5_accuracy', 0.9096238060756525))||量化: (('量化', 0.7154236060825488), ('top_5_accuracy', 0.9085548774180201))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30003it [1:05:14,  9.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7153428219059365), ('top_5_accuracy', 0.9070030998966702))||量化: (('量化', 0.7119762674577514), ('top_5_accuracy', 0.9055364821172628))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31001it [1:08:07,  3.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7146866230121609), ('top_5_accuracy', 0.9054869197767814))||量化: (('量化', 0.7113964065675301), ('top_5_accuracy', 0.903841811554466))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32003it [1:10:28,  8.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7093215837005094), ('top_5_accuracy', 0.9031280272491484))||量化: (('量化', 0.7062279303771757), ('top_5_accuracy', 0.9010968407237274))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "33002it [1:12:19,  9.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7076755249840914), ('top_5_accuracy', 0.9014575315899518))||量化: (('量化', 0.7043422926577982), ('top_5_accuracy', 0.8994272900821187))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34002it [1:14:10,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7063615776006588), ('top_5_accuracy', 0.9002676391870827))||量化: (('量化', 0.702949913237846), ('top_5_accuracy', 0.8981500544101644))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "35001it [1:16:22, 10.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7044941573097911), ('top_5_accuracy', 0.8994028742035942))||量化: (('量化', 0.7011799662866776), ('top_5_accuracy', 0.8973457901202823))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "36003it [1:18:23, 10.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7038693369628621), ('top_5_accuracy', 0.8990861364962084))||量化: (('量化', 0.7008694202938808), ('top_5_accuracy', 0.8969750840254438))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "37002it [1:20:18,  6.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.7021972379124889), ('top_5_accuracy', 0.8973811518607605))||量化: (('量化', 0.6989270560255129), ('top_5_accuracy', 0.8951920218372477))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "38001it [1:23:07,  3.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.6996921133654378), ('top_5_accuracy', 0.8958974763822005))||量化: (('量化', 0.6963237809531329), ('top_5_accuracy', 0.8935554327517697))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "39002it [1:25:34,  8.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.6986487525960873), ('top_5_accuracy', 0.8945411656111382))||量化: (('量化', 0.6952642239942566), ('top_5_accuracy', 0.8922078921053306))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40001it [1:27:49,  4.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.697257568560786), ('top_5_accuracy', 0.8931526711832204))||量化: (('量化', 0.6938826529336767), ('top_5_accuracy', 0.8907527311817205))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41003it [1:29:57,  9.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.6957147386649106), ('top_5_accuracy', 0.8919294651349967))||量化: (('量化', 0.6924465256944953), ('top_5_accuracy', 0.8896368381258993))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "42002it [1:33:24,  7.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.6931977810052141), ('top_5_accuracy', 0.8900026189852622))||量化: (('量化', 0.689840718078141), ('top_5_accuracy', 0.8878121949477393))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43001it [1:36:15,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.6917048440733936), ('top_5_accuracy', 0.8890258366084509))||量化: (('量化', 0.6881002767377503), ('top_5_accuracy', 0.8868165856607986))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "44003it [1:38:18,  9.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.6905524874434672), ('top_5_accuracy', 0.8884798072771073))||量化: (('量化', 0.6870071134746938), ('top_5_accuracy', 0.8863207654371491))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "45002it [1:40:13,  9.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.6892069065131886), ('top_5_accuracy', 0.8874691673518367))||量化: (('量化', 0.6854736561409747), ('top_5_accuracy', 0.8854247683384814))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "46003it [1:42:36, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.6880719984348166), ('top_5_accuracy', 0.886785069889785))||量化: (('量化', 0.6843764265994218), ('top_5_accuracy', 0.8845242494728376))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "47003it [1:44:14,  9.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.6882619518733644), ('top_5_accuracy', 0.8871300610625306))||量化: (('量化', 0.6845811791238484), ('top_5_accuracy', 0.8850237228995128))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "48002it [1:47:09,  3.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.6899022937022146), ('top_5_accuracy', 0.8883356596737568))||量化: (('量化', 0.6861940376242162), ('top_5_accuracy', 0.8860232078498365))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "49002it [1:49:35,  9.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "浮点: (('浮点', 0.6872920960796718), ('top_5_accuracy', 0.8874308687577804))||量化: (('量化', 0.6833942164445623), ('top_5_accuracy', 0.8849411236505378))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50000it [1:51:37,  7.47it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from tvm.runtime.vm import VirtualMachine\n",
    "from tvm_book.metric.classification import Accuracy, TopKAccuracy\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    vm_exec = relay.vm.compile(run_mod, target=\"llvm\", params=params)\n",
    "vm = VirtualMachine(vm_exec, tvm.cpu())\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    qvm_exec = relay.vm.compile(qmod, target=\"llvm\", params=params)\n",
    "qvm = VirtualMachine(qvm_exec, tvm.cpu())\n",
    "\n",
    "metric_top1 = Accuracy(\"浮点\")\n",
    "metric_top5 = TopKAccuracy(top_k=5)\n",
    "qmetric_top1 = Accuracy(\"量化\")\n",
    "qmetric_top5 = TopKAccuracy(top_k=5)\n",
    "for k, (data, label) in tqdm(enumerate(dataset.valset)):\n",
    "    image = preprocess_image(data, dataset.size, dataset.mean, dataset.std)\n",
    "    images = np.expand_dims(image, 0)\n",
    "    images = images.transpose((0, 3, 1, 2))\n",
    "    input_dict = {\"data\": images}\n",
    "    output = vm.run(**input_dict).asnumpy()\n",
    "    quant_output = qvm.run(**input_dict).asnumpy()\n",
    "    label = np.array([label])\n",
    "    # 精度度量\n",
    "    metric_top1.update(preds = output, labels = label)\n",
    "    metric_top5.update(preds = output, labels = label)\n",
    "    qmetric_top1.update(preds = quant_output, labels = label)\n",
    "    qmetric_top5.update(preds = quant_output, labels = label)\n",
    "    if k % 1000 == 0:\n",
    "        print(f\"浮点: {metric_top1.get(), metric_top5.get()}||量化: {qmetric_top1.get(), qmetric_top5.get()}\")\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision.prototype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/chaos/quantize/resnet18.ipynb 单元格 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2B10.16.11.3/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/chaos/quantize/resnet18.ipynb#X26sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mprototype\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m ImageNet\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision.prototype'"
     ]
    }
   ],
   "source": [
    "from torchvision.prototype.datasets.utils import ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0+cu121'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cudagraphs', 'inductor', 'onnxrt', 'openxla', 'openxla_eval', 'tvm']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.compiler.list_backends()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41974/231343347.py:11: UserWarning: GPU is not NVIDIA V100, A100, or H100. Speedup numbers may be lower than expected.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import warnings\n",
    "\n",
    "gpu_ok = False\n",
    "if torch.cuda.is_available():\n",
    "    device_cap = torch.cuda.get_device_capability()\n",
    "    if device_cap in ((7, 0), (8, 0), (9, 0)):\n",
    "        gpu_ok = True\n",
    "\n",
    "if not gpu_ok:\n",
    "    warnings.warn(\n",
    "        \"GPU is not NVIDIA V100, A100, or H100. Speedup numbers may be lower \"\n",
    "        \"than expected.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 6)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_capability()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
