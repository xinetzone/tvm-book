{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VTA ALU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import te\n",
    "import numpy as np\n",
    "from tvm import topi\n",
    "from tvm.contrib.utils import tempdir\n",
    "\n",
    "import vta\n",
    "import vta.testing\n",
    "from vta.testing import simulator\n",
    "\n",
    "np.random.seed(0xDEADB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 13:12:35.136 INFO load_module /tmp/tmp7oy9i8lt/load_act.o\n",
      "2023-09-25 13:12:35.287 INFO load_module /tmp/tmp7oy9i8lt/load_act.o\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALU SHL execution statistics:\n",
      "\tinp_load_nbytes :                0\n",
      "\twgt_load_nbytes :                0\n",
      "\tacc_load_nbytes :             4096\n",
      "\tuop_load_nbytes :                4\n",
      "\tout_store_nbytes:             1024\n",
      "\tgemm_counter    :                0\n",
      "\talu_counter     :               64\n",
      "ALU MAX execution statistics:\n",
      "\tinp_load_nbytes :                0\n",
      "\twgt_load_nbytes :                0\n",
      "\tacc_load_nbytes :             4096\n",
      "\tuop_load_nbytes :                4\n",
      "\tout_store_nbytes:             1024\n",
      "\tgemm_counter    :                0\n",
      "\talu_counter     :               64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 13:12:35.458 INFO load_module /tmp/tmp7oy9i8lt/load_act.o\n",
      "2023-09-25 13:12:35.609 INFO load_module /tmp/tmp7oy9i8lt/load_act.o\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALU MAX execution statistics:\n",
      "\tinp_load_nbytes :                0\n",
      "\twgt_load_nbytes :                0\n",
      "\tacc_load_nbytes :             8192\n",
      "\tuop_load_nbytes :                4\n",
      "\tout_store_nbytes:             1024\n",
      "\tgemm_counter    :                0\n",
      "\talu_counter     :               64\n",
      "ALU ADD execution statistics:\n",
      "\tinp_load_nbytes :                0\n",
      "\twgt_load_nbytes :                0\n",
      "\tacc_load_nbytes :             4096\n",
      "\tuop_load_nbytes :                4\n",
      "\tout_store_nbytes:             1024\n",
      "\tgemm_counter    :                0\n",
      "\talu_counter     :               64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 13:12:35.780 INFO load_module /tmp/tmp7oy9i8lt/load_act.o\n",
      "2023-09-25 13:12:35.933 INFO load_module /tmp/tmp7oy9i8lt/load_act.o\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALU ADD execution statistics:\n",
      "\tinp_load_nbytes :                0\n",
      "\twgt_load_nbytes :                0\n",
      "\tacc_load_nbytes :             8192\n",
      "\tuop_load_nbytes :                4\n",
      "\tout_store_nbytes:             1024\n",
      "\tgemm_counter    :                0\n",
      "\talu_counter     :               64\n",
      "ALU SHR execution statistics:\n",
      "\tinp_load_nbytes :                0\n",
      "\twgt_load_nbytes :                0\n",
      "\tacc_load_nbytes :             4096\n",
      "\tuop_load_nbytes :                4\n",
      "\tout_store_nbytes:             1024\n",
      "\tgemm_counter    :                0\n",
      "\talu_counter     :               64\n"
     ]
    }
   ],
   "source": [
    "def _run(env, remote):\n",
    "    def check_alu(tvm_op, np_op=None, use_imm=False, test_name=None):\n",
    "        \"\"\"Test ALU\"\"\"\n",
    "        m = 8\n",
    "        n = 8\n",
    "        imm = np.random.randint(1, 5)\n",
    "        # compute\n",
    "        a = te.placeholder((m, n, env.BATCH, env.BLOCK_OUT), name=\"a\", dtype=env.acc_dtype)\n",
    "        a_buf = te.compute(\n",
    "            (m, n, env.BATCH, env.BLOCK_OUT), lambda *i: a(*i), \"a_buf\"\n",
    "        )  # DRAM->SRAM\n",
    "        if use_imm:\n",
    "            res_buf = te.compute(\n",
    "                (m, n, env.BATCH, env.BLOCK_OUT), lambda *i: tvm_op(a_buf(*i), imm), \"res_buf\"\n",
    "            )  # compute\n",
    "        else:\n",
    "            b = te.placeholder((m, n, env.BATCH, env.BLOCK_OUT), name=\"b\", dtype=env.acc_dtype)\n",
    "            b_buf = te.compute(\n",
    "                (m, n, env.BATCH, env.BLOCK_OUT), lambda *i: b(*i), \"b_buf\"\n",
    "            )  # DRAM->SRAM\n",
    "            res_buf = te.compute(\n",
    "                (m, n, env.BATCH, env.BLOCK_OUT),\n",
    "                lambda *i: tvm_op(a_buf(*i), b_buf(*i)),\n",
    "                \"res_buf\",\n",
    "            )  # compute5B\n",
    "        res = te.compute(\n",
    "            (m, n, env.BATCH, env.BLOCK_OUT),\n",
    "            lambda *i: res_buf(*i).astype(env.inp_dtype),\n",
    "            \"res\",\n",
    "        )  # SRAM->DRAM\n",
    "        # schedule\n",
    "        s = te.create_schedule(res.op)\n",
    "        s[a_buf].set_scope(env.acc_scope)  # SRAM\n",
    "        s[a_buf].pragma(a_buf.op.axis[0], env.dma_copy)  # DRAM->SRAM\n",
    "        s[res_buf].set_scope(env.acc_scope)  # SRAM\n",
    "        s[res_buf].pragma(res_buf.op.axis[0], env.alu)  # compute\n",
    "        s[res].pragma(res.op.axis[0], env.dma_copy)  # SRAM->DRAM\n",
    "        if not use_imm:\n",
    "            s[b_buf].set_scope(env.acc_scope)  # SRAM\n",
    "            s[b_buf].pragma(b_buf.op.axis[0], env.dma_copy)  # DRAM->SRAM\n",
    "\n",
    "        if not remote:\n",
    "            return\n",
    "\n",
    "        # build\n",
    "        with vta.build_config():\n",
    "            if use_imm:\n",
    "                mod = vta.build(s, [a, res], tvm.target.Target(\"ext_dev\", host=env.target_host))\n",
    "            else:\n",
    "                mod = vta.build(\n",
    "                    s, [a, b, res], tvm.target.Target(\"ext_dev\", host=env.target_host)\n",
    "                )\n",
    "        temp = tempdir()\n",
    "        mod.save(temp.relpath(\"load_act.o\"))\n",
    "        remote.upload(temp.relpath(\"load_act.o\"))\n",
    "        f = remote.load_module(\"load_act.o\")\n",
    "        # verify\n",
    "        dev = remote.ext_dev(0)\n",
    "        a_np = np.random.randint(-16, 16, size=(m, n, env.BATCH, env.BLOCK_OUT)).astype(a.dtype)\n",
    "        if use_imm:\n",
    "            res_np = np_op(a_np, imm) if np_op else tvm_op(a_np, imm)\n",
    "        else:\n",
    "            b_np = np.random.randint(-16, 16, size=(m, n, env.BATCH, env.BLOCK_OUT)).astype(\n",
    "                b.dtype\n",
    "            )\n",
    "            res_np = np_op(a_np, b_np) if np_op else tvm_op(a_np, b_np)\n",
    "        res_np = res_np.astype(res.dtype)\n",
    "        a_nd = tvm.nd.array(a_np, dev)\n",
    "        res_nd = tvm.nd.array(np.zeros((m, n, env.BATCH, env.BLOCK_OUT)).astype(res.dtype), dev)\n",
    "\n",
    "        if env.TARGET in [\"sim\", \"tsim\"]:\n",
    "            simulator.clear_stats()\n",
    "\n",
    "        if use_imm:\n",
    "            f(a_nd, res_nd)\n",
    "        else:\n",
    "            b_nd = tvm.nd.array(b_np, dev)\n",
    "            f(a_nd, b_nd, res_nd)\n",
    "\n",
    "        np.testing.assert_equal(res_np, res_nd.numpy())\n",
    "\n",
    "        if env.TARGET in [\"sim\", \"tsim\"]:\n",
    "            sim_stats = simulator.stats()\n",
    "            print(\"ALU {} execution statistics:\".format(test_name))\n",
    "            for k, v in sim_stats.items():\n",
    "                print(\"\\t{:<16}: {:>16}\".format(k, v))\n",
    "\n",
    "    check_alu(lambda x, y: x << y, np.left_shift, use_imm=True, test_name=\"SHL\")\n",
    "    check_alu(tvm.te.max, np.maximum, use_imm=True, test_name=\"MAX\")\n",
    "    check_alu(tvm.te.max, np.maximum, test_name=\"MAX\")\n",
    "    check_alu(lambda x, y: x + y, use_imm=True, test_name=\"ADD\")\n",
    "    check_alu(lambda x, y: x + y, test_name=\"ADD\")\n",
    "    check_alu(lambda x, y: x >> y, np.right_shift, use_imm=True, test_name=\"SHR\")\n",
    "\n",
    "vta.testing.run(_run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
