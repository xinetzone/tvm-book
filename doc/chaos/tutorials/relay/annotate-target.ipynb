{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 注解目标设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "import tvm\n",
    "import tvm.relay.testing\n",
    "from tvm.relay import transform\n",
    "from tvm import relay\n",
    "from tvm import runtime\n",
    "from tvm.contrib import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注解 DNNL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotated(dtype, ishape, w1shape):\n",
    "    data = relay.var(\"data\", shape=(ishape), dtype=dtype)\n",
    "    weight1 = relay.var(\"weight1\", shape=(w1shape), dtype=dtype)\n",
    "    depthwise_conv2d_1 = relay.nn.conv2d(\n",
    "        data, weight1, kernel_size=(3, 3), padding=(1, 1), groups=32\n",
    "    )\n",
    "    depthwise_conv2d_2 = relay.nn.conv2d(\n",
    "        depthwise_conv2d_1, weight1, kernel_size=(3, 3), padding=(1, 1), groups=32\n",
    "    )\n",
    "    out = relay.add(depthwise_conv2d_1, depthwise_conv2d_2)\n",
    "\n",
    "    f = relay.Function([data, weight1], out)\n",
    "\n",
    "    mod = tvm.IRModule.from_expr(f)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%data: Tensor[(1, 32, 14, 14), float32] /* ty=Tensor[(1, 32, 14, 14), float32] */, %weight1: Tensor[(32, 1, 3, 3), float32] /* ty=Tensor[(32, 1, 3, 3), float32] */) -> Tensor[(1, 32, 14, 14), float32] {\n",
      "  %0 = @tvmgen_default_dnnl_main_0(%data, %weight1) /* ty=Tensor[(1, 32, 14, 14), float32] */;\n",
      "  %1 = @tvmgen_default_dnnl_main_3(%0, %weight1) /* ty=Tensor[(1, 32, 14, 14), float32] */;\n",
      "  @tvmgen_default_dnnl_main_2(%0, %1) /* ty=Tensor[(1, 32, 14, 14), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_dnnl_main_0(%dnnl_0_i0: Tensor[(1, 32, 14, 14), float32] /* ty=Tensor[(1, 32, 14, 14), float32] */, %dnnl_0_i1: Tensor[(32, 1, 3, 3), float32] /* ty=Tensor[(32, 1, 3, 3), float32] */, Compiler=\"dnnl\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_dnnl_main_0\") -> Tensor[(1, 32, 14, 14), float32] {\n",
      "  nn.conv2d(%dnnl_0_i0, %dnnl_0_i1, padding=[1, 1, 1, 1], groups=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 14, 14), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_dnnl_main_2(%dnnl_2_i0: Tensor[(1, 32, 14, 14), float32] /* ty=Tensor[(1, 32, 14, 14), float32] */, %dnnl_2_i1: Tensor[(1, 32, 14, 14), float32] /* ty=Tensor[(1, 32, 14, 14), float32] */, Compiler=\"dnnl\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_dnnl_main_2\") -> Tensor[(1, 32, 14, 14), float32] {\n",
      "  add(%dnnl_2_i0, %dnnl_2_i1) /* ty=Tensor[(1, 32, 14, 14), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_dnnl_main_3(%dnnl_3_i0: Tensor[(1, 32, 14, 14), float32] /* ty=Tensor[(1, 32, 14, 14), float32] */, %dnnl_3_i1: Tensor[(32, 1, 3, 3), float32] /* ty=Tensor[(32, 1, 3, 3), float32] */, Compiler=\"dnnl\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_dnnl_main_3\") -> Tensor[(1, 32, 14, 14), float32] {\n",
      "  nn.conv2d(%dnnl_3_i0, %dnnl_3_i1, padding=[1, 1, 1, 1], groups=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 14, 14), float32] */\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtype = \"float32\"\n",
    "ishape = (1, 32, 14, 14)\n",
    "w1shape = (32, 1, 3, 3)\n",
    "\n",
    "mod = annotated(dtype, ishape, w1shape)\n",
    "mod = transform.AnnotateTarget(\"dnnl\")(mod)\n",
    "mod = relay.transform.InferType()(mod)\n",
    "mod = transform.PartitionGraph()(mod)\n",
    "print(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注解多后端设备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.ir.register_op_attr(\"nn.relu\", \"target.test\")\n",
    "def relu(expr):  # pylint: disable=unused-variable\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%x: Tensor[(10, 10), float32] /* ty=Tensor[(10, 10), float32] */) -> Tensor[(10, 10), float32] {\n",
      "  %0 = annotation.compiler_begin(%x, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %1 = nn.relu(%0) /* ty=Tensor[(10, 10), float32] */;\n",
      "  %2 = annotation.compiler_end(%1, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %3 = annotation.compiler_begin(%2, compiler=\"default\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %4 = abs(%3) /* ty=Tensor[(10, 10), float32] */;\n",
      "  %5 = annotation.compiler_end(%4, compiler=\"default\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %6 = annotation.compiler_end(%1, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %7 = annotation.compiler_begin(%6, compiler=\"default\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %8 = abs(%7) /* ty=Tensor[(10, 10), float32] */;\n",
      "  %9 = annotation.compiler_end(%8, compiler=\"default\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %10 = annotation.compiler_begin(%5, compiler=\"default\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %11 = annotation.compiler_begin(%9, compiler=\"default\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %12 = add(%10, %11) /* ty=Tensor[(10, 10), float32] */;\n",
      "  annotation.compiler_end(%12, compiler=\"default\") /* ty=Tensor[(10, 10), float32] */\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def before():\n",
    "    x = relay.var(\"x\", shape=(10, 10))\n",
    "    r = relay.nn.relu(x)\n",
    "    a_1 = relay.abs(r)\n",
    "    a_2 = relay.abs(r)\n",
    "    out = relay.add(a_1, a_2)\n",
    "    f = relay.Function([x], out)\n",
    "    return tvm.IRModule.from_expr(f)\n",
    "\n",
    "result = transform.AnnotateTarget(\"test\")(before())\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "def @main(%x: Tensor[(10, 10), float32] /* ty=Tensor[(10, 10), float32] */) -> Tensor[(10, 10), float32] {\n",
       "  %0 = annotation.compiler_begin(%x, compiler=\"test_type_propagation\") /* ty=Tensor[(10, 10), float32] */;\n",
       "  %1 = nn.relu(%0) /* ty=Tensor[(10, 10), float32] */;\n",
       "  %2 = annotation.compiler_end(%1, compiler=\"test_type_propagation\") /* ty=Tensor[(10, 10), float32] */;\n",
       "  %3 = annotation.compiler_begin(%2, compiler=\"test_type_propagation\") /* ty=Tensor[(10, 10), float32] */;\n",
       "  %4 = nn.relu(%3) /* ty=Tensor[(10, 10), float32] */;\n",
       "  annotation.compiler_end(%4, compiler=\"test_type_propagation\") /* ty=Tensor[(10, 10), float32] */\n",
       "}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = \"test_type_propagation\"\n",
    "\n",
    "@tvm.ir.register_op_attr(\"nn.relu\", \"target.\" + target)\n",
    "def relu(expr):  # pylint: disable=unused-variable\n",
    "    return expr.args[0].checked_type.dtype == \"float32\"\n",
    "\n",
    "def before():\n",
    "    x = relay.var(\"x\", shape=(10, 10))\n",
    "    r = relay.nn.relu(x)\n",
    "    out = relay.nn.relu(r)\n",
    "    f = relay.Function([x], out)\n",
    "    mod = tvm.IRModule.from_expr(f)\n",
    "    return mod\n",
    "    \n",
    "res = transform.AnnotateTarget(target, True)(before())\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read & write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "def @main() -> () {\n",
       "  %0 = annotation.compiler_begin(1f /* ty=float32 */, compiler=\"default\") /* ty=float32 */;\n",
       "  %1 = ref(%0);\n",
       "  %2 = annotation.compiler_end(%1, compiler=\"default\") /* ty=ref(float32) */;\n",
       "  %3 = annotation.compiler_begin(%2, compiler=\"default\") /* ty=ref(float32) */;\n",
       "  %4 = annotation.compiler_end(%1, compiler=\"default\") /* ty=ref(float32) */;\n",
       "  %5 = annotation.compiler_begin(%4, compiler=\"default\") /* ty=ref(float32) */;\n",
       "  %6 = ref_read(%5);\n",
       "  %7 = annotation.compiler_end(%6, compiler=\"default\") /* ty=float32 */;\n",
       "  %8 = annotation.compiler_begin(%7, compiler=\"relu\") /* ty=float32 */;\n",
       "  %9 = nn.relu(%8) /* ty=float32 */;\n",
       "  %10 = annotation.compiler_end(%9, compiler=\"relu\") /* ty=float32 */;\n",
       "  %11 = annotation.compiler_begin(%10, compiler=\"default\") /* ty=float32 */;\n",
       "  %12 = ref_write(%3, %11);\n",
       "  annotation.compiler_end(%12, compiler=\"default\") /* ty=() */\n",
       "}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = \"relu\"\n",
    "\n",
    "@tvm.ir.register_op_attr(\"nn.relu\", \"target.\" + target)\n",
    "def annotate(expr):\n",
    "    return True\n",
    "\n",
    "def before():\n",
    "    ref = relay.expr.RefCreate(relay.const(1.0))\n",
    "    r = relay.expr.RefWrite(ref, relay.nn.relu(relay.expr.RefRead(ref)))\n",
    "    return tvm.IRModule.from_expr(r)\n",
    "\n",
    "def after(annotate_non_call_ops):\n",
    "        co = relay.const(1.0)\n",
    "        if annotate_non_call_ops:\n",
    "            co = relay.annotation.compiler_begin(co, \"default\")\n",
    "\n",
    "        ref = relay.expr.RefCreate(co)\n",
    "        ref1 = ref\n",
    "        if annotate_non_call_ops:\n",
    "            ref = relay.annotation.compiler_end(ref, \"default\")\n",
    "            ref = relay.annotation.compiler_begin(ref, \"default\")\n",
    "            ref1 = relay.annotation.compiler_end(ref1, \"default\")\n",
    "            ref1 = relay.annotation.compiler_begin(ref1, \"default\")\n",
    "\n",
    "        read = relay.expr.RefRead(ref1)\n",
    "        if annotate_non_call_ops:\n",
    "            read = relay.annotation.compiler_end(read, \"default\")\n",
    "\n",
    "        beg = relay.annotation.compiler_begin(read, target)\n",
    "        relu = relay.nn.relu(beg)\n",
    "        end = relay.annotation.compiler_end(relu, target)\n",
    "\n",
    "        if annotate_non_call_ops:\n",
    "            end = relay.annotation.compiler_begin(end, \"default\")\n",
    "\n",
    "        r = relay.expr.RefWrite(ref, end)\n",
    "\n",
    "        if annotate_non_call_ops:\n",
    "            r = relay.annotation.compiler_end(r, \"default\")\n",
    "        return tvm.IRModule.from_expr(r)\n",
    "\n",
    "\n",
    "result = transform.AnnotateTarget(target)(before())\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "def @main() -> () {\n",
       "  %0 = ref(1f /* ty=float32 */);\n",
       "  %1 = ref_read(%0);\n",
       "  %2 = annotation.compiler_begin(%1, compiler=\"relu\") /* ty=float32 */;\n",
       "  %3 = nn.relu(%2) /* ty=float32 */;\n",
       "  %4 = annotation.compiler_end(%3, compiler=\"relu\") /* ty=float32 */;\n",
       "  ref_write(%0, %4)\n",
       "}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = transform.AnnotateTarget(target, False)(before())\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"test_tuple\"\n",
    "\n",
    "@tvm.ir.register_op_attr(\"nn.relu\", \"target.\" + target)\n",
    "def relu(expr):  # pylint: disable=unused-variable\n",
    "    return True\n",
    "\n",
    "@tvm.ir.register_op_attr(\"concatenate\", \"target.\" + target)\n",
    "def concatenate(expr):  # pylint: disable=unused-variable\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def before():\n",
    "    x = relay.var(\"x\", shape=(10, 5))\n",
    "    y = relay.var(\"y\", shape=(10, 5))\n",
    "    a_1 = relay.nn.relu(x)\n",
    "    a_2 = relay.nn.relu(y)\n",
    "    out = relay.concatenate((a_1, a_2), axis=1)\n",
    "    f = relay.Function([x, y], out)\n",
    "    mod = tvm.IRModule.from_expr(f)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def after(annotate_non_call_ops):\n",
    "    x = relay.var(\"x\", shape=(10, 5))\n",
    "    y = relay.var(\"y\", shape=(10, 5))\n",
    "    cb_1 = relay.annotation.compiler_begin(x, target)\n",
    "    cb_2 = relay.annotation.compiler_begin(y, target)\n",
    "    a_1 = relay.nn.relu(cb_1)\n",
    "    a_2 = relay.nn.relu(cb_2)\n",
    "    ce_1 = relay.annotation.compiler_end(a_1, target)\n",
    "    ce_2 = relay.annotation.compiler_end(a_2, target)\n",
    "\n",
    "    if annotate_non_call_ops:\n",
    "        cb_3 = relay.annotation.compiler_begin(ce_1, target)\n",
    "        cb_4 = relay.annotation.compiler_begin(ce_2, target)\n",
    "        tup = relay.Tuple([cb_3, cb_4])\n",
    "        ce_3 = relay.annotation.compiler_end(tup, target)\n",
    "    else:\n",
    "        ce_3 = relay.Tuple([ce_1, ce_2])\n",
    "\n",
    "    cb_3 = relay.annotation.compiler_begin(ce_3, target)\n",
    "    out = relay.op._make.concatenate(cb_3, 1)\n",
    "    ce_4 = relay.annotation.compiler_end(out, target)\n",
    "    f = relay.Function([x, y], ce_4)\n",
    "    mod = tvm.IRModule.from_expr(f)\n",
    "    return mod\n",
    "\n",
    "for annotate_non_call_ops in [False, True]:\n",
    "    result = transform.AnnotateTarget(target, annotate_non_call_ops)(before())\n",
    "    expected = transform.InferType()(after(annotate_non_call_ops))\n",
    "    assert tvm.ir.structural_equal(expected, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## composite_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def before():\n",
    "    a = relay.var(\"a\", shape=(10, 10))\n",
    "    b = relay.var(\"b\", shape=(10, 10))\n",
    "\n",
    "    # add_relu function\n",
    "    in_1 = relay.var(\"in_1\", shape=(10, 10))\n",
    "    in_2 = relay.var(\"in_2\", shape=(10, 10))\n",
    "    add_node = relay.add(in_1, in_2)\n",
    "    relu_node = relay.nn.relu(add_node)\n",
    "    add_relu = relay.Function([in_1, in_2], relu_node)\n",
    "    add_relu = add_relu.with_attr(\"Composite\", \"test.add_relu\")\n",
    "\n",
    "    # merged function\n",
    "    r = relay.Call(add_relu, [a, b])\n",
    "    f = relay.Function([a, b], r)\n",
    "    mod = tvm.IRModule.from_expr(f)\n",
    "    return mod\n",
    "\n",
    "def after():\n",
    "    a = relay.var(\"a\", shape=(10, 10))\n",
    "    b = relay.var(\"b\", shape=(10, 10))\n",
    "\n",
    "    # add_relu function\n",
    "    in_1 = relay.var(\"in_1\", shape=(10, 10))\n",
    "    in_2 = relay.var(\"in_2\", shape=(10, 10))\n",
    "    add_node = relay.add(in_1, in_2)\n",
    "    relu_node = relay.nn.relu(add_node)\n",
    "    add_relu = relay.Function([in_1, in_2], relu_node)\n",
    "    add_relu = add_relu.with_attr(\"Composite\", \"test.add_relu\")\n",
    "\n",
    "    # merged function\n",
    "    cb_1 = relay.annotation.compiler_begin(a, \"test\")\n",
    "    cb_2 = relay.annotation.compiler_begin(b, \"test\")\n",
    "    r = relay.Call(add_relu, [cb_1, cb_2])\n",
    "    ce_1 = relay.annotation.compiler_end(r, \"test\")\n",
    "    f = relay.Function([a, b], ce_1)\n",
    "    mod = tvm.IRModule.from_expr(f)\n",
    "    return mod\n",
    "\n",
    "result = transform.AnnotateTarget(\"test\")(before())\n",
    "expected = transform.InferType()(after())\n",
    "assert tvm.ir.structural_equal(expected, result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## double_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.ir.register_op_attr(\"nn.relu\", \"target.double.A\")\n",
    "def relu(expr):  # pylint: disable=unused-variable\n",
    "    return True\n",
    "\n",
    "def before():\n",
    "    x = relay.var(\"x\", shape=(10, 5))\n",
    "    a_1 = relay.nn.relu(x)\n",
    "    mod = tvm.IRModule.from_expr(a_1)\n",
    "    return mod\n",
    "\n",
    "for annotate_non_call_ops in [True, False]:\n",
    "    mod = before()\n",
    "    mod1 = transform.AnnotateTarget(\"double.A\", annotate_non_call_ops)(mod)\n",
    "    mod2 = transform.AnnotateTarget(\"double.A\", annotate_non_call_ops)(mod1)\n",
    "    assert tvm.ir.structural_equal(mod1, mod2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## different_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.ir.register_op_attr(\"nn.relu\", \"target.different.A\")\n",
    "def relu(expr):  # pylint: disable=unused-variable\n",
    "    return True\n",
    "\n",
    "@tvm.ir.register_op_attr(\"add\", \"target.different.B\")\n",
    "def relu(expr):  # pylint: disable=unused-variable\n",
    "    return True\n",
    "\n",
    "def before():\n",
    "    x = relay.var(\"x\", shape=(10, 5))\n",
    "    a_1 = relay.nn.relu(x)\n",
    "    b_1 = relay.add(a_1, a_1)\n",
    "    mod = tvm.IRModule.from_expr(b_1)\n",
    "    return mod\n",
    "\n",
    "for annotate_non_call_ops in [True, False]:\n",
    "    mod = before()\n",
    "    mod1 = transform.AnnotateTarget(\"different.A\", annotate_non_call_ops)(mod)\n",
    "    mod1 = transform.AnnotateTarget(\"different.B\", annotate_non_call_ops)(mod1)\n",
    "    mod2 = transform.AnnotateTarget([\"different.A\", \"different.B\"], annotate_non_call_ops)(mod)\n",
    "    assert tvm.ir.structural_equal(mod1, mod2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiple_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.ir.register_op_attr(\"nn.relu\", \"target.A\")\n",
    "def relu(expr):  # pylint: disable=unused-variable\n",
    "    return True\n",
    "\n",
    "@tvm.ir.register_op_attr(\"add\", \"target.B\")\n",
    "def add(expr):  # pylint: disable=unused-variable\n",
    "    return True\n",
    "\n",
    "def before():\n",
    "    x = relay.var(\"x\", shape=(10, 5))\n",
    "    a_1 = relay.nn.relu(x)\n",
    "    a_2 = relay.abs(a_1)\n",
    "    a_3 = relay.nn.relu(a_1)\n",
    "    out = relay.add(a_2, a_3)\n",
    "\n",
    "    f = relay.Function([x], out)\n",
    "    mod = tvm.IRModule.from_expr(f)\n",
    "    return mod\n",
    "\n",
    "for annotate_non_call_ops in [True, False]:\n",
    "    mod = transform.AnnotateTarget(\"A\", annotate_non_call_ops)(before())\n",
    "    mod = transform.AnnotateTarget(\"B\", annotate_non_call_ops)(mod)\n",
    "    expected = transform.AnnotateTarget([\"A\", \"B\"], annotate_non_call_ops)(before())\n",
    "    assert tvm.ir.structural_equal(expected, mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ends_with_tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "trgt = \"clip\"\n",
    "\n",
    "@tvm.ir.register_op_attr(\"clip\", \"target.\" + trgt)\n",
    "def relu(expr):  # pylint: disable=unused-variable\n",
    "    return True\n",
    "\n",
    "def get_model(get_item):\n",
    "    \"\"\"Return a model\"\"\"\n",
    "    a = relay.var(\"a\", shape=(1, 16, 16, 4), dtype=\"uint8\")\n",
    "    z = relay.op.clip(a, 0, 255)\n",
    "    b = relay.op.clip(z, 0, 15)\n",
    "    c = relay.op.clip(z, 16, 31)\n",
    "    t = relay.Tuple((c, b))\n",
    "    tgi = relay.TupleGetItem(t, 1) if get_item else t\n",
    "    foo = relay.Function([a], tgi)\n",
    "    return tvm.IRModule.from_expr(tgi)\n",
    "\n",
    "def get_expected(annotate_non_call_ops, get_item):\n",
    "    a_ = relay.var(\"a\", shape=(1, 16, 16, 4), dtype=\"uint8\")\n",
    "    a = relay.annotation.compiler_begin(a_, trgt)\n",
    "    z = relay.op.clip(a, 0, 255)\n",
    "    z1 = relay.annotation.compiler_end(z, trgt)\n",
    "    z1 = relay.annotation.compiler_begin(z1, trgt)\n",
    "    b = relay.op.clip(z1, 0, 15)\n",
    "    b = relay.annotation.compiler_end(b, trgt)\n",
    "    b = relay.annotation.compiler_begin(b, trgt) if annotate_non_call_ops else b\n",
    "    z2 = relay.annotation.compiler_end(z, trgt)\n",
    "    z2 = relay.annotation.compiler_begin(z2, trgt)\n",
    "    c = relay.op.clip(z2, 16, 31)\n",
    "    c = relay.annotation.compiler_end(c, trgt)\n",
    "    c = relay.annotation.compiler_begin(c, trgt) if annotate_non_call_ops else c\n",
    "    t = relay.Tuple((c, b))\n",
    "    t = relay.annotation.compiler_end(t, trgt) if annotate_non_call_ops else t\n",
    "    if get_item:\n",
    "        t = relay.annotation.compiler_begin(t, trgt) if annotate_non_call_ops else t\n",
    "        tgi = relay.TupleGetItem(t, 1)\n",
    "        tgi = relay.annotation.compiler_end(tgi, trgt) if annotate_non_call_ops else tgi\n",
    "    else:\n",
    "        tgi = t\n",
    "    foo = relay.Function([a_], tgi)\n",
    "    return tvm.IRModule.from_expr(foo)\n",
    "\n",
    "for get_item in [True, False]:\n",
    "    for annotate_non_call_ops in [False, True]:\n",
    "        mod = get_model(get_item)\n",
    "        mod = transform.AnnotateTarget(\"clip\", annotate_non_call_ops)(mod)\n",
    "        expected = transform.InferType()(get_expected(annotate_non_call_ops, get_item))\n",
    "        assert tvm.ir.structural_equal(expected, mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注解目标-其他"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_if_else():\n",
    "    target = \"test_if_else\"\n",
    "\n",
    "    @tvm.ir.register_op_attr(\"equal\", \"target.\" + target)\n",
    "    def relu(expr):  # pylint: disable=unused-variable\n",
    "        return True\n",
    "\n",
    "    @tvm.ir.register_op_attr(\"tanh\", \"target.\" + target)\n",
    "    def tanh(expr):  # pylint: disable=unused-variable\n",
    "        return True\n",
    "\n",
    "    @tvm.ir.register_op_attr(\"sigmoid\", \"target.\" + target)\n",
    "    def sigmoid(expr):  # pylint: disable=unused-variable\n",
    "        return True\n",
    "\n",
    "    @tvm.ir.register_op_attr(\"erf\", \"target.\" + target)\n",
    "    def erf(expr):  # pylint: disable=unused-variable\n",
    "        return True\n",
    "\n",
    "    \"\"\"Test that If-else nodes compiles correctly when surrounded by supported nodes.\"\"\"\n",
    "\n",
    "    def before():\n",
    "        data = relay.var(\"data\", shape=(1, 32))\n",
    "        eq1 = relay.var(\"e1\", shape=[], dtype=\"float32\")\n",
    "        eq2 = relay.var(\"e2\", shape=[], dtype=\"float32\")\n",
    "        eq = relay.equal(eq1, eq2)\n",
    "\n",
    "        true_branch = relay.tanh(data)\n",
    "        false_branch = relay.sigmoid(data)\n",
    "        ife = relay.If(eq, true_branch, false_branch)\n",
    "        out = relay.erf(ife)\n",
    "        func = relay.Function([data, eq1, eq2], out)\n",
    "        mod = tvm.IRModule.from_expr(func)\n",
    "\n",
    "        return mod\n",
    "\n",
    "    def after():\n",
    "\n",
    "        data = relay.var(\"data\", shape=(1, 32))\n",
    "        eq1 = relay.var(\"e1\", shape=[], dtype=\"float32\")\n",
    "        eq2 = relay.var(\"e2\", shape=[], dtype=\"float32\")\n",
    "\n",
    "        cb_1 = relay.annotation.compiler_begin(eq1, target)\n",
    "        cb_2 = relay.annotation.compiler_begin(eq2, target)\n",
    "\n",
    "        equality_condition = relay.equal(cb_1, cb_2)\n",
    "        ce_1 = relay.annotation.compiler_end(equality_condition, target)\n",
    "\n",
    "        # if condition\n",
    "        cb_3 = relay.annotation.compiler_begin(data, target)\n",
    "        true_branch = relay.tanh(cb_3)\n",
    "        ce_2 = relay.annotation.compiler_end(true_branch, target)\n",
    "\n",
    "        # else condition\n",
    "        cb_4 = relay.annotation.compiler_begin(data, target)\n",
    "        false_branch = relay.sigmoid(cb_4)\n",
    "        ce_3 = relay.annotation.compiler_end(false_branch, target)\n",
    "\n",
    "        if_condition = relay.If(ce_1, ce_2, ce_3)\n",
    "        cb_5 = relay.annotation.compiler_begin(if_condition, target)\n",
    "        erf_out = relay.erf(cb_5)\n",
    "        ce_4 = relay.annotation.compiler_end(erf_out, target)\n",
    "        func = relay.Function([data, eq1, eq2], ce_4)\n",
    "        mod = tvm.IRModule.from_expr(func)\n",
    "        return mod\n",
    "\n",
    "    expected = transform.InferType()(after())\n",
    "    for annotate_non_call_ops in [True, False]:\n",
    "        result = transform.AnnotateTarget(target, annotate_non_call_ops)(before())\n",
    "        assert tvm.ir.structural_equal(expected, result)\n",
    "\n",
    "\n",
    "def test_while_let():\n",
    "    target = \"test_while_let\"\n",
    "\n",
    "    @tvm.ir.register_op_attr(\"less\", \"target.\" + target)\n",
    "    def less(expr):  # pylint: disable=unused-variable\n",
    "        return True\n",
    "\n",
    "    @tvm.ir.register_op_attr(\"add\", \"target.\" + target)\n",
    "    def add(expr):  # pylint: disable=unused-variable\n",
    "        return True\n",
    "\n",
    "    @tvm.ir.register_op_attr(\"zeros_like\", \"target.\" + target)\n",
    "    def zeros_like(expr):  # pylint: disable=unused-variable\n",
    "        return True\n",
    "\n",
    "    \"\"\"Test that let nodes compiles correctly when surrounded by other nodes.\"\"\"\n",
    "\n",
    "    def before():\n",
    "\n",
    "        var1 = relay.var(\"var1\", shape=(2,))\n",
    "        var2 = relay.var(\"var2\", shape=(), dtype=\"int32\")\n",
    "        var3 = relay.var(\"var3\", shape=(2,))\n",
    "        cond = relay.less(var2, relay.const(10, dtype=\"int32\"))\n",
    "\n",
    "        loop = relay.var(\"while_loop\")\n",
    "        ii = var2 + relay.const(1, dtype=\"int32\")\n",
    "        ss = var3 + var1\n",
    "        true_branch = loop(ii, ss)\n",
    "        ife = relay.If(cond, true_branch, var3)\n",
    "        func_1 = relay.Function([var2, var3], ife)\n",
    "\n",
    "        ret = relay.Let(loop, func_1, loop(relay.const(0, dtype=\"int32\"), relay.zeros_like(var1)))\n",
    "        func_2 = relay.Function([var1], ret)\n",
    "        mod = tvm.IRModule.from_expr(func_2)\n",
    "        return mod\n",
    "\n",
    "    def after(annotate_non_call_ops):\n",
    "        var1 = relay.var(\"var1\", shape=(2,))\n",
    "        var2 = relay.var(\"var2\", shape=(), dtype=\"int32\")\n",
    "        var3 = relay.var(\"var3\", shape=(2,))\n",
    "        var4 = relay.const(10, dtype=\"int32\")\n",
    "\n",
    "        cb_1 = relay.annotation.compiler_begin(var2, target)\n",
    "        cb_2 = relay.annotation.compiler_begin(var4, target)\n",
    "\n",
    "        less_condition = relay.less(cb_1, cb_2)\n",
    "        ce_1 = relay.annotation.compiler_end(less_condition, target)\n",
    "\n",
    "        loop = relay.var(\"while_loop\")\n",
    "\n",
    "        # if condition\n",
    "        cb_3 = relay.annotation.compiler_begin(var2, target)\n",
    "        cb_4 = relay.annotation.compiler_begin(relay.const(1, dtype=\"int32\"), target)\n",
    "        add_op_1 = relay.add(cb_3, cb_4)\n",
    "        ce_2 = relay.annotation.compiler_end(add_op_1, target)\n",
    "\n",
    "        cb_5 = relay.annotation.compiler_begin(ce_2, \"default\") if annotate_non_call_ops else ce_2\n",
    "\n",
    "        cb_6 = relay.annotation.compiler_begin(var3, target)\n",
    "        cb_7 = relay.annotation.compiler_begin(var1, target)\n",
    "        add_op_2 = relay.add(cb_6, cb_7)\n",
    "        ce_3 = relay.annotation.compiler_end(add_op_2, target)\n",
    "\n",
    "        cb_8 = relay.annotation.compiler_begin(ce_3, \"default\") if annotate_non_call_ops else ce_3\n",
    "\n",
    "        true_branch = loop(cb_5, cb_8)  # while loop\n",
    "        ce_4 = (\n",
    "            relay.annotation.compiler_end(true_branch, \"default\")\n",
    "            if annotate_non_call_ops\n",
    "            else true_branch\n",
    "        )\n",
    "        if_condition = relay.If(ce_1, ce_4, var3)\n",
    "        const_1 = relay.const(0, dtype=\"int32\")\n",
    "        cb_9 = (\n",
    "            relay.annotation.compiler_begin(const_1, \"default\")\n",
    "            if annotate_non_call_ops\n",
    "            else const_1\n",
    "        )\n",
    "        cb_10 = relay.annotation.compiler_begin(var1, target)\n",
    "        zeros_like = relay.zeros_like(cb_10)\n",
    "        ce_5 = relay.annotation.compiler_end(zeros_like, target)\n",
    "        cb_11 = relay.annotation.compiler_begin(ce_5, \"default\") if annotate_non_call_ops else ce_5\n",
    "        while_condition = loop(cb_9, cb_11)\n",
    "        ce_6 = (\n",
    "            relay.annotation.compiler_end(while_condition, \"default\")\n",
    "            if annotate_non_call_ops\n",
    "            else while_condition\n",
    "        )\n",
    "\n",
    "        func_1 = relay.Function([var2, var3], if_condition)\n",
    "        ret = relay.Let(loop, func_1, ce_6)\n",
    "        func_2 = relay.Function([var1], ret)\n",
    "        mod = tvm.IRModule.from_expr(func_2)\n",
    "        return mod\n",
    "\n",
    "    for annotate_non_call_ops in [False, True]:\n",
    "        result = transform.AnnotateTarget(target, annotate_non_call_ops)(before())\n",
    "        expected = transform.InferType()(after(annotate_non_call_ops))\n",
    "        assert tvm.ir.structural_equal(expected, result)\n",
    "\n",
    "\n",
    "def test_if_free_vars():\n",
    "    target = \"test_if_free_vars\"\n",
    "\n",
    "    @tvm.ir.register_op_attr(\"equal\", \"target.\" + target)\n",
    "    def equal(expr):  # pylint: disable=unused-variable\n",
    "        return True\n",
    "\n",
    "    @tvm.ir.register_op_attr(\"sigmoid\", \"target.\" + target)\n",
    "    def sigmoid(expr):  # pylint: disable=unused-variable\n",
    "        return True\n",
    "\n",
    "    @tvm.ir.register_op_attr(\"erf\", \"target.\" + target)\n",
    "    def erf(expr):  # pylint: disable=unused-variable\n",
    "        return True\n",
    "\n",
    "    \"\"\"Test that If-else nodes compiles correctly when surrounded by free variables\"\"\"\n",
    "\n",
    "    def before():\n",
    "        data = relay.var(\"data\", shape=(1, 32))\n",
    "        eq1 = relay.var(\"e1\", shape=[], dtype=\"float32\")\n",
    "        eq2 = relay.var(\"e2\", shape=[], dtype=\"float32\")\n",
    "        eq = relay.equal(eq1, eq2)\n",
    "\n",
    "        true_branch = relay.zeros(shape=(1, 32), dtype=\"float32\")\n",
    "        false_branch = relay.sigmoid(data)\n",
    "        ife = relay.If(eq, true_branch, false_branch)\n",
    "        out = relay.erf(ife)\n",
    "\n",
    "        func = relay.Function([data, eq1, eq2], out)\n",
    "        mod = tvm.IRModule.from_expr(func)\n",
    "\n",
    "        return mod\n",
    "\n",
    "    def after():\n",
    "        data = relay.var(\"data\", shape=(1, 32))\n",
    "        eq1 = relay.var(\"e1\", shape=[], dtype=\"float32\")\n",
    "        eq2 = relay.var(\"e2\", shape=[], dtype=\"float32\")\n",
    "\n",
    "        cb_1 = relay.annotation.compiler_begin(eq1, target)\n",
    "        cb_2 = relay.annotation.compiler_begin(eq2, target)\n",
    "\n",
    "        equality_condition = relay.equal(cb_1, cb_2)\n",
    "        ce_1 = relay.annotation.compiler_end(equality_condition, target)\n",
    "\n",
    "        # if condition\n",
    "        true_branch = relay.zeros(shape=(1, 32), dtype=\"float32\")\n",
    "\n",
    "        # else condition\n",
    "        cb_3 = relay.annotation.compiler_begin(data, target)\n",
    "        false_branch = relay.sigmoid(cb_3)\n",
    "        ce_2 = relay.annotation.compiler_end(false_branch, target)\n",
    "\n",
    "        if_condition = relay.If(ce_1, true_branch, ce_2)\n",
    "        cb_4 = relay.annotation.compiler_begin(if_condition, target)\n",
    "        erf_out = relay.erf(cb_4)\n",
    "        ce_3 = relay.annotation.compiler_end(erf_out, target)\n",
    "        func = relay.Function([data, eq1, eq2], ce_3)\n",
    "        mod = tvm.IRModule.from_expr(func)\n",
    "        return mod\n",
    "\n",
    "    for annotate_non_call_ops in [True, False]:\n",
    "        result = transform.AnnotateTarget(target, annotate_non_call_ops)(before())\n",
    "        expected = transform.InferType()(after())\n",
    "        assert tvm.ir.structural_equal(expected, result)\n",
    "\n",
    "\n",
    "def test_free_vars_zeros():\n",
    "    target = \"test_free_vars_zeros\"\n",
    "\n",
    "    \"\"\"Test that free variables compile correctly on their own\"\"\"\n",
    "\n",
    "    def before():\n",
    "        func = relay.Function([], relay.zeros(shape=(0), dtype=\"float32\"))\n",
    "        mod = tvm.IRModule.from_expr(func)\n",
    "        return mod\n",
    "\n",
    "    def after():\n",
    "        func = relay.Function([], relay.zeros(shape=(0), dtype=\"float32\"))\n",
    "        mod = tvm.IRModule.from_expr(func)\n",
    "        return mod\n",
    "\n",
    "    result = transform.AnnotateTarget(target)(before())\n",
    "    expected = transform.InferType()(after())\n",
    "    assert tvm.ir.structural_equal(expected, result)\n",
    "\n",
    "\n",
    "def test_empty_tuple():\n",
    "    target = \"test_empty_tuple\"\n",
    "\n",
    "    \"\"\"An empty tuple should behave just like a call with no args (see above test).\"\"\"\n",
    "\n",
    "    def before():\n",
    "        func = relay.Function([], relay.Tuple([]))\n",
    "        mod = tvm.IRModule.from_expr(func)\n",
    "        return mod\n",
    "\n",
    "    def after():\n",
    "        func = relay.Function([], relay.Tuple([]))\n",
    "        mod = tvm.IRModule.from_expr(func)\n",
    "        return mod\n",
    "\n",
    "    for annotate_non_call_ops in [True, False]:\n",
    "        result = transform.AnnotateTarget(target, annotate_non_call_ops)(before())\n",
    "        expected = transform.InferType()(after())\n",
    "        assert tvm.ir.structural_equal(expected, result)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
