{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 合并编译器区域"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 菱形计算图\n",
    "\n",
    "定义如下数据依赖：\n",
    "\n",
    "```\n",
    "     O         O\n",
    "    / \\\\      /               \\\\\n",
    "    O   X --> O    +       +    X\n",
    "    \\\\ /             \\\\ /\n",
    "      O                O\n",
    "```\n",
    "\n",
    "其中 `O` 表示 `target` 支持的算子，`X` 表示 `target` 不支持的算子。\n",
    "\n",
    "注意，不能仅仅将三个支持的算子合并在一起，否则两个子图将依赖于另一个子图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.relay.op.annotation import compiler_begin, compiler_end\n",
    "from tvm.relay.testing import run_opt_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diamond_graph_fanouts():\n",
    "    data = relay.var(\"data\", shape=(10, 10))\n",
    "    cb_1 = compiler_begin(data, \"test\")\n",
    "    O_1 = relay.abs(cb_1)\n",
    "    ce_1 = compiler_end(O_1, \"test\")\n",
    "    ce_2 = compiler_end(O_1, \"test\")\n",
    "    cb_2 = compiler_begin(ce_1, \"test\")\n",
    "    cb_3 = compiler_begin(ce_2, \"default\")\n",
    "    O_2 = relay.nn.relu(cb_2)\n",
    "    ce_3 = compiler_end(O_2, \"test\")\n",
    "\n",
    "    X = relay.tanh(cb_3)\n",
    "    ce_4 = compiler_end(X, \"default\")\n",
    "\n",
    "    cb_4 = compiler_begin(ce_3, \"test\")\n",
    "    cb_5 = compiler_begin(ce_4, \"test\")\n",
    "    O_3 = relay.add(cb_4, cb_5)\n",
    "    ce_5 = compiler_end(O_3, \"test\")\n",
    "\n",
    "    diamond = relay.Function([data], ce_5)\n",
    "    return diamond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "合并之前：def @main(%data: Tensor[(10, 10), float32]) {\n",
      "  %0 = annotation.compiler_begin(%data, compiler=\"test\");\n",
      "  %1 = abs(%0);\n",
      "  %2 = annotation.compiler_end(%1, compiler=\"test\");\n",
      "  %3 = annotation.compiler_begin(%2, compiler=\"test\");\n",
      "  %4 = nn.relu(%3);\n",
      "  %5 = annotation.compiler_end(%4, compiler=\"test\");\n",
      "  %6 = annotation.compiler_end(%1, compiler=\"test\");\n",
      "  %7 = annotation.compiler_begin(%6, compiler=\"default\");\n",
      "  %8 = tanh(%7);\n",
      "  %9 = annotation.compiler_end(%8, compiler=\"default\");\n",
      "  %10 = annotation.compiler_begin(%5, compiler=\"test\");\n",
      "  %11 = annotation.compiler_begin(%9, compiler=\"test\");\n",
      "  %12 = add(%10, %11);\n",
      "  annotation.compiler_end(%12, compiler=\"test\")\n",
      "}\n",
      "\n",
      "合并之后：def @main(%data: Tensor[(10, 10), float32] /* ty=Tensor[(10, 10), float32] */) -> Tensor[(10, 10), float32] {\n",
      "  %0 = annotation.compiler_begin(%data, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %1 = abs(%0) /* ty=Tensor[(10, 10), float32] */;\n",
      "  %2 = nn.relu(%1) /* ty=Tensor[(10, 10), float32] */;\n",
      "  %3 = annotation.compiler_end(%2, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %4 = annotation.compiler_end(%1, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %5 = annotation.compiler_begin(%4, compiler=\"default\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %6 = tanh(%5) /* ty=Tensor[(10, 10), float32] */;\n",
      "  %7 = annotation.compiler_end(%6, compiler=\"default\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %8 = annotation.compiler_begin(%3, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %9 = annotation.compiler_begin(%7, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %10 = add(%8, %9) /* ty=Tensor[(10, 10), float32] */;\n",
      "  annotation.compiler_end(%10, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mod = tvm.IRModule.from_expr(diamond_graph_fanouts())\n",
    "print(f\"合并之前：{mod}\")\n",
    "mod = relay.transform.MergeCompilerRegions()(mod)\n",
    "print(f\"合并之后：{mod}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `if-else` 测试\n",
    "\n",
    "```\n",
    "           O1 - - - |      O1 --|\n",
    "            |       |               |\n",
    "            X       |               X\n",
    "            |       |                              |\n",
    "    If cond ? O1: X | -->       +       +  If cond ? O1: X  +\n",
    "            |       |                                           |\n",
    "           O2 <- - -|                                          O2 <-|\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = \"test_if_else_merge\"\n",
    "\n",
    "@tvm.ir.register_op_attr(\"sigmoid\", \"target.\" + target)\n",
    "def sigmoid(expr):  # pylint: disable=unused-variable\n",
    "    return True\n",
    "\n",
    "@tvm.ir.register_op_attr(\"erf\", \"target.\" + target)\n",
    "def erf(expr):  # pylint: disable=unused-variable\n",
    "    return True\n",
    "\n",
    "@tvm.ir.register_op_attr(\"add\", \"target.\" + target)\n",
    "def add(expr):  # pylint: disable=unused-variable\n",
    "    return True\n",
    "def get_mod():\n",
    "    data = relay.var(\"data\", shape=(1, 32))\n",
    "    add0 = relay.add(data, data)\n",
    "    sub0 = relay.subtract(add0, data)\n",
    "    eq = relay.equal(relay.sum(add0), relay.sum(sub0))\n",
    "\n",
    "    true_branch = relay.sigmoid(add0)\n",
    "    false_branch = relay.sigmoid(sub0)\n",
    "    ife = relay.If(eq, true_branch, false_branch)\n",
    "    erf = relay.erf(ife)\n",
    "    out = relay.add(add0, erf)\n",
    "    func = relay.Function([data], out)\n",
    "    mod = tvm.IRModule.from_expr(func)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for annotate_non_call_ops in [True, False]:\n",
    "    result = relay.transform.AnnotateTarget(target, annotate_non_call_ops)(get_mod())\n",
    "    merge = relay.transform.MergeCompilerRegions()(result)\n",
    "    # Ensure partition finished without segment fault.\n",
    "    partition = relay.transform.PartitionGraph()(merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 合并计算图示例\n",
    "参考：[RFC 5830](https://discuss.tvm.apache.org/t/relay-improved-graph-partitioning-algorithm/5830)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotated():\n",
    "    in_1 = relay.var(\"in_1\", shape=(10, 10), dtype=\"float32\")\n",
    "    in_2 = relay.var(\"in_2\", shape=(10, 10), dtype=\"float32\")\n",
    "    in_3 = relay.var(\"in_3\", shape=(10, 10), dtype=\"float32\")\n",
    "    in_4 = relay.var(\"in_4\", shape=(10, 10), dtype=\"float32\")\n",
    "    in_5 = relay.var(\"in_5\", shape=(10, 10), dtype=\"float32\")\n",
    "    in_6 = relay.var(\"in_6\", shape=(10, 10), dtype=\"float32\")\n",
    "    in_7 = relay.var(\"in_7\", shape=(10, 10), dtype=\"float32\")\n",
    "    in_8 = relay.var(\"in_8\", shape=(10, 10), dtype=\"float32\")\n",
    "    in_9 = relay.var(\"in_9\", shape=(10, 10), dtype=\"float32\")\n",
    "    in_10 = relay.var(\"in_10\", shape=(10, 10), dtype=\"float32\")\n",
    "\n",
    "    begin0 = compiler_begin(in_1, \"test\")\n",
    "    begin1 = compiler_begin(in_2, \"test\")\n",
    "    begin2 = compiler_begin(in_3, \"test\")\n",
    "    begin3 = compiler_begin(in_4, \"test\")\n",
    "    node0 = relay.add(begin0, begin1)\n",
    "    node1 = relay.add(begin2, begin3)\n",
    "    end0 = compiler_end(node0, \"test\")\n",
    "    end1 = compiler_end(node1, \"test\")\n",
    "    begin4 = compiler_begin(end0, \"test\")\n",
    "    begin5 = compiler_begin(end1, \"test\")\n",
    "    node2 = relay.add(begin4, begin5)\n",
    "    end2 = compiler_end(node2, \"test\")\n",
    "\n",
    "    dbegin0 = compiler_begin(in_5, \"default\")\n",
    "    dbegin1 = compiler_begin(in_6, \"default\")\n",
    "    node3 = relay.subtract(dbegin0, dbegin1)\n",
    "    dbegin2 = compiler_begin(in_7, \"default\")\n",
    "    dend1 = compiler_end(node3, \"default\")\n",
    "    dbegin3 = compiler_begin(dend1, \"default\")\n",
    "    node4 = relay.subtract(dbegin2, dbegin3)\n",
    "    dend2 = compiler_end(node4, \"default\")\n",
    "\n",
    "    begin6 = compiler_begin(end2, \"test\")\n",
    "    begin7 = compiler_begin(dend2, \"test\")\n",
    "    node5 = relay.add(begin6, begin7)\n",
    "    end3 = compiler_end(node5, \"test\")\n",
    "    end4 = compiler_end(node5, \"test\")\n",
    "    dbegin4 = compiler_begin(in_8, \"default\")\n",
    "    dbegin5 = compiler_begin(end3, \"default\")\n",
    "    node6 = relay.subtract(dbegin4, dbegin5)\n",
    "    begin8 = compiler_begin(in_9, \"test\")\n",
    "    begin9 = compiler_begin(end4, \"test\")\n",
    "    node7 = relay.add(begin8, begin9)\n",
    "    end5 = compiler_end(node7, \"test\")\n",
    "\n",
    "    dend3 = compiler_end(node6, \"default\")\n",
    "    begin10 = compiler_begin(dend3, \"test\")\n",
    "    begin11 = compiler_begin(end5, \"test\")\n",
    "    node8 = relay.add(begin10, begin11)\n",
    "    end6 = compiler_end(node8, \"test\")\n",
    "    begin12 = compiler_begin(in_10, \"test\")\n",
    "    begin13 = compiler_begin(end6, \"test\")\n",
    "    node9 = relay.add(begin12, begin13)\n",
    "    end7 = compiler_end(node9, \"test\")\n",
    "\n",
    "    f = relay.Function([in_1, in_2, in_3, in_4, in_5, in_6, in_7, in_8, in_9, in_10], end7)\n",
    "    mod = tvm.IRModule.from_expr(f)\n",
    "    return mod\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%in_1: Tensor[(10, 10), float32] /* ty=Tensor[(10, 10), float32] */, %in_2: Tensor[(10, 10), float32] /* ty=Tensor[(10, 10), float32] */, %in_3: Tensor[(10, 10), float32] /* ty=Tensor[(10, 10), float32] */, %in_4: Tensor[(10, 10), float32] /* ty=Tensor[(10, 10), float32] */, %in_5: Tensor[(10, 10), float32] /* ty=Tensor[(10, 10), float32] */, %in_6: Tensor[(10, 10), float32] /* ty=Tensor[(10, 10), float32] */, %in_7: Tensor[(10, 10), float32] /* ty=Tensor[(10, 10), float32] */, %in_8: Tensor[(10, 10), float32] /* ty=Tensor[(10, 10), float32] */, %in_9: Tensor[(10, 10), float32] /* ty=Tensor[(10, 10), float32] */, %in_10: Tensor[(10, 10), float32] /* ty=Tensor[(10, 10), float32] */) -> Tensor[(10, 10), float32] {\n",
      "  %0 = annotation.compiler_begin(%in_1, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %1 = annotation.compiler_begin(%in_2, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %2 = annotation.compiler_begin(%in_3, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %3 = annotation.compiler_begin(%in_4, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %4 = add(%0, %1) /* ty=Tensor[(10, 10), float32] */;\n",
      "  %5 = add(%2, %3) /* ty=Tensor[(10, 10), float32] */;\n",
      "  %6 = annotation.compiler_begin(%in_5, compiler=\"default\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %7 = annotation.compiler_begin(%in_6, compiler=\"default\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %8 = annotation.compiler_begin(%in_7, compiler=\"default\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %9 = subtract(%6, %7) /* ty=Tensor[(10, 10), float32] */;\n",
      "  %10 = subtract(%8, %9) /* ty=Tensor[(10, 10), float32] */;\n",
      "  %11 = annotation.compiler_end(%10, compiler=\"default\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %12 = add(%4, %5) /* ty=Tensor[(10, 10), float32] */;\n",
      "  %13 = annotation.compiler_begin(%11, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %14 = add(%12, %13) /* ty=Tensor[(10, 10), float32] */;\n",
      "  %15 = annotation.compiler_end(%14, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %16 = annotation.compiler_begin(%in_8, compiler=\"default\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %17 = annotation.compiler_begin(%15, compiler=\"default\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %18 = subtract(%16, %17) /* ty=Tensor[(10, 10), float32] */;\n",
      "  %19 = annotation.compiler_end(%18, compiler=\"default\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %20 = annotation.compiler_begin(%in_9, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %21 = add(%20, %14) /* ty=Tensor[(10, 10), float32] */;\n",
      "  %22 = annotation.compiler_end(%21, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %23 = annotation.compiler_begin(%19, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %24 = annotation.compiler_begin(%22, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %25 = annotation.compiler_begin(%in_10, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */;\n",
      "  %26 = add(%23, %24) /* ty=Tensor[(10, 10), float32] */;\n",
      "  %27 = add(%25, %26) /* ty=Tensor[(10, 10), float32] */;\n",
      "  annotation.compiler_end(%27, compiler=\"test\") /* ty=Tensor[(10, 10), float32] */\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mod = annotated()\n",
    "mod = relay.transform.MergeCompilerRegions()(mod)\n",
    "mod = relay.transform.InferType()(mod)\n",
    "print(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
