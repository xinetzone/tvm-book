{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 计算图分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tvm\n",
    "from tvm.relay.backend import te_compiler\n",
    "from tvm.relay.backend.runtime import Runtime\n",
    "import tvm.relay.testing\n",
    "import tvm.relay.op as reg\n",
    "from tvm import relay\n",
    "from tvm.relay import transform\n",
    "from tvm.relay.testing import byoc\n",
    "from tvm.contrib import utils\n",
    "from tvm.relay.expr_functor import ExprMutator\n",
    "from tvm.relay.op.annotation import compiler_begin, compiler_end\n",
    "from tvm.relay.op.contrib.register import get_pattern_table\n",
    "from tvm.relay.build_module import bind_params_by_name\n",
    "\n",
    "def set_func_attr(func, compile_name, symbol_name):\n",
    "    func = func.with_attr(\"Primitive\", tvm.tir.IntImm(\"int32\", 1))\n",
    "    func = func.with_attr(\"Inline\", tvm.tir.IntImm(\"int32\", 1))\n",
    "    func = func.with_attr(\"Compiler\", compile_name)\n",
    "    func = func.with_attr(\"global_symbol\", symbol_name)\n",
    "    return func\n",
    "\n",
    "def update_lib(lib, source_dir=\"/media/pc/data/lxw/ai/tvm\"):\n",
    "    kwargs = {\n",
    "        \"options\" : [\n",
    "            \"-O2\", \"-std=c++17\", \n",
    "            f\"-I{source_dir}/src/runtime/contrib\", \n",
    "            f\"-I{source_dir}/include\",\n",
    "            f\"-I{source_dir}/3rdparty/dlpack/include\",\n",
    "            f\"-I{source_dir}/3rdparty/dmlc-core/include\",\n",
    "        ]\n",
    "    }\n",
    "    tmp_path = utils.tempdir()\n",
    "    lib_name = \"lib.so\"\n",
    "    lib_path = tmp_path.relpath(lib_name)\n",
    "    lib.export_library(lib_path, fcompile=False, **kwargs)\n",
    "    lib = tvm.runtime.load_module(lib_path)\n",
    "    return lib\n",
    "\n",
    "# Leverage the pass manager to write a simple allowed list based annotator\n",
    "@transform.function_pass(opt_level=0)\n",
    "class AllowedListAnnotator:\n",
    "    def __init__(self, op_list, compiler):\n",
    "        assert isinstance(op_list, (list, tuple, set))\n",
    "        self.op_list = op_list\n",
    "        self.compiler = compiler\n",
    "\n",
    "    def transform_function(self, func, mod, dev):\n",
    "\n",
    "        annotator = self\n",
    "\n",
    "        class Annotator(tvm.relay.ExprMutator):\n",
    "            def visit_call(self, call):\n",
    "                op_name = call.op.name\n",
    "                if op_name in annotator.op_list:\n",
    "                    new_args = []\n",
    "                    for arg in call.args:\n",
    "                        ann = compiler_begin(super().visit(arg), annotator.compiler)\n",
    "                        new_args.append(ann)\n",
    "                    new_call = relay.Call(call.op, new_args, call.attrs, call.type_args)\n",
    "                    return compiler_end(new_call, annotator.compiler)\n",
    "                else:\n",
    "                    return super().visit_call(call)\n",
    "\n",
    "        return Annotator().visit(func)\n",
    "\n",
    "class MobileNetAnnotator(ExprMutator):\n",
    "    \"\"\"\n",
    "    Annotate mobilenet until global_avg_pool.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, compiler):\n",
    "        super(MobileNetAnnotator, self).__init__()\n",
    "        self.compiler = compiler\n",
    "        self.compiler_open = False\n",
    "\n",
    "    def visit_call(self, call):\n",
    "\n",
    "        if call.op.name == \"nn.global_avg_pool2d\":\n",
    "            self.compiler_open = True\n",
    "        compiler_open = self.compiler_open\n",
    "\n",
    "        params = []\n",
    "        for arg in call.args:\n",
    "            param = super().visit(arg)\n",
    "            if call.op.name == \"nn.global_avg_pool2d\":\n",
    "                param = compiler_end(param, self.compiler)\n",
    "            if compiler_open and isinstance(param, relay.expr.Var):\n",
    "                param = compiler_begin(param, self.compiler)\n",
    "            params.append(param)\n",
    "\n",
    "        new_call = relay.Call(call.op, params, call.attrs)\n",
    "        return new_call\n",
    "\n",
    "def check_result(\n",
    "    mod,\n",
    "    map_inputs,\n",
    "    out_shape,\n",
    "    result,\n",
    "    tol=1e-5,\n",
    "    target=\"llvm\",\n",
    "    device=tvm.cpu(),\n",
    "    params=None,\n",
    "    runtime=Runtime(\"cpp\"),\n",
    "):\n",
    "    def check_vm_result():\n",
    "        te_compiler.get().clear()\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "            exe = relay.vm.compile(mod, target=target, params=params)\n",
    "        code, lib = exe.save()\n",
    "        lib = update_lib(lib)\n",
    "        exe = tvm.runtime.vm.Executable.load_exec(code, lib)\n",
    "        vm = tvm.runtime.vm.VirtualMachine(exe, device)\n",
    "        outs = vm.run(**map_inputs)\n",
    "        outs = outs if isinstance(outs, tvm.runtime.container.ADT) else [outs]\n",
    "        results = result if isinstance(result, list) else [result]\n",
    "        for out, ref in zip(outs, results):\n",
    "            tvm.testing.assert_allclose(out.numpy(), ref, rtol=tol, atol=tol)\n",
    "    check_vm_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多节点编译"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于多节点编译这种情况，我们生成了两个编译器，但由于它们具有相同的输入 (`x`)，应该将它们合并为一个。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expr():\n",
    "    x = relay.var(\"x\", shape=(10, 10))\n",
    "    w0 = relay.var(\"w0\", shape=(10, 10))\n",
    "    w1 = relay.var(\"w1\", shape=(10, 10))\n",
    "    w2 = relay.var(\"w2\", shape=(10, 10))\n",
    "    w3 = relay.var(\"w3\", shape=(10, 10))\n",
    "    w4 = relay.var(\"w4\", shape=(10, 10))\n",
    "    w5 = relay.var(\"w5\", shape=(10, 10))\n",
    "    w6 = relay.var(\"w6\", shape=(10, 10))\n",
    "    w7 = relay.var(\"w7\", shape=(10, 10))\n",
    "\n",
    "    z0 = relay.add(x, w0)\n",
    "    p0 = relay.subtract(z0, w1)\n",
    "    q0 = relay.multiply(p0, w2)\n",
    "\n",
    "    z1 = relay.add(x, w3)\n",
    "    p1 = relay.subtract(z1, w4)\n",
    "    q1 = relay.multiply(p1, w5)\n",
    "\n",
    "    z2 = relay.add(x, w6)\n",
    "    q2 = relay.subtract(z2, w7)\n",
    "\n",
    "    r = relay.concatenate((q0, q1, q2), axis=0)\n",
    "    return relay.Function([x, w0, w1, w2, w3, w4, w5, w6, w7], r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
      "To print formatted TVM script, please install the formatter 'Black':\n",
      "/media/pc/data/tmp/cache/conda/envs/tvmz/bin/python -m pip install \"black==22.3.0\" --upgrade --user\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32], <span style=\"color: #AA22FF; font-weight: bold\">%</span>w0: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32], <span style=\"color: #AA22FF; font-weight: bold\">%</span>w1: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32], <span style=\"color: #AA22FF; font-weight: bold\">%</span>w2: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32], <span style=\"color: #AA22FF; font-weight: bold\">%</span>w3: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32], <span style=\"color: #AA22FF; font-weight: bold\">%</span>w4: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32], <span style=\"color: #AA22FF; font-weight: bold\">%</span>w5: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32], <span style=\"color: #AA22FF; font-weight: bold\">%</span>w6: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32], <span style=\"color: #AA22FF; font-weight: bold\">%</span>w7: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32]) {\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> annotation<span style=\"color: #AA22FF; font-weight: bold\">.</span>compiler_begin(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x, compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> annotation<span style=\"color: #AA22FF; font-weight: bold\">.</span>compiler_begin(<span style=\"color: #AA22FF; font-weight: bold\">%</span>w0, compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> add(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span>);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">3</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> annotation<span style=\"color: #AA22FF; font-weight: bold\">.</span>compiler_begin(<span style=\"color: #AA22FF; font-weight: bold\">%</span>w1, compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">4</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> subtract(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">2</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">3</span>);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">5</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> annotation<span style=\"color: #AA22FF; font-weight: bold\">.</span>compiler_begin(<span style=\"color: #AA22FF; font-weight: bold\">%</span>w2, compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">6</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> multiply(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">4</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">5</span>);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">7</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> annotation<span style=\"color: #AA22FF; font-weight: bold\">.</span>compiler_begin(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x, compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">8</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> annotation<span style=\"color: #AA22FF; font-weight: bold\">.</span>compiler_begin(<span style=\"color: #AA22FF; font-weight: bold\">%</span>w3, compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">9</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> add(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">7</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">8</span>);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">10</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> annotation<span style=\"color: #AA22FF; font-weight: bold\">.</span>compiler_begin(<span style=\"color: #AA22FF; font-weight: bold\">%</span>w4, compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">11</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> subtract(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">9</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">10</span>);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">12</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> annotation<span style=\"color: #AA22FF; font-weight: bold\">.</span>compiler_begin(<span style=\"color: #AA22FF; font-weight: bold\">%</span>w5, compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">13</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> multiply(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">11</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">12</span>);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">14</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> add(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w6);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">15</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> annotation<span style=\"color: #AA22FF; font-weight: bold\">.</span>compiler_end(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">6</span>, compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">16</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> annotation<span style=\"color: #AA22FF; font-weight: bold\">.</span>compiler_end(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">13</span>, compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">17</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> subtract(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">14</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w7);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">18</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> (<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">15</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">16</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">17</span>);\n",
       "  concatenate(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">18</span>)\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
      "To print formatted TVM script, please install the formatter 'Black':\n",
      "/media/pc/data/tmp/cache/conda/envs/tvmz/bin/python -m pip install \"black==22.3.0\" --upgrade --user\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w0: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w1: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w2: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w3: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w4: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w5: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w6: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w7: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">30</span>, <span style=\"color: #008000\">10</span>), float32] {\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> add(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w6) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> <span style=\"color: #AA22FF\">@tvmgen_default_ccompiler_main_0</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w0, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w1, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w2) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> <span style=\"color: #AA22FF\">@tvmgen_default_ccompiler_main_4</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w3, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w4, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w5) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">3</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> subtract(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w7) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">4</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> (<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">2</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">3</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>(Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32], Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32], Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32]) <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  concatenate(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">4</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">30</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@tvmgen_default_ccompiler_main_0</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_0_i0: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_0_i1: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_0_i2: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_0_i3: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, Compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>, Primitive<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, Inline<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, global_symbol<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;tvmgen_default_ccompiler_main_0&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] {\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">5</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> add(<span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_0_i0, <span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_0_i1) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">6</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> subtract(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">5</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_0_i2) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  multiply(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">6</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_0_i3) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@tvmgen_default_ccompiler_main_4</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_4_i0: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_4_i1: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_4_i2: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_4_i3: Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, Compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>, Primitive<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, Inline<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, global_symbol<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;tvmgen_default_ccompiler_main_4&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] {\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">7</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> add(<span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_4_i0, <span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_4_i1) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">8</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> subtract(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">7</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_4_i2) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  multiply(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">8</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_4_i3) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">10</span>, <span style=\"color: #008000\">10</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod = tvm.IRModule()\n",
    "ann = byoc.CcompilerAnnotator()\n",
    "mod[\"main\"] = ann.visit(get_expr())\n",
    "mod.show()\n",
    "mod = transform.PartitionGraph()(mod)\n",
    "mod = transform.InferType()(mod)\n",
    "mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.random.rand(10, 10).astype(\"float32\")\n",
    "w_data = []\n",
    "for _ in range(8):\n",
    "    w_data.append(np.random.rand(10, 10).astype(\"float32\"))\n",
    "\n",
    "map_inputs = {f\"w{i}\": w_data[i] for i in range(8)}\n",
    "map_inputs[\"x\"] = x_data\n",
    "params = None\n",
    "targets = [(\"llvm\", Runtime(\"cpp\")), (\"c\", Runtime(\"crt\", {\"system-lib\": True}))]\n",
    "for tgt, rt in targets:\n",
    "    check_result(\n",
    "        mod,\n",
    "        map_inputs,\n",
    "        (30, 10),\n",
    "        np.concatenate(\n",
    "            (\n",
    "                ((x_data + w_data[0]) - w_data[1]) * w_data[2],\n",
    "                ((x_data + w_data[3]) - w_data[4]) * w_data[5],\n",
    "                x_data + w_data[6] - w_data[7],\n",
    "            ),\n",
    "            axis=0,\n",
    "        ),\n",
    "        target=tgt,\n",
    "        runtime=rt,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编译外部库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@transform.function_pass(opt_level=0)\n",
    "class MyAnnotator:\n",
    "    def transform_function(self, func, mod, dev):\n",
    "        class Annotator(tvm.relay.ExprMutator):\n",
    "            def visit_call(self, call):\n",
    "                new_args = []\n",
    "                for arg in call.args:\n",
    "                    ann = compiler_begin(self.visit(arg), \"ccompiler\")\n",
    "                    new_args.append(ann)\n",
    "                new_call = relay.Call(call.op, new_args)\n",
    "                return compiler_end(new_call, \"ccompiler\")\n",
    "\n",
    "        return Annotator().visit(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
      "To print formatted TVM script, please install the formatter 'Black':\n",
      "/media/pc/data/tmp/cache/conda/envs/tvmz/bin/python -m pip install \"black==22.3.0\" --upgrade --user\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32], <span style=\"color: #AA22FF; font-weight: bold\">%</span>y: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32]) {\n",
       "  add(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x, <span style=\"color: #AA22FF; font-weight: bold\">%</span>y)\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
      "To print formatted TVM script, please install the formatter 'Black':\n",
      "/media/pc/data/tmp/cache/conda/envs/tvmz/bin/python -m pip install \"black==22.3.0\" --upgrade --user\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>y: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] {\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> annotation<span style=\"color: #AA22FF; font-weight: bold\">.</span>compiler_begin(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x, compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> annotation<span style=\"color: #AA22FF; font-weight: bold\">.</span>compiler_begin(<span style=\"color: #AA22FF; font-weight: bold\">%</span>y, compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> add(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  annotation<span style=\"color: #AA22FF; font-weight: bold\">.</span>compiler_end(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">2</span>, compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
      "To print formatted TVM script, please install the formatter 'Black':\n",
      "/media/pc/data/tmp/cache/conda/envs/tvmz/bin/python -m pip install \"black==22.3.0\" --upgrade --user\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>y: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] {\n",
       "  <span style=\"color: #AA22FF\">@tvmgen_default_ccompiler_main_0</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x, <span style=\"color: #AA22FF; font-weight: bold\">%</span>y) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@tvmgen_default_ccompiler_main_0</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_0_i0: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_0_i1: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, Compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>, Primitive<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, Inline<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, global_symbol<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;tvmgen_default_ccompiler_main_0&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] {\n",
       "  add(<span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_0_i0, <span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_0_i1) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:45:16] /media/pc/data/lxw/ai/tvm/src/relay/backend/vm/compiler.cc:1202: All lowered functions have been build by BYOC -- generating an empty TVM module\n"
     ]
    }
   ],
   "source": [
    "x = relay.var(\"x\", shape=(8, 8))\n",
    "y = relay.var(\"y\", shape=(8, 8))\n",
    "z = x + y\n",
    "f = relay.Function([x, y], z)\n",
    "mod = tvm.IRModule()\n",
    "mod[\"main\"] = f\n",
    "mod.show()\n",
    "mod = MyAnnotator()(mod)\n",
    "mod.show()\n",
    "mod = transform.PartitionGraph()(mod)\n",
    "mod.show()\n",
    "x_data = np.random.rand(8, 8).astype(\"float32\")\n",
    "y_data = np.random.rand(8, 8).astype(\"float32\")\n",
    "check_result(mod, {\"x\": x_data, \"y\": y_data}, (8, 8), x_data + y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_extern_ccompiler_default_ops："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected():\n",
    "    mod = tvm.IRModule()\n",
    "    x = relay.var(\"x\", shape=(8, 8))\n",
    "    y = relay.var(\"y\", shape=(8, 8))\n",
    "    x0 = relay.var(\"x0\", shape=(8, 8))\n",
    "    y0 = relay.var(\"y0\", shape=(8, 8))\n",
    "    add = x0 + y0\n",
    "    # Function that uses C compiler\n",
    "    func = relay.Function([x0, y0], add)\n",
    "    func = set_func_attr(func, \"ccompiler\", \"tvmgen_default_ccompiler_main_0\")\n",
    "    glb_0 = relay.GlobalVar(\"tvmgen_default_ccompiler_main_0\")\n",
    "    mod[glb_0] = func\n",
    "    add_call = relay.Call(glb_0, [x, y])\n",
    "    # Function that uses default compiler. Ops are fused in this function.\n",
    "    p0 = relay.var(\"p0\", shape=(8, 8))\n",
    "    log = relay.log(p0)\n",
    "    exp = relay.exp(p0)\n",
    "    concat = relay.concatenate([log, exp], axis=0)\n",
    "    fused_func = relay.Function([p0], concat)\n",
    "    fused_func = fused_func.with_attr(\"Primitive\", tvm.tir.IntImm(\"int32\", 1))\n",
    "    fused_call = relay.Call(fused_func, [add_call])\n",
    "    main = relay.Function([x, y], fused_call)\n",
    "    mod[\"main\"] = main\n",
    "    mod = transform.InferType()(mod)\n",
    "    return mod\n",
    "\n",
    "x = relay.var(\"x\", shape=(8, 8))\n",
    "y = relay.var(\"y\", shape=(8, 8))\n",
    "add = x + y\n",
    "log = relay.log(add)\n",
    "exp = relay.exp(add)\n",
    "concat = relay.concatenate([log, exp], axis=0)\n",
    "f = relay.Function([x, y], concat)\n",
    "mod = tvm.IRModule()\n",
    "mod[\"main\"] = f\n",
    "mod = AllowedListAnnotator([\"add\", \"subtract\", \"multiply\"], \"ccompiler\")(mod)\n",
    "mod = transform.PartitionGraph()(mod)\n",
    "fused_mod = transform.FuseOps(2)(mod)\n",
    "expected_mod = expected()\n",
    "assert tvm.ir.structural_equal(fused_mod, expected_mod, map_free_vars=True)\n",
    "\n",
    "x_data = np.random.rand(8, 8).astype(\"float32\")\n",
    "y_data = np.random.rand(8, 8).astype(\"float32\")\n",
    "np_add = x_data + y_data\n",
    "res = np.concatenate([np.log(np_add), np.exp(np_add)])\n",
    "check_result(mod, {\"x\": x_data, \"y\": y_data}, (16, 8), res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_extern_compiler_sanitized_ops():\n",
    "    def expected():\n",
    "        mod = tvm.IRModule()\n",
    "        x = relay.var(\"x\", shape=(8, 8))\n",
    "        y = relay.var(\"y\", shape=(8, 8))\n",
    "        x0 = relay.var(\"x0\", shape=(8, 8))\n",
    "        y0 = relay.var(\"y0\", shape=(8, 8))\n",
    "        add = x0 + y0\n",
    "        # Function that uses C compiler\n",
    "        func = relay.Function([x0, y0], add)\n",
    "        func = set_func_attr(func, \"unsanitary-name++\", \"tvmgen_default_unsanitary_name___main_0\")\n",
    "        glb_0 = relay.GlobalVar(\"tvmgen_default_unsanitary_name___main_0\")\n",
    "        mod[glb_0] = func\n",
    "        add_call = relay.Call(glb_0, [x, y])\n",
    "        # Function that uses default compiler. Ops are fused in this function.\n",
    "        p0 = relay.var(\"p0\", shape=(8, 8))\n",
    "        log = relay.log(p0)\n",
    "        exp = relay.exp(p0)\n",
    "        concat = relay.concatenate([log, exp], axis=0)\n",
    "        fused_func = relay.Function([p0], concat)\n",
    "        fused_func = fused_func.with_attr(\"Primitive\", tvm.tir.IntImm(\"int32\", 1))\n",
    "        fused_call = relay.Call(fused_func, [add_call])\n",
    "        main = relay.Function([x, y], fused_call)\n",
    "        mod[\"main\"] = main\n",
    "        mod = transform.InferType()(mod)\n",
    "        return mod\n",
    "\n",
    "    x = relay.var(\"x\", shape=(8, 8))\n",
    "    y = relay.var(\"y\", shape=(8, 8))\n",
    "    add = x + y\n",
    "    log = relay.log(add)\n",
    "    exp = relay.exp(add)\n",
    "    concat = relay.concatenate([log, exp], axis=0)\n",
    "    f = relay.Function([x, y], concat)\n",
    "    mod = tvm.IRModule()\n",
    "    mod[\"main\"] = f\n",
    "    mod = AllowedListAnnotator([\"add\", \"subtract\", \"multiply\"], \"unsanitary-name++\")(mod)\n",
    "    mod = transform.PartitionGraph()(mod)\n",
    "    fused_mod = transform.FuseOps(2)(mod)\n",
    "    expected_mod = expected()\n",
    "    assert tvm.ir.structural_equal(fused_mod, expected_mod, map_free_vars=True)\n",
    "\n",
    "\n",
    "def test_extern_ccompiler_multiple_functions():\n",
    "    def expected():\n",
    "        mod = tvm.IRModule()\n",
    "        x = relay.var(\"x\", shape=(8, 8))\n",
    "        y = relay.var(\"y\", shape=(8, 8))\n",
    "        x0 = relay.var(\"x0\", shape=(8, 8))\n",
    "        y0 = relay.var(\"y0\", shape=(8, 8))\n",
    "        add = x0 + y0\n",
    "        # Function that uses C compiler\n",
    "        func = relay.Function([x0, y0], add)\n",
    "        func = set_func_attr(func, \"ccompiler\", \"tvmgen_default_ccompiler_main_0\")\n",
    "        glb_0 = relay.GlobalVar(\"tvmgen_default_ccompiler_main_0\")\n",
    "        mod[glb_0] = func\n",
    "        add_call = relay.Call(glb_0, [x, y])\n",
    "        # Function that uses default compiler. Ops are fused in this function.\n",
    "        p0 = relay.var(\"p0\", shape=(8, 8))\n",
    "        log = relay.log(p0)\n",
    "        exp = relay.exp(p0)\n",
    "        concat = relay.concatenate([log, exp], axis=0)\n",
    "        fused_func = relay.Function([p0], concat)\n",
    "        fused_func = fused_func.with_attr(\"Primitive\", tvm.tir.IntImm(\"int32\", 1))\n",
    "        fused_call = relay.Call(fused_func, [add_call])\n",
    "        main = relay.Function([x, y], fused_call)\n",
    "        mod[\"main\"] = main\n",
    "        # define the second one\n",
    "        a = relay.var(\"a\", shape=(16, 16))\n",
    "        b = relay.var(\"b\", shape=(16, 16))\n",
    "        a0 = relay.var(\"a0\", shape=(16, 16))\n",
    "        b0 = relay.var(\"b0\", shape=(16, 16))\n",
    "        add = a0 + b0\n",
    "        # Function that uses C compiler\n",
    "        func = relay.Function([a0, b0], add)\n",
    "        func = set_func_attr(func, \"ccompiler\", \"tvmgen_default_ccompiler_subfunction_0\")\n",
    "        glb_0 = relay.GlobalVar(\"tvmgen_default_ccompiler_subfunction_0\")\n",
    "        mod[glb_0] = func\n",
    "        add_call = relay.Call(glb_0, [a, b])\n",
    "        # Function that uses default compiler. Ops are fused in this function.\n",
    "        p0 = relay.var(\"p0\", shape=(16, 16))\n",
    "        log = relay.log(p0)\n",
    "        exp = relay.exp(p0)\n",
    "        concat = relay.concatenate([log, exp], axis=0)\n",
    "        fused_func = relay.Function([p0], concat)\n",
    "        fused_func = fused_func.with_attr(\"Primitive\", tvm.tir.IntImm(\"int32\", 1))\n",
    "        fused_call = relay.Call(fused_func, [add_call])\n",
    "        sunfunction = relay.Function([a, b], fused_call)\n",
    "        mod[\"subfunction\"] = sunfunction\n",
    "        mod = transform.InferType()(mod)\n",
    "        return mod\n",
    "\n",
    "    x = relay.var(\"x\", shape=(8, 8))\n",
    "    y = relay.var(\"y\", shape=(8, 8))\n",
    "    add = x + y\n",
    "    log = relay.log(add)\n",
    "    exp = relay.exp(add)\n",
    "    concat = relay.concatenate([log, exp], axis=0)\n",
    "    f = relay.Function([x, y], concat)\n",
    "    mod = tvm.IRModule()\n",
    "    mod[\"main\"] = f\n",
    "    # define second function\n",
    "    a = relay.var(\"a\", shape=(16, 16))\n",
    "    b = relay.var(\"b\", shape=(16, 16))\n",
    "    add = a + b\n",
    "    log = relay.log(add)\n",
    "    exp = relay.exp(add)\n",
    "    concat = relay.concatenate([log, exp], axis=0)\n",
    "    f2 = relay.Function([a, b], concat)\n",
    "    mod[\"subfunction\"] = f2\n",
    "    mod = AllowedListAnnotator([\"add\", \"subtract\", \"multiply\"], \"ccompiler\")(mod)\n",
    "    mod = transform.PartitionGraph()(mod)\n",
    "\n",
    "    fused_mod = transform.FuseOps(2)(mod)\n",
    "    expected_mod = expected()\n",
    "    assert tvm.ir.structural_equal(fused_mod, expected_mod, map_free_vars=True)\n",
    "\n",
    "    x_data = np.random.rand(8, 8).astype(\"float32\")\n",
    "    y_data = np.random.rand(8, 8).astype(\"float32\")\n",
    "    np_add = x_data + y_data\n",
    "    res = np.concatenate([np.log(np_add), np.exp(np_add)])\n",
    "    check_result(mod, {\"x\": x_data, \"y\": y_data}, (16, 8), res)\n",
    "\n",
    "\n",
    "def test_extern_ccompiler():\n",
    "    x = relay.var(\"x\", shape=(2, 2))\n",
    "    y = relay.var(\"y\", shape=(2, 2))\n",
    "    z = x + x\n",
    "    p = y * y\n",
    "    f = relay.Function([x, y], p - z)\n",
    "    x_data = np.random.rand(2, 2).astype(\"float32\")\n",
    "    y_data = np.random.rand(2, 2).astype(\"float32\")\n",
    "    mod = tvm.IRModule()\n",
    "    mod[\"main\"] = f\n",
    "    mod = AllowedListAnnotator([\"add\", \"subtract\", \"multiply\"], \"ccompiler\")(mod)\n",
    "    mod = transform.PartitionGraph()(mod)\n",
    "\n",
    "    check_result(mod, {\"x\": x_data, \"y\": y_data}, (2, 2), (y_data * y_data) - (x_data + x_data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WholeGraphAnnotator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WholeGraphAnnotator(ExprMutator):\n",
    "    \"\"\"\n",
    "    An annotator that creates a compiler for an entire graph.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, compiler):\n",
    "        super().__init__()\n",
    "        self.compiler = compiler\n",
    "        self.last_call = True\n",
    "\n",
    "    def visit_call(self, call):\n",
    "        curr_last = self.last_call\n",
    "        self.last_call = False\n",
    "\n",
    "        params = []\n",
    "        for arg in call.args:\n",
    "            param = super().visit(arg)\n",
    "            if isinstance(param, relay.expr.Var):\n",
    "                param = compiler_begin(param, self.compiler)\n",
    "            params.append(param)\n",
    "\n",
    "        new_call = relay.Call(call.op, params, call.attrs)\n",
    "        if curr_last:\n",
    "            new_call = compiler_end(new_call, self.compiler)\n",
    "        return new_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = \"float32\"\n",
    "ishape = (1, 32, 14, 14)\n",
    "w1shape = (32, 1, 3, 3)\n",
    "def get_func():\n",
    "    data = relay.var(\"data\", shape=(ishape), dtype=dtype)\n",
    "    weight1 = relay.var(\"weight1\", shape=(w1shape), dtype=dtype)\n",
    "    depthwise_conv2d_1 = relay.nn.conv2d(\n",
    "        data, weight1, kernel_size=(3, 3), padding=(1, 1), groups=32\n",
    "    )\n",
    "    depthwise_conv2d_2 = relay.nn.conv2d(\n",
    "        depthwise_conv2d_1, weight1, kernel_size=(3, 3), padding=(1, 1), groups=32\n",
    "    )\n",
    "    out = relay.add(depthwise_conv2d_1, depthwise_conv2d_2)\n",
    "\n",
    "    return relay.Function([data, weight1], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = get_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = tvm.IRModule()\n",
    "mod[\"main\"] = WholeGraphAnnotator(\"dnnl\").visit(get_func())\n",
    "mod = transform.PartitionGraph()(mod)\n",
    "mod = transform.InferType()(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%data: Tensor[(1, 32, 14, 14), float32] /* ty=Tensor[(1, 32, 14, 14), float32] */, %weight1: Tensor[(32, 1, 3, 3), float32] /* ty=Tensor[(32, 1, 3, 3), float32] */) -> Tensor[(1, 32, 14, 14), float32] {\n",
      "  @tvmgen_default_dnnl_main_0(%data, %weight1) /* ty=Tensor[(1, 32, 14, 14), float32] */\n",
      "}\n",
      "\n",
      "def @tvmgen_default_dnnl_main_0(%dnnl_0_i0: Tensor[(1, 32, 14, 14), float32] /* ty=Tensor[(1, 32, 14, 14), float32] */, %dnnl_0_i1: Tensor[(32, 1, 3, 3), float32] /* ty=Tensor[(32, 1, 3, 3), float32] */, Compiler=\"dnnl\", Primitive=1, Inline=1, global_symbol=\"tvmgen_default_dnnl_main_0\") -> Tensor[(1, 32, 14, 14), float32] {\n",
      "  %0 = nn.conv2d(%dnnl_0_i0, %dnnl_0_i1, padding=[1, 1, 1, 1], groups=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 14, 14), float32] */;\n",
      "  %1 = nn.conv2d(%0, %dnnl_0_i1, padding=[1, 1, 1, 1], groups=32, kernel_size=[3, 3]) /* ty=Tensor[(1, 32, 14, 14), float32] */;\n",
      "  add(%0, %1) /* ty=Tensor[(1, 32, 14, 14), float32] */\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 函数 lifting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = relay.var(\"data\", relay.TensorType((1, 3, 224, 224), \"float32\"))\n",
    "weight = relay.var(\"weight\", relay.TensorType((16, 3, 3, 3), \"float32\"))\n",
    "bn_gamma = relay.var(\"bn_gamma\", relay.TensorType((16,), \"float32\"))\n",
    "bn_beta = relay.var(\"bn_beta\", relay.TensorType((16,), \"float32\"))\n",
    "bn_mmean = relay.var(\"bn_mean\", relay.TensorType((16,), \"float32\"))\n",
    "bn_mvar = relay.var(\"bn_var\", relay.TensorType((16,), \"float32\"))\n",
    "\n",
    "conv = relay.nn.conv2d(\n",
    "    data=data, weight=weight, kernel_size=(3, 3), channels=16, padding=(1, 1)\n",
    ")\n",
    "bn_output = relay.nn.batch_norm(conv, bn_gamma, bn_beta, bn_mmean, bn_mvar)\n",
    "\n",
    "func = relay.Function(\n",
    "    [data, weight, bn_gamma, bn_beta, bn_mmean, bn_mvar], bn_output.astuple()\n",
    ")\n",
    "mod = tvm.IRModule()\n",
    "mod[\"main\"] = func\n",
    "mod = relay.transform.InferType()(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
      "To print formatted TVM script, please install the formatter 'Black':\n",
      "/media/pc/data/tmp/cache/conda/envs/tvmz/bin/python -m pip install \"black==22.3.0\" --upgrade --user\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>data: Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>weight: Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_gamma: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_beta: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_mean: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_var: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> (Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32]) {\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>conv2d(<span style=\"color: #AA22FF; font-weight: bold\">%</span>data, <span style=\"color: #AA22FF; font-weight: bold\">%</span>weight, padding<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], channels<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">16</span>, kernel_size<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>]) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>batch_norm(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_gamma, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_beta, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_mean, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_var) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>(Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32]) <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_list = [\"nn.batch_norm\", \"nn.conv2d\"]\n",
    "mod = AllowedListAnnotator(op_list, \"test_compiler\")(mod)\n",
    "\n",
    "opt_pass = tvm.transform.Sequential(\n",
    "    [\n",
    "        transform.InferType(),\n",
    "        transform.PartitionGraph(),\n",
    "        transform.SimplifyInference(),\n",
    "        transform.FoldConstant(),\n",
    "        transform.AlterOpLayout(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    mod = opt_pass(mod)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
      "To print formatted TVM script, please install the formatter 'Black':\n",
      "/media/pc/data/tmp/cache/conda/envs/tvmz/bin/python -m pip install \"black==22.3.0\" --upgrade --user\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>data: Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>weight: Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_gamma: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_beta: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_mean: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_var: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> (Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32]) {\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> <span style=\"color: #AA22FF\">@tvmgen_default_test_compiler_main_0</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>data, <span style=\"color: #AA22FF; font-weight: bold\">%</span>weight) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF\">@tvmgen_default_test_compiler_main_2</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_gamma, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_beta, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_mean, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_var) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>(Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32]) <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@tvmgen_default_test_compiler_main_0</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_0_i0: Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_0_i1: Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, Compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;test_compiler&quot;</span>, Primitive<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, Inline<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, global_symbol<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;tvmgen_default_test_compiler_main_0&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] {\n",
       "  nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>conv2d(<span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_0_i0, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_0_i1, padding<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], channels<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">16</span>, kernel_size<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>]) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@tvmgen_default_test_compiler_main_2</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_2_i0: Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_2_i1: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_2_i2: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_2_i3: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_2_i4: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, Compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;test_compiler&quot;</span>, Primitive<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, Inline<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, global_symbol<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;tvmgen_default_test_compiler_main_2&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> (Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32]) {\n",
       "  nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>batch_norm(<span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_2_i0, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_2_i1, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_2_i2, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_2_i3, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_2_i4) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>(Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32]) <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = relay.var(\"data\", relay.TensorType((1, 16, 224, 224), \"float32\"))\n",
    "bn_gamma = relay.var(\"bn_gamma\", relay.TensorType((16,), \"float32\"))\n",
    "bn_beta = relay.var(\"bn_beta\", relay.TensorType((16,), \"float32\"))\n",
    "bn_mmean = relay.var(\"bn_mean\", relay.TensorType((16,), \"float32\"))\n",
    "bn_mvar = relay.var(\"bn_var\", relay.TensorType((16,), \"float32\"))\n",
    "\n",
    "bn_output = relay.nn.batch_norm(data, bn_gamma, bn_beta, bn_mmean, bn_mvar)\n",
    "\n",
    "func = relay.Function([data, bn_gamma, bn_beta, bn_mmean, bn_mvar], bn_output.astuple())\n",
    "mod = tvm.IRModule()\n",
    "mod[\"main\"] = func\n",
    "op_list = [\"nn.batch_norm\", \"nn.conv2d\"]\n",
    "mod = AllowedListAnnotator(op_list, \"test_compiler\")(mod)\n",
    "\n",
    "opt_pass = tvm.transform.Sequential(\n",
    "    [\n",
    "        transform.InferType(),\n",
    "        transform.PartitionGraph(),\n",
    "        transform.SimplifyInference(),\n",
    "        transform.FoldConstant(),\n",
    "        transform.AlterOpLayout(),\n",
    "        transform.Inline(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    mod = opt_pass(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
      "To print formatted TVM script, please install the formatter 'Black':\n",
      "/media/pc/data/tmp/cache/conda/envs/tvmz/bin/python -m pip install \"black==22.3.0\" --upgrade --user\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>data: Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_gamma: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_beta: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_mean: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_var: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> (Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32]) {\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> fn (<span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_0_i0: Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_0_i1: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_0_i2: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_0_i3: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_0_i4: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, Compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;test_compiler&quot;</span>, Primitive<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, Inline<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, global_symbol<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;tvmgen_default_test_compiler_main_0&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> (Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32]) {\n",
       "    nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>batch_norm(<span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_0_i0, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_0_i1, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_0_i2, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_0_i3, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_compiler_0_i4) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>(Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32]) <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "  };\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>data, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_gamma, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_beta, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_mean, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_var)\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## constant_propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = np.ones(shape=(8, 8), dtype=\"float32\")\n",
    "x = relay.var(\"x\", shape=(8, 8))\n",
    "y = relay.var(\"y\", shape=(8, 8))\n",
    "add = x + y\n",
    "log = relay.log(add)\n",
    "f = relay.Function([x, y], log)\n",
    "f = bind_params_by_name(f, {\"x\": tvm.nd.array(ones)})\n",
    "mod = tvm.IRModule()\n",
    "mod[\"main\"] = f\n",
    "mod = AllowedListAnnotator([\"add\"], \"ccompiler\")(mod)\n",
    "mod = transform.PartitionGraph()(mod)\n",
    "mod = relay.transform.InferType()(mod)\n",
    "\n",
    "y_data = np.random.rand(8, 8).astype(\"float32\")\n",
    "np_add = ones + y_data\n",
    "check_result(mod, {\"y\": y_data}, (8, 8), np.log(np_add))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 多输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph():\n",
    "    data = relay.var(\"data\", relay.TensorType((1, 3, 224, 224), \"float32\"))\n",
    "    weight = relay.var(\"weight\", relay.TensorType((16, 3, 3, 3), \"float32\"))\n",
    "    bn_gamma = relay.var(\"bn_gamma\", relay.TensorType((16,), \"float32\"))\n",
    "    bn_beta = relay.var(\"bn_beta\", relay.TensorType((16,), \"float32\"))\n",
    "    bn_mean = relay.var(\"bn_mean\", relay.TensorType((16,), \"float32\"))\n",
    "    bn_var = relay.var(\"bn_var\", relay.TensorType((16,), \"float32\"))\n",
    "\n",
    "    data_cb = compiler_begin(data, \"test_target\")\n",
    "    weight_cb = compiler_begin(weight, \"test_target\")\n",
    "    bn_gamma_cb = compiler_begin(bn_gamma, \"test_target\")\n",
    "    bn_beta_cb = compiler_begin(bn_beta, \"test_target\")\n",
    "    bn_mean_cb = compiler_begin(bn_mean, \"test_target\")\n",
    "    bn_var_cb = compiler_begin(bn_var, \"test_target\")\n",
    "\n",
    "    conv_o = relay.nn.conv2d(\n",
    "        data=data_cb, weight=weight_cb, kernel_size=(3, 3), channels=16, padding=(1, 1)\n",
    "    )\n",
    "\n",
    "    bn_o = relay.nn.batch_norm(conv_o, bn_gamma_cb, bn_beta_cb, bn_mean_cb, bn_var_cb)\n",
    "\n",
    "    relu_o = relay.nn.relu(bn_o[0])\n",
    "    relu_o_ce = compiler_end(relu_o, \"test_target\")\n",
    "\n",
    "    bn_omean = bn_o[1]\n",
    "    rebn_omean_ce = compiler_end(bn_omean, \"test_target\")\n",
    "    bn_ovar = bn_o[2]\n",
    "    bn_ovar_ce = compiler_end(bn_ovar, \"test_target\")\n",
    "\n",
    "    dummy_mean_abs = relay.abs(rebn_omean_ce)\n",
    "    dummy_ovar_abs = relay.abs(bn_ovar_ce)\n",
    "    dummy_tuple = relay.Tuple((relu_o_ce, dummy_mean_abs, dummy_ovar_abs))\n",
    "\n",
    "    func = relay.Function([data, weight, bn_gamma, bn_beta, bn_mean, bn_var], dummy_tuple)\n",
    "    return func\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = tvm.IRModule()\n",
    "mod[\"main\"] = create_graph()\n",
    "partitioned = transform.PartitionGraph()(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
      "To print formatted TVM script, please install the formatter 'Black':\n",
      "/media/pc/data/tmp/cache/conda/envs/tvmz/bin/python -m pip install \"black==22.3.0\" --upgrade --user\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>data: Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>weight: Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_gamma: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_beta: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_mean: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_var: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> (Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32]) {\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> <span style=\"color: #AA22FF\">@tvmgen_default_test_target_main_0</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>data, <span style=\"color: #AA22FF; font-weight: bold\">%</span>weight, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_gamma, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_beta, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_mean, <span style=\"color: #AA22FF; font-weight: bold\">%</span>bn_var) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>(Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32]) <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0.1</span> <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0.2</span> <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">3</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0.0</span> <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">4</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> abs(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">5</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> abs(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">2</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  (<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">3</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">4</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">5</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>(Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32]) <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@tvmgen_default_test_target_main_0</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>test_target_0_i0: Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_target_0_i1: Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_target_0_i2: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_target_0_i3: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_target_0_i4: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_target_0_i5: Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, Compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;test_target&quot;</span>, Primitive<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, Inline<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, global_symbol<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;tvmgen_default_test_target_main_0&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> (Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32]) {\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">6</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>conv2d(<span style=\"color: #AA22FF; font-weight: bold\">%</span>test_target_0_i0, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_target_0_i1, padding<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], channels<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">16</span>, kernel_size<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>]) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">7</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>batch_norm(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">6</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_target_0_i2, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_target_0_i3, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_target_0_i4, <span style=\"color: #AA22FF; font-weight: bold\">%</span>test_target_0_i5) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>(Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32]) <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">8</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">7.0</span> <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">9</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>relu(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">8</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">10</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">7.1</span> <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">11</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">7.2</span> <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  (<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">9</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">10</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">11</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>(Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32], Tensor[(<span style=\"color: #008000\">16</span>), float32]) <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "partitioned.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mixed_single_multiple_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph():\n",
    "    data = relay.var(\"data\", shape=(10, 10))\n",
    "\n",
    "    cb_1 = compiler_begin(data, \"test_target\")\n",
    "    O_1 = relay.abs(cb_1)\n",
    "    ce_2 = compiler_end(O_1, \"test_target\")\n",
    "    O_2 = relay.nn.relu(O_1)\n",
    "    ce_3 = compiler_end(O_2, \"test_target\")\n",
    "\n",
    "    X = relay.tanh(ce_2)\n",
    "\n",
    "    cb_3 = compiler_begin(ce_3, \"test_target\")\n",
    "    cb_4 = compiler_begin(X, \"test_target\")\n",
    "    O_3 = relay.add(cb_3, cb_4)\n",
    "    ce_4 = compiler_end(O_3, \"test_target\")\n",
    "\n",
    "    func = relay.Function([data], ce_4)\n",
    "    return func\n",
    "\n",
    "mod = tvm.IRModule()\n",
    "mod[\"main\"] = create_graph()\n",
    "mod = transform.InferType()(mod)\n",
    "\n",
    "partitioned = transform.PartitionGraph()(mod)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## multiple_use_of_an_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_multiple_use_of_an_output():\n",
    "    def expected_same_output_region():\n",
    "        mod = tvm.IRModule()\n",
    "        x = relay.var(\"x\", shape=(8, 8))\n",
    "        y = relay.var(\"y\", shape=(8, 8))\n",
    "        z = relay.var(\"z\", shape=(8, 8))\n",
    "        x0 = relay.var(\"x0\", shape=(8, 8))\n",
    "        y0 = relay.var(\"y0\", shape=(8, 8))\n",
    "        log = relay.log(x0)\n",
    "        sub = x0 - y0\n",
    "        mul = log * sub\n",
    "        # The partitioned graph contains log, subtract, and multiply\n",
    "        func = relay.Function([x0, y0], mul)\n",
    "        func = set_func_attr(func, \"ccompiler\", \"tvmgen_default_ccompiler_main_0\")\n",
    "        glb_0 = relay.GlobalVar(\"tvmgen_default_ccompiler_main_0\")\n",
    "        mod[glb_0] = func\n",
    "        mod = transform.InferType()(mod)\n",
    "\n",
    "        add = x + y\n",
    "        call = relay.Call(glb_0, [add, z])\n",
    "        main = relay.Function([x, y, z], call)\n",
    "        mod[\"main\"] = main\n",
    "        mod = transform.InferType()(mod)\n",
    "        return mod\n",
    "\n",
    "    def expected_different_output_region():\n",
    "        mod = tvm.IRModule()\n",
    "        x = relay.var(\"x\", shape=(8, 8))\n",
    "        y = relay.var(\"y\", shape=(8, 8))\n",
    "        z = relay.var(\"z\", shape=(8, 8))\n",
    "\n",
    "        # The partitioned graph contains log\n",
    "        i0 = relay.var(\"i0\", shape=(8, 8))\n",
    "        log = relay.log(i0)\n",
    "        func = relay.Function([i0], log)\n",
    "        func = set_func_attr(func, \"ccompiler\", \"tvmgen_default_ccompiler_main_0\")\n",
    "        glb_0 = relay.GlobalVar(\"tvmgen_default_ccompiler_main_0\")\n",
    "        mod[glb_0] = func\n",
    "        mod = transform.InferType()(mod)\n",
    "\n",
    "        # The partitioned graph contains subtract\n",
    "        x0 = relay.var(\"x0\", shape=(8, 8))\n",
    "        y0 = relay.var(\"y0\", shape=(8, 8))\n",
    "        sub = x0 - y0\n",
    "        func = relay.Function([x0, y0], sub)\n",
    "        func = set_func_attr(func, \"ccompiler\", \"tvmgen_default_ccompiler_main_1\")\n",
    "        glb_1 = relay.GlobalVar(\"tvmgen_default_ccompiler_main_1\")\n",
    "        mod[glb_1] = func\n",
    "        mod = transform.InferType()(mod)\n",
    "\n",
    "        add = x + y\n",
    "        call_log = relay.Call(glb_0, [add])\n",
    "        call_sub = relay.Call(glb_1, [add, z])\n",
    "        main = relay.Function([x, y, z], call_log * call_sub)\n",
    "        mod[\"main\"] = main\n",
    "        mod = transform.InferType()(mod)\n",
    "        return mod\n",
    "\n",
    "    def get_mod():\n",
    "        x = relay.var(\"x\", shape=(8, 8))\n",
    "        y = relay.var(\"y\", shape=(8, 8))\n",
    "        z = relay.var(\"z\", shape=(8, 8))\n",
    "        add = x + y\n",
    "        sub = add - z\n",
    "        log = relay.log(add)\n",
    "        sub1 = log * sub\n",
    "        f = relay.Function([x, y, z], sub1)\n",
    "        mod = tvm.IRModule()\n",
    "        mod[\"main\"] = f\n",
    "        return mod\n",
    "\n",
    "    def test_same_output_region():\n",
    "        mod = get_mod()\n",
    "        mod = AllowedListAnnotator([\"subtract\", \"log\", \"multiply\"], \"ccompiler\")(mod)\n",
    "        mod = transform.MergeCompilerRegions()(mod)\n",
    "        mod = transform.PartitionGraph()(mod)\n",
    "\n",
    "        expected_mod = expected_same_output_region()\n",
    "        assert tvm.ir.structural_equal(mod, expected_mod, map_free_vars=True)\n",
    "\n",
    "    def test_different_output_region():\n",
    "        mod = get_mod()\n",
    "        mod = AllowedListAnnotator([\"subtract\", \"log\"], \"ccompiler\")(mod)\n",
    "        mod = transform.MergeCompilerRegions()(mod)\n",
    "        mod = transform.PartitionGraph()(mod)\n",
    "\n",
    "        expected_mod = expected_different_output_region()\n",
    "        assert tvm.ir.structural_equal(mod, expected_mod, map_free_vars=True)\n",
    "\n",
    "    test_same_output_region()\n",
    "    test_different_output_region()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_multiple_use_of_an_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_duplicate_outputs():\n",
    "    target = \"test_duplicate_outputs\"\n",
    "\n",
    "    @tvm.ir.register_op_attr(\"abs\", \"target.\" + target)\n",
    "    def abs(expr):  # pylint: disable=unused-variable\n",
    "        return True\n",
    "\n",
    "    def create_graph():\n",
    "        data = relay.var(\"data\", shape=(10, 10))\n",
    "        x = relay.abs(data)\n",
    "        out_1 = relay.nn.relu(x)\n",
    "        out_2 = relay.tanh(x)\n",
    "        out_3 = relay.log(x)\n",
    "        out = relay.Tuple([out_1, out_2, out_3])\n",
    "        func = relay.Function([data], out)\n",
    "        return func\n",
    "\n",
    "    def expected():\n",
    "        mod = tvm.IRModule()\n",
    "\n",
    "        # function 0\n",
    "        f0_i0 = relay.var(target + \"_0_i0\", shape=(10, 10))\n",
    "        f0_o0 = relay.abs(f0_i0)\n",
    "        func0 = relay.Function([f0_i0], f0_o0)\n",
    "\n",
    "        func0 = func0.with_attr(\"Primitive\", tvm.tir.IntImm(\"int32\", 1))\n",
    "        func0 = func0.with_attr(\"Inline\", tvm.tir.IntImm(\"int32\", 1))\n",
    "        func0 = func0.with_attr(\"Compiler\", target)\n",
    "        func0 = func0.with_attr(\"global_symbol\", \"tvmgen_default_\" + target + \"_main_0\")\n",
    "        gv0 = relay.GlobalVar(\"tvmgen_default_\" + target + \"_main_0\")\n",
    "        mod[gv0] = func0\n",
    "        mod = transform.InferType()(mod)\n",
    "\n",
    "        # body\n",
    "        data = relay.var(\"data\", shape=(10, 10))\n",
    "        function_out = gv0(data)\n",
    "        out_1 = relay.nn.relu(function_out)\n",
    "        out_2 = relay.tanh(function_out)\n",
    "        out_3 = relay.log(function_out)\n",
    "        out = relay.Tuple([out_1, out_2, out_3])\n",
    "        func = relay.Function([data], out)\n",
    "        mod[\"main\"] = func\n",
    "        mod = transform.InferType()(mod)\n",
    "        return mod\n",
    "\n",
    "    mod = tvm.IRModule()\n",
    "    mod[\"main\"] = create_graph()\n",
    "\n",
    "    seq = tvm.transform.Sequential(\n",
    "        [\n",
    "            transform.AnnotateTarget(target),\n",
    "            transform.MergeCompilerRegions(),\n",
    "            transform.PartitionGraph(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    ref_mod = expected()\n",
    "    partitioned = seq(mod)\n",
    "    assert tvm.ir.structural_equal(partitioned, ref_mod, map_free_vars=True)\n",
    "\n",
    "test_duplicate_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_constant_tuples():\n",
    "    @tvm.ir.register_op_attr(\"qnn.concatenate\", \"target.const_tuples\")\n",
    "    def add(expr):  # pylint: disable=unused-variable\n",
    "        return True\n",
    "\n",
    "    def create_graph():\n",
    "        a = relay.var(\"a\", shape=(10, 10), dtype=\"uint8\")\n",
    "        b = relay.var(\"b\", shape=(10, 10), dtype=\"uint8\")\n",
    "        a1 = relay.abs(a)\n",
    "\n",
    "        zeroi = relay.const(1, \"int32\")\n",
    "        zerof = relay.const(0, \"float32\")\n",
    "        con = relay.qnn.op.concatenate(\n",
    "            (a1, b),\n",
    "            input_scales=(zerof, zerof),\n",
    "            input_zero_points=(zeroi, zeroi),\n",
    "            output_scale=zerof,\n",
    "            output_zero_point=zeroi,\n",
    "            axis=1,\n",
    "        )\n",
    "\n",
    "        f = relay.Function([a, b], con)\n",
    "        mod = tvm.IRModule.from_expr(f)\n",
    "        mod = transform.InferType()(mod)\n",
    "        return mod\n",
    "\n",
    "    seq = tvm.transform.Sequential(\n",
    "        [\n",
    "            transform.AnnotateTarget(\"const_tuples\"),\n",
    "            transform.InferType(),\n",
    "            transform.MergeCompilerRegions(),\n",
    "            transform.PartitionGraph(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    partitioned = seq(create_graph())\n",
    "\n",
    "    concat = partitioned[\"tvmgen_default_const_tuples_main_0\"].body\n",
    "    assert type(concat.args[1]) == relay.Tuple\n",
    "    assert type(concat.args[2]) == relay.Tuple\n",
    "    assert type(concat.args[3]) == relay.Constant\n",
    "    assert type(concat.args[4]) == relay.Constant\n",
    "\n",
    "\n",
    "def test_flatten_tuple_output():\n",
    "    target = \"test_flatten_tuple_output\"\n",
    "\n",
    "    @tvm.ir.register_op_attr(\"split\", \"target.\" + target)\n",
    "    def split(expr):  # pylint: disable=unused-variable\n",
    "        return True\n",
    "\n",
    "    @tvm.ir.register_op_attr(\"abs\", \"target.\" + target)\n",
    "    def abs(expr):  # pylint: disable=unused-variable\n",
    "        return True\n",
    "\n",
    "    def create_graph():\n",
    "        a = relay.var(\"a\", shape=(10, 10), dtype=\"uint8\")\n",
    "\n",
    "        a_split = relay.split(a, 2)\n",
    "        a_split_0 = relay.TupleGetItem(a_split.astuple(), 0)\n",
    "        a_split_0_abs = relay.abs(a_split_0)\n",
    "\n",
    "        a_con = relay.concatenate(a_split, 0)\n",
    "        a_split_0_relu = relay.nn.relu(a_split_0_abs)\n",
    "\n",
    "        out = relay.Tuple((a_con, a_split_0_relu))\n",
    "        f = relay.Function([a], out)\n",
    "        mod = tvm.IRModule.from_expr(f)\n",
    "        mod = transform.InferType()(mod)\n",
    "        return mod\n",
    "\n",
    "    def expected():\n",
    "        mod = tvm.IRModule()\n",
    "\n",
    "        # function 0\n",
    "        f0_i0 = relay.var(target + \"_0_i0\", shape=(10, 10), dtype=\"uint8\")\n",
    "        a_split = relay.split(f0_i0, 2)\n",
    "        a_split_0 = relay.TupleGetItem(a_split.astuple(), 0)\n",
    "        a_split_1 = relay.TupleGetItem(a_split.astuple(), 1)\n",
    "        a_split_abs_in = relay.TupleGetItem(a_split.astuple(), 0)\n",
    "        abs = relay.abs(a_split_abs_in)\n",
    "        tuple_out = relay.Tuple((a_split_0, a_split_1, abs))\n",
    "        func0 = relay.Function([f0_i0], tuple_out)\n",
    "\n",
    "        func0 = func0.with_attr(\"Primitive\", tvm.tir.IntImm(\"int32\", 1))\n",
    "        func0 = func0.with_attr(\"Inline\", tvm.tir.IntImm(\"int32\", 1))\n",
    "        func0 = func0.with_attr(\"Compiler\", target)\n",
    "        func0 = func0.with_attr(\"global_symbol\", \"tvmgen_default_\" + target + \"_main_0\")\n",
    "        gv0 = relay.GlobalVar(\"tvmgen_default_\" + target + \"_main_0\")\n",
    "        mod[gv0] = func0\n",
    "        mod = transform.InferType()(mod)\n",
    "\n",
    "        # body\n",
    "        data = relay.var(\"a\", shape=(10, 10), dtype=\"uint8\")\n",
    "        f_out = gv0(data)\n",
    "        f_out_0 = relay.TupleGetItem(f_out, 0)\n",
    "        f_out_1 = relay.TupleGetItem(f_out, 1)\n",
    "        tuple = relay.Tuple((f_out_0, f_out_1))\n",
    "        concat = relay.concatenate(tuple, 0)\n",
    "        f_out_2 = relay.TupleGetItem(f_out, 2)\n",
    "        relu = relay.nn.relu(f_out_2)\n",
    "        ret_tuple = relay.Tuple((concat, relu))\n",
    "        mod[\"main\"] = relay.Function([data], ret_tuple)\n",
    "        mod = transform.InferType()(mod)\n",
    "        return mod\n",
    "\n",
    "    seq = tvm.transform.Sequential(\n",
    "        [\n",
    "            transform.AnnotateTarget(target),\n",
    "            transform.MergeCompilerRegions(),\n",
    "            transform.PartitionGraph(),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    partitioned = seq(create_graph())\n",
    "    partitioned = transform.InferType()(partitioned)\n",
    "    expected_mod = transform.InferType()(expected())\n",
    "    assert tvm.ir.structural_equal(partitioned, expected_mod, map_free_vars=True)\n",
    "\n",
    "\n",
    "def test_tuple_output_exec():\n",
    "    \"\"\"Test C codegen and runtime for a subgraph with a tuple output\"\"\"\n",
    "    a = relay.var(\"a\", shape=(10, 10), dtype=\"float32\")\n",
    "    b = relay.var(\"b\", shape=(10, 10), dtype=\"float32\")\n",
    "    ba = relay.annotation.compiler_begin(a, \"ccompiler\")\n",
    "    bb = relay.annotation.compiler_begin(b, \"ccompiler\")\n",
    "    add = relay.add(ba, bb)\n",
    "    sub = relay.subtract(ba, bb)\n",
    "    out = relay.Tuple((add, sub))\n",
    "    eout = relay.annotation.compiler_end(out, \"ccompiler\")\n",
    "    func = relay.Function([a, b], eout)\n",
    "\n",
    "    mod = tvm.IRModule()\n",
    "    mod[\"main\"] = func\n",
    "    mod = transform.InferType()(mod)\n",
    "    mod = transform.PartitionGraph()(mod)\n",
    "\n",
    "    a_data = np.random.rand(10, 10).astype(\"float32\")\n",
    "    b_data = np.random.rand(10, 10).astype(\"float32\")\n",
    "\n",
    "    check_result(\n",
    "        mod,\n",
    "        {\"a\": a_data, \"b\": b_data},\n",
    "        [(10, 10), (10, 10)],\n",
    "        [(a_data + b_data), (a_data - b_data)],\n",
    "    )\n",
    "\n",
    "\n",
    "def test_extern_opt():\n",
    "    def Optimize(mod):\n",
    "        return relay.transform.FoldConstant()(mod)\n",
    "\n",
    "    tvm.register_func(\"relay.ext.test_target.optimize\", Optimize)\n",
    "\n",
    "    x = relay.var(\"x\", shape=(2, 2))\n",
    "    y0 = relay.var(\"y0\", shape=(2, 2))\n",
    "    y1 = relay.var(\"y1\", shape=(2, 2))\n",
    "    yy0 = relay.annotation.compiler_begin(y0, \"test_target\")\n",
    "    yy1 = relay.annotation.compiler_begin(y1, \"test_target\")\n",
    "    z = yy0 + yy1\n",
    "    end = relay.annotation.compiler_end(z, \"test_target\")\n",
    "    f = relay.Function([x, y0, y1], end * x)\n",
    "    c = np.ones(shape=(2, 2), dtype=\"float32\")\n",
    "    f = bind_params_by_name(f, {\"y0\": tvm.nd.array(c), \"y1\": tvm.nd.array(c)})\n",
    "    mod = tvm.IRModule()\n",
    "    mod[\"main\"] = f\n",
    "    mod = transform.InferType()(mod)\n",
    "    mod = transform.PartitionGraph()(mod)\n",
    "\n",
    "    try:\n",
    "        t0 = mod[\"tvmgen_default_test_target_main_0\"]\n",
    "    except:\n",
    "        raise KeyError(\"test_target_main_0 not found\")\n",
    "\n",
    "    assert isinstance(t0.body, relay.Constant)\n",
    "    expected = np.empty([2, 2])\n",
    "    expected.fill(2)\n",
    "    tvm.testing.assert_allclose(t0.body.data.numpy(), expected, rtol=1e-5, atol=1e-5)\n",
    "\n",
    "\n",
    "def test_preserve_type_import():\n",
    "    \"\"\"Test to make sure type definition and imports are preserved during the BYOC pipeline.\"\"\"\n",
    "    from tvm.relay.prelude import Prelude, StaticTensorArrayOps\n",
    "\n",
    "    def run(dtype, shape):\n",
    "        mod = tvm.IRModule()\n",
    "        p = Prelude(mod)\n",
    "        static_tensor_array_ops = StaticTensorArrayOps(p, dtype, shape)\n",
    "        static_tensor_array_ops.register()\n",
    "\n",
    "        tensor_array = p.get_global_var_static(\"tensor_array\", dtype, shape)\n",
    "        tensor = p.get_tensor_ctor_static(\"tensor_constructor\", dtype, shape)\n",
    "        write = p.get_global_var_static(\"tensor_array_write\", dtype, shape)\n",
    "        gather = p.get_global_var_static(\"tensor_array_gather\", dtype, shape)\n",
    "        v = relay.var(\"v\")\n",
    "        indice = relay.var(\"indice\")\n",
    "        init_tensor_array = tensor_array(relay.const(3))\n",
    "        tensor_array1 = write(init_tensor_array, relay.const(0), tensor(v))\n",
    "        tensor_array2 = write(tensor_array1, relay.const(1), tensor(v))\n",
    "        tensor_array3 = write(tensor_array2, relay.const(2), tensor(v))\n",
    "        out = gather(tensor_array3, indice)\n",
    "        mod[\"main\"] = relay.Function([v, indice], out)\n",
    "        mod = transform.RemoveUnusedFunctions()(mod)\n",
    "        mod = transform.PartitionGraph()(mod)\n",
    "\n",
    "    run(\"float32\", [2, 3])\n",
    "\n",
    "\n",
    "def test_not_bind_constant():\n",
    "    def get_net(prefix, data, out_channel):\n",
    "        weight = relay.var(prefix + \"weight\")\n",
    "        bn_gamma = relay.var(prefix + \"bn_gamma\")\n",
    "        bn_beta = relay.var(prefix + \"bn_beta\")\n",
    "        bn_mmean = relay.var(prefix + \"bn_mean\")\n",
    "        bn_mvar = relay.var(prefix + \"bn_var\")\n",
    "\n",
    "        layer = relay.nn.conv2d(\n",
    "            data=data, weight=weight, kernel_size=(3, 3), channels=out_channel, padding=(1, 1)\n",
    "        )\n",
    "        bn_output = relay.nn.batch_norm(layer, bn_gamma, bn_beta, bn_mmean, bn_mvar)\n",
    "        out = relay.nn.relu(bn_output[0])\n",
    "        return relay.Function(relay.analysis.free_vars(out), out)\n",
    "\n",
    "    def get_partitoned_mod(mod, params, pattern_table, bind_constants):\n",
    "        mod[\"main\"] = bind_params_by_name(mod[\"main\"], params)\n",
    "        remove_bn_pass = tvm.transform.Sequential(\n",
    "            [\n",
    "                transform.InferType(),\n",
    "                transform.SimplifyInference(),\n",
    "                transform.FoldConstant(),\n",
    "                transform.FoldScaleAxis(),\n",
    "            ]\n",
    "        )\n",
    "        composite_partition = tvm.transform.Sequential(\n",
    "            [\n",
    "                remove_bn_pass,\n",
    "                transform.MergeComposite(pattern_table),\n",
    "                transform.AnnotateTarget(\"dnnl\"),\n",
    "                transform.PartitionGraph(bind_constants=bind_constants),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        with tvm.transform.PassContext(opt_level=3, disabled_pass=[\"AlterOpLayout\"]):\n",
    "            return composite_partition(mod)\n",
    "\n",
    "    data = relay.var(\"data\", relay.TensorType((1, 3, 224, 224), \"float32\"))\n",
    "    net = get_net(\"block_\", data, 8)\n",
    "    mod, params = tvm.relay.testing.create_workload(net)\n",
    "\n",
    "    mod = get_partitoned_mod(mod, params, get_pattern_table(\"dnnl\"), bind_constants=True)\n",
    "    len(mod[\"main\"].body.args) == 1\n",
    "\n",
    "    mod = get_partitoned_mod(mod, params, get_pattern_table(\"dnnl\"), bind_constants=False)\n",
    "    len(mod[\"main\"].body.args) == 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
