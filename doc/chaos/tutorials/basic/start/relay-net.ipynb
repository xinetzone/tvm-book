{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "# Relay 神经网络推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    },
    "origin_pos": 1,
    "tab": [
     "tvm"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import tvm\n",
    "from tvm import relay"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 {mod}`PIL` 读取图像，{mod}`mxnet` 获取预训练的神经网络，以及在 TVM 中的 {mod}`~tvm.relay` 模块 {cite:p}`Roesch.Lyubomirsky.Kirisame.ea.2019` 转换和优化神经网络。\n",
    "\n",
    "`Relay` 是 TVM 中表示神经网络的高级中间表示（intermediate representation，简称 IR）。\n",
    "\n",
    "## 获得预训练模型\n",
    "\n",
    "预训练模型是指在数据集上训练好参数的神经网络。在这里，通过从 MXNet 的模型动物园 {cite:p}`Roesch.Lyubomirsky.Kirisame.ea.2019` 指定 `pretrained=True` 来下载和加载 ResNet-18 模型。如果你想了解该模型，可以参考 [Chapter 7.6 in D2L](http://d2l.ai/chapter_convolutional-modern/resnet.html)。\n",
    "\n",
    "```{seealso}\n",
    "[MXNet model zoo](https://mxnet.apache.org/api/python/docs/api/gluon/model_zoo/index.html) 可以找到更多信息。或者参考 [GluonCV](https://gluon-cv.mxnet.io/model_zoo/index.html) 和 [GluonNLP](http://gluon-nlp.mxnet.io/model_zoo/index.html) 使用更多的计算机视觉和自然语言模型。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "2"
    },
    "origin_pos": 3,
    "tab": [
     "tvm"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, Dense(512 -> 1000, linear))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mxnet.gluon.model_zoo.vision import get_model\n",
    "\n",
    "model_name = 'resnet18_v2'\n",
    "model = get_model(model_name, pretrained=True)\n",
    "len(model.features), model.output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 4
   },
   "source": [
    "加载的模型在 Imagenet 1K 数据集上训练，该数据集包含 1000 个类中大约 100 万张自然物体图像。模型分为两部分，主体部分 `model.features` 包含 13 个块，输出层是 dense 层，有 1000 个输出。\n",
    "\n",
    "下面的代码块为 Imagenet 数据集中的每个类加载文本标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2py.download import get_github_content\n",
    "\n",
    "labels = get_github_content(\"xinetzone\", \"meta-data\", \"vision/imagenet1k_labels.txt\")\n",
    "labels = labels.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "## 数据预处理示例\n",
    "\n",
    "读取样本图像并调整其大小，即 224 像素的宽度和高度，这是训练的神经网络的尺寸。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from d2py.download import iter_github_bytes\n",
    "\n",
    "# 获取图片\n",
    "image_byte = next(iter_github_bytes(\"xinetzone\", \"meta-data\", \"vision/images\"))\n",
    "with Image.open(image_byte) as im:\n",
    "    image = np.array(im.resize((224, 224)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "根据 [动物园模型页面](https://mxnet.apache.org/api/python/docs/api/gluon/model_zoo/index.html)。图像像素在每个颜色通道上进行归一化，数据布局为 `(batch, RGB channels, height, width)`。下面的函数对输入图像进行变换，使其满足要求。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    },
    "origin_pos": 9,
    "tab": [
     "tvm"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 3, 224, 224)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def image_preprocessing(image):\n",
    "    mean_rgb = [123.68, 116.779, 103.939]\n",
    "    std_rgb = [58.393, 57.12, 57.375]\n",
    "    image = image - np.array([mean_rgb])\n",
    "    image /= np.array([std_rgb])\n",
    "    image = image.transpose((2, 0, 1))\n",
    "    image = image[np.newaxis, :]\n",
    "    return image.astype('float32')\n",
    "\n",
    "x = image_preprocessing(image)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "## 编译预训练模型\n",
    "\n",
    "为了编译模型，使用 `from_mxnet` 方法导入 MXNet 模型并变换为 Relay IR。在该方法为模型提供输入数据形状。一些神经网络可能需要稍后确定的数据形状的某些维数。然而，在 ResNet 模型中，数据形状是固定的，这使得编译器更容易实现高性能。推荐固定的数据形状。在后面的章节中，只涉及动态数据形状（即在运行时确定的某些维度）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "6"
    },
    "origin_pos": 11,
    "tab": [
     "tvm"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tvm.ir.module.IRModule, dict)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_name = 'data'\n",
    "relay_mod, relay_params = relay.frontend.from_mxnet(model, {input_name: x.shape})\n",
    "type(relay_mod), type(relay_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{meth}`~tvm.relay.frontend.mxnet.from_mxnet` 方法将返回 program `relay_mod`，它是 `relay` 模块，以及 `relay_params` 参数字典，它将字符串键映射到 TVM ndarray。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看每个参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.runtime.ndarray.NDArray"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(relay_params['resnetv20_dense0_weight'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，将模块 lower 到一些可以被 `llvm` 后端使用的低级 IR。LLVM 定义了被多种编程语言采用的 IR。然后，[LLVM](https://en.wikipedia.org/wiki/LLVM) 编译器能够将生成的程序编译成 CPU 的机器码。\n",
    "\n",
    "此外，将优化级别设置为级别 3。您可能会收到警告消息，并不是每个算子都得到了很好的优化，现在可以忽略它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "7"
    },
    "origin_pos": 13,
    "tab": [
     "tvm"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tvm.relay.backend.executor_factory.GraphExecutorFactoryModule at 0x7f68f2e05ea0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'llvm'\n",
    "# 将模型与标准优化一起构建成 TVM 库\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(relay_mod, target, params=relay_params)\n",
    "\n",
    "lib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编译模块 `lib` 有：\n",
    "\n",
    "- `params`：映射参数名到权重的字典。\n",
    "- `graph_json`：将被 graph compiler 部署成 JSON 格式输出的 json graph。\n",
    "- `function_metadata`：字符串到 FunctionInfo 的 {class}`~tvm.ir.container.Map`。这保存了映射函数名称到它们的信息。graph 中可以包含指向 libmod 中 PackedFunc 名称的算子 (tvm_op)。\n",
    "- `ir_mod`：构建的 IR 模块。\n",
    "- `executor`：Executor 的内部表示。\n",
    "- `libmod_name`：模块名称。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(str, dict)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(lib.graph_json), type(lib.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 98)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lib.params), len(relay_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以将 `lib.graph_json` 中间转化为 Python 字典："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_bunch = eval(lib.graph_json)\n",
    "type(graph_bunch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'default'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lib.libmod_name # 模块名称"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取模块所对应的函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tvm.runtime.packed_func.PackedFunc at 0x7f68f571f140>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "func = lib[lib.libmod_name]\n",
    "func"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`func` 是在 TVM 中使用的 {class}`~tvm.runtime.packed_func.PackedFunc` 对象。\n",
    "\n",
    "```{seealso}\n",
    "更多信息可参考：[](global-func)。\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从 TVM 库中创建 TVM graph 运行时模块。包含已编译算子机器码的库，带有可以从目标构建的设备上下文（`ctx`）。这里的设备是 CPU，由 `llvm` 指定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tvm.contrib.graph_executor.GraphModule at 0x7f6cc413dcc0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tvm.contrib.graph_executor import GraphModule\n",
    "\n",
    "ctx = tvm.device(target, 0)\n",
    "module = GraphModule(func(ctx))\n",
    "module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "## 推理\n",
    "\n",
    "借由创建的运行时模块来运行模型推理，即神经网络的前向传播。使用 `set_input` 加载参数，并通过输入数据运行工作负载（workload）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype = \"float32\"\n",
    "module.set_input(input_name, x)\n",
    "module.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以直接使用 `run` 加载参数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "module.run(**{input_name:x})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于此网络只有单个输出层，可以通过 `get_output(0)` 得到 `(1, 1000)` 形状矩阵。最终输出长度为 1000 的 NumPy 向量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvm_output = module.get_output(0).numpy()\n",
    "tvm_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该向量包含每个类的预测置信度得分（confidence score）。注意，预训练的模型没有 [softmax](https://en.wikipedia.org/wiki/Softmax_function) 算子，所以这些得分没有映射到概率 (0,1) 中。现在可以找到两个最大的分数并报告它们的标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tiger cat', 'Egyptian cat')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = tvm_output[0]\n",
    "a = np.argsort(scores)[-1:-5:-1]\n",
    "labels[a[0]], labels[a[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "## 保存已编译的库\n",
    "\n",
    "可以保存 `relay.build` 的输出到磁盘以便以后重用它们。下面的代码块保存了 json 字符串、库和参数。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-rw-r-- 1 ai ai 45M 9月  23 14:03 outputs/resnet18_v2.params\n",
      "-rw-rw-r-- 1 ai ai 36K 9月  23 14:03 outputs/resnet18_v2.json\n",
      "-rw-rw-r-- 1 ai ai 42M 9月  23 14:03 outputs/resnet18_v2.tar\n"
     ]
    }
   ],
   "source": [
    "from d2py.utils.file import mkdir\n",
    "\n",
    "mkdir(\"outputs\") # 创建目录\n",
    "!rm -rf outputs/resnet18*\n",
    "graph_fn, mod_fn, params_fn = ['outputs/'+model_name+ext for ext in ('.json','.tar','.params')]\n",
    "lib.export_library(mod_fn)\n",
    "with open(graph_fn, 'w') as f:\n",
    "    f.write(lib.graph_json)\n",
    "with open(params_fn, 'wb') as f:\n",
    "    f.write(relay.save_param_dict(lib.params))\n",
    "\n",
    "!ls -alht outputs/resnet18*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 22
   },
   "source": [
    "加载已保存的模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "12"
    },
    "origin_pos": 23,
    "tab": [
     "tvm"
    ]
   },
   "outputs": [],
   "source": [
    "with open(graph_fn) as fp:\n",
    "    loaded_graph = fp.read()\n",
    "\n",
    "loaded_mod = tvm.runtime.load_module(mod_fn)\n",
    "\n",
    "with open(params_fn, \"rb\") as fp:\n",
    "    loaded_params = fp.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以使用 {func}`~tvm.contrib.graph_executor.create` 加载运行时模块："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.contrib.graph_executor import create\n",
    "\n",
    "loaded_rt = create(loaded_graph, loaded_mod, ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "也可以像前面一样构造运行时模块："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_rt = GraphModule(loaded_mod[\"default\"](ctx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "13"
    },
    "origin_pos": 25,
    "tab": [
     "tvm"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "loaded_rt.load_params(loaded_params)\n",
    "loaded_rt.run(data=tvm.nd.array(x))\n",
    "loaded_scores = loaded_rt.get_output(0).numpy()[0]\n",
    "np.testing.assert_allclose(loaded_scores, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 26
   },
   "source": [
    "```{rubric} 小结\n",
    "```\n",
    "\n",
    "- 可以利用 TVM 的 `relay` 将神经网络转换并编译成模块以进行模型推理。\n",
    "- 可以将编译后的模块保存到磁盘中，以方便将来的部署。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e0af55fbb1c4b4e8ca009f3673b968438b459a89daa1170f52b672ab74da765c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
