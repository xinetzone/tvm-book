{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RELU on ALU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import te\n",
    "import numpy as np\n",
    "from tvm import topi\n",
    "from tvm.contrib.utils import tempdir\n",
    "\n",
    "import vta\n",
    "import vta.testing\n",
    "from vta.testing import simulator\n",
    "\n",
    "np.random.seed(0xDEADB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 13:13:49.037 INFO load_module /tmp/tmppyrqqdcq/load_act.o\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relu execution statistics:\n",
      "\tinp_load_nbytes :                0\n",
      "\twgt_load_nbytes :                0\n",
      "\tacc_load_nbytes :             5120\n",
      "\tuop_load_nbytes :                8\n",
      "\tout_store_nbytes:             1280\n",
      "\tgemm_counter    :                0\n",
      "\talu_counter     :              160\n"
     ]
    }
   ],
   "source": [
    "def _run(env, remote):\n",
    "    m = 8\n",
    "    n = 10\n",
    "    # compute\n",
    "    a = te.placeholder((m, n, env.BATCH, env.BLOCK_OUT), name=\"a\", dtype=env.acc_dtype)\n",
    "    a_buf = te.compute(\n",
    "        (m, n, env.BATCH, env.BLOCK_OUT), lambda *i: a(*i), \"a_buf\"\n",
    "    )  # DRAM->SRAM\n",
    "    max_buf = te.compute(\n",
    "        (m, n, env.BATCH, env.BLOCK_OUT), lambda *i: tvm.te.max(a_buf(*i), 0), \"res_buf\"\n",
    "    )  # relu\n",
    "    min_buf = te.compute(\n",
    "        (m, n, env.BATCH, env.BLOCK_OUT),\n",
    "        lambda *i: tvm.te.min(max_buf(*i), (1 << (env.INP_WIDTH - 1)) - 1),\n",
    "        \"max_buf\",\n",
    "    )  # relu\n",
    "    res = te.compute(\n",
    "        (m, n, env.BATCH, env.BLOCK_OUT),\n",
    "        lambda *i: min_buf(*i).astype(env.inp_dtype),\n",
    "        \"min_buf\",\n",
    "    )  # SRAM->DRAM\n",
    "    # schedule\n",
    "    s = te.create_schedule(res.op)\n",
    "    s[a_buf].set_scope(env.acc_scope)  # SRAM\n",
    "    s[a_buf].pragma(a_buf.op.axis[0], env.dma_copy)  # DRAM->SRAM\n",
    "    s[max_buf].set_scope(env.acc_scope)  # SRAM\n",
    "    s[min_buf].set_scope(env.acc_scope)  # SRAM\n",
    "    s[max_buf].pragma(max_buf.op.axis[0], env.alu)  # compute\n",
    "    s[min_buf].pragma(min_buf.op.axis[0], env.alu)  # compute\n",
    "    s[res].pragma(res.op.axis[0], env.dma_copy)  # SRAM->DRAM\n",
    "    # build\n",
    "    with vta.build_config():\n",
    "        mod = vta.build(s, [a, res], tvm.target.Target(\"ext_dev\", host=env.target_host))\n",
    "    if not remote:\n",
    "        return\n",
    "    temp = tempdir()\n",
    "    mod.save(temp.relpath(\"load_act.o\"))\n",
    "    remote.upload(temp.relpath(\"load_act.o\"))\n",
    "    f = remote.load_module(\"load_act.o\")\n",
    "    # verify\n",
    "    dev = remote.ext_dev(0)\n",
    "    a_np = np.random.randint(-256, 256, size=(m, n, env.BATCH, env.BLOCK_OUT)).astype(a.dtype)\n",
    "    res_np = np.clip(a_np, 0, (1 << (env.INP_WIDTH - 1)) - 1).astype(res.dtype)\n",
    "    a_nd = tvm.nd.array(a_np, dev)\n",
    "    res_nd = tvm.nd.array(np.zeros((m, n, env.BATCH, env.BLOCK_OUT)).astype(res.dtype), dev)\n",
    "\n",
    "    if env.TARGET in [\"sim\", \"tsim\"]:\n",
    "        simulator.clear_stats()\n",
    "\n",
    "    f(a_nd, res_nd)\n",
    "\n",
    "    np.testing.assert_equal(res_np, res_nd.numpy())\n",
    "\n",
    "    if env.TARGET in [\"sim\", \"tsim\"]:\n",
    "        sim_stats = simulator.stats()\n",
    "        print(\"Relu execution statistics:\")\n",
    "        for k, v in sim_stats.items():\n",
    "            print(\"\\t{:<16}: {:>16}\".format(k, v))\n",
    "\n",
    "vta.testing.run(_run)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
