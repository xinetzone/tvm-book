{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义 VTA Graph Pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import tvm\n",
    "from tvm import relay\n",
    "from vta_utils.pack_tool import ExprGraphPack # WithVTAFunctionTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VTA 模型样例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>data: Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), float32] span<span style=\"color: #AA22FF; font-weight: bold\">=</span>aten::_convolution_0<span style=\"color: #AA22FF; font-weight: bold\">.</span>data:<span style=\"color: #008000\">0</span>:<span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">*/</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), float32] {\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> multiply(<span style=\"color: #AA22FF; font-weight: bold\">%</span>data, <span style=\"color: #008000\">16</span>f <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>float32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> round(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> clip(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span>, a_min<span style=\"color: #AA22FF; font-weight: bold\">=-</span><span style=\"color: #008000\">127</span>f, a_max<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">127</span>f) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">3</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> cast(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">2</span>, dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int8&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), int8] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">4</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>conv2d(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">3</span>, meta[relay<span style=\"color: #AA22FF; font-weight: bold\">.</span>Constant][<span style=\"color: #008000\">0</span>] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), int8] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, padding<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], channels<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">32</span>, kernel_size<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>], out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), int32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">5</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> cast(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">4</span>, dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int64&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), int64] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">6</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> fixed_point_multiply(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">5</span>, multiplier<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1652854784</span>, shift<span style=\"color: #AA22FF; font-weight: bold\">=-</span><span style=\"color: #008000\">9</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), int64] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">7</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> clip(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">6</span>, a_min<span style=\"color: #AA22FF; font-weight: bold\">=-</span><span style=\"color: #008000\">127</span>f, a_max<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">127</span>f) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), int64] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">8</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> cast(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">7</span>, dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), int32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">9</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> cast(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">8</span>, dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int8&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), int8] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">10</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> annotation<span style=\"color: #AA22FF; font-weight: bold\">.</span>stop_fusion(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">9</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), int8] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">11</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> cast(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">10</span>, dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  multiply(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">11</span>, <span style=\"color: #008000\">0.0625</span>f <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>float32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">4</span>, <span style=\"color: #008000\">4</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from torch import nn\n",
    "import torch\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.conv = nn.Conv2d(3, 32, 3, 1, 1, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        # x = self.bn(x)\n",
    "        # x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "pt_model = Model().eval().float()\n",
    "ishape = (1, 3, 4, 4)\n",
    "input_name = \"data\"\n",
    "input_shapes = [(input_name, ishape)]\n",
    "# script_module = torch.jit.script(pt_model)\n",
    "# mod, params = relay.frontend.from_pytorch(script_module, input_shapes)\n",
    "idata = torch.randn(ishape).type(torch.float32)\n",
    "traced_model = torch.jit.trace(pt_model, idata)\n",
    "# traced_model 翻译为 TVM 前端模型\n",
    "mod, params = relay.frontend.from_pytorch(traced_model, input_shapes)\n",
    "# 量化\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    with relay.quantize.qconfig(skip_conv_layers=[], weight_scale=\"max\",):\n",
    "        mod = relay.quantize.quantize(mod, params)\n",
    "mod.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VTA Graph Pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tvm.relay import op\n",
    "# from tvm.relay.op import op as _op\n",
    "# from tvm.relay import ExprMutator\n",
    "# from tvm.relay.expr import Call\n",
    "# from tvm.ir.op import Op\n",
    "from tvm.relay.function import Function\n",
    "# from vta.top.graphpack import (\n",
    "#     _channel_const_match,\n",
    "#     _to_shape,\n",
    "#     _get_tensor_type,\n",
    "#     _pack_weight,\n",
    "#     _weight_shape_match,\n",
    "#     _pack_weight_conv2d_transpose,\n",
    "#     _weight_shape_match_transpose,\n",
    "#     _pack_const,\n",
    "#     _const_shape_match,\n",
    "# )\n",
    "from tvm.relay.testing import run_opt_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/vta/graph-pack.ipynb 单元格 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2B10.16.11.3/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/vta/graph-pack.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m transform \u001b[39m=\u001b[39m ExprGraphPack(bfactor, cfactor, weight_bits)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.11.3/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/vta/graph-pack.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m new_fn \u001b[39m=\u001b[39m run_mod[\u001b[39m\"\u001b[39m\u001b[39mmain\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B10.16.11.3/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/vta/graph-pack.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m new_fn \u001b[39m=\u001b[39m transform\u001b[39m.\u001b[39;49mvisit(new_fn)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.11.3/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/vta/graph-pack.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m new_body \u001b[39m=\u001b[39m new_fn\u001b[39m.\u001b[39mbody\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.11.3/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/vta/graph-pack.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m new_fn \u001b[39m=\u001b[39m Function(\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.11.3/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/vta/graph-pack.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     \u001b[39mlist\u001b[39m(new_fn\u001b[39m.\u001b[39mparams), new_body,\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.11.3/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/vta/graph-pack.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m     ret_type\u001b[39m=\u001b[39mnew_body\u001b[39m.\u001b[39mchecked_type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.11.3/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/vta/graph-pack.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m     span\u001b[39m=\u001b[39mnew_fn\u001b[39m.\u001b[39mspan\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B10.16.11.3/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/vta/graph-pack.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m )\n",
      "File \u001b[0;32m/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/relay/expr_functor.py:46\u001b[0m, in \u001b[0;36mExprFunctor.visit\u001b[0;34m(self, expr)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemo_map[expr]\n\u001b[1;32m     45\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(expr, Function):\n\u001b[0;32m---> 46\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_function(expr)\n\u001b[1;32m     47\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(expr, Call):\n\u001b[1;32m     48\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_call(expr)\n",
      "File \u001b[0;32m/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/relay/expr_functor.py:206\u001b[0m, in \u001b[0;36mExprMutator.visit_function\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_function\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    205\u001b[0m     new_params \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m fn\u001b[39m.\u001b[39mparams]\n\u001b[0;32m--> 206\u001b[0m     new_body \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(fn\u001b[39m.\u001b[39;49mbody)\n\u001b[1;32m    207\u001b[0m     \u001b[39mif\u001b[39;00m new_params \u001b[39m==\u001b[39m \u001b[39mlist\u001b[39m(fn\u001b[39m.\u001b[39mparams) \u001b[39mand\u001b[39;00m new_body \u001b[39m==\u001b[39m fn\u001b[39m.\u001b[39mbody:\n\u001b[1;32m    208\u001b[0m         \u001b[39mreturn\u001b[39;00m fn\n",
      "File \u001b[0;32m/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/relay/expr_functor.py:48\u001b[0m, in \u001b[0;36mExprFunctor.visit\u001b[0;34m(self, expr)\u001b[0m\n\u001b[1;32m     46\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_function(expr)\n\u001b[1;32m     47\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(expr, Call):\n\u001b[0;32m---> 48\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_call(expr)\n\u001b[1;32m     49\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(expr, Let):\n\u001b[1;32m     50\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_let(expr)\n",
      "File \u001b[0;32m/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/vta/vta_utils/pack_tool.py:45\u001b[0m, in \u001b[0;36mExprGraphPack.visit_call\u001b[0;34m(self, call)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_call\u001b[39m(\u001b[39mself\u001b[39m, call):\n\u001b[1;32m     44\u001b[0m     new_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(call\u001b[39m.\u001b[39mop)\n\u001b[0;32m---> 45\u001b[0m     new_args \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m call\u001b[39m.\u001b[39margs]\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(new_fn, Op):\n\u001b[1;32m     48\u001b[0m         \u001b[39m# oshape = _get_tensor_shape(call)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m         odtype \u001b[39m=\u001b[39m _get_tensor_type(call)\n",
      "File \u001b[0;32m/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/vta/vta_utils/pack_tool.py:45\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_call\u001b[39m(\u001b[39mself\u001b[39m, call):\n\u001b[1;32m     44\u001b[0m     new_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(call\u001b[39m.\u001b[39mop)\n\u001b[0;32m---> 45\u001b[0m     new_args \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m call\u001b[39m.\u001b[39margs]\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(new_fn, Op):\n\u001b[1;32m     48\u001b[0m         \u001b[39m# oshape = _get_tensor_shape(call)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m         odtype \u001b[39m=\u001b[39m _get_tensor_type(call)\n",
      "File \u001b[0;32m/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/relay/expr_functor.py:48\u001b[0m, in \u001b[0;36mExprFunctor.visit\u001b[0;34m(self, expr)\u001b[0m\n\u001b[1;32m     46\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_function(expr)\n\u001b[1;32m     47\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(expr, Call):\n\u001b[0;32m---> 48\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_call(expr)\n\u001b[1;32m     49\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(expr, Let):\n\u001b[1;32m     50\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_let(expr)\n",
      "File \u001b[0;32m/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/vta/vta_utils/pack_tool.py:45\u001b[0m, in \u001b[0;36mExprGraphPack.visit_call\u001b[0;34m(self, call)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_call\u001b[39m(\u001b[39mself\u001b[39m, call):\n\u001b[1;32m     44\u001b[0m     new_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(call\u001b[39m.\u001b[39mop)\n\u001b[0;32m---> 45\u001b[0m     new_args \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m call\u001b[39m.\u001b[39margs]\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(new_fn, Op):\n\u001b[1;32m     48\u001b[0m         \u001b[39m# oshape = _get_tensor_shape(call)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m         odtype \u001b[39m=\u001b[39m _get_tensor_type(call)\n",
      "File \u001b[0;32m/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/vta/vta_utils/pack_tool.py:45\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_call\u001b[39m(\u001b[39mself\u001b[39m, call):\n\u001b[1;32m     44\u001b[0m     new_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(call\u001b[39m.\u001b[39mop)\n\u001b[0;32m---> 45\u001b[0m     new_args \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m call\u001b[39m.\u001b[39margs]\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(new_fn, Op):\n\u001b[1;32m     48\u001b[0m         \u001b[39m# oshape = _get_tensor_shape(call)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m         odtype \u001b[39m=\u001b[39m _get_tensor_type(call)\n",
      "    \u001b[0;31m[... skipping similar frames: ExprFunctor.visit at line 48 (6 times), <listcomp> at line 45 (5 times), ExprGraphPack.visit_call at line 45 (5 times)]\u001b[0m\n",
      "File \u001b[0;32m/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/vta/vta_utils/pack_tool.py:45\u001b[0m, in \u001b[0;36mExprGraphPack.visit_call\u001b[0;34m(self, call)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_call\u001b[39m(\u001b[39mself\u001b[39m, call):\n\u001b[1;32m     44\u001b[0m     new_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(call\u001b[39m.\u001b[39mop)\n\u001b[0;32m---> 45\u001b[0m     new_args \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m call\u001b[39m.\u001b[39margs]\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(new_fn, Op):\n\u001b[1;32m     48\u001b[0m         \u001b[39m# oshape = _get_tensor_shape(call)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m         odtype \u001b[39m=\u001b[39m _get_tensor_type(call)\n",
      "File \u001b[0;32m/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/vta/vta_utils/pack_tool.py:45\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mvisit_call\u001b[39m(\u001b[39mself\u001b[39m, call):\n\u001b[1;32m     44\u001b[0m     new_fn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit(call\u001b[39m.\u001b[39mop)\n\u001b[0;32m---> 45\u001b[0m     new_args \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m call\u001b[39m.\u001b[39margs]\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(new_fn, Op):\n\u001b[1;32m     48\u001b[0m         \u001b[39m# oshape = _get_tensor_shape(call)\u001b[39;00m\n\u001b[1;32m     49\u001b[0m         odtype \u001b[39m=\u001b[39m _get_tensor_type(call)\n",
      "File \u001b[0;32m/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/relay/expr_functor.py:48\u001b[0m, in \u001b[0;36mExprFunctor.visit\u001b[0;34m(self, expr)\u001b[0m\n\u001b[1;32m     46\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_function(expr)\n\u001b[1;32m     47\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(expr, Call):\n\u001b[0;32m---> 48\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvisit_call(expr)\n\u001b[1;32m     49\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(expr, Let):\n\u001b[1;32m     50\u001b[0m     res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvisit_let(expr)\n",
      "File \u001b[0;32m/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/vta/vta_utils/pack_tool.py:56\u001b[0m, in \u001b[0;36mExprGraphPack.visit_call\u001b[0;34m(self, call)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mif\u001b[39;00m data_shape[\u001b[39m1\u001b[39m] \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfactor \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     55\u001b[0m     new_args[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m _pad_channel(new_args[\u001b[39m0\u001b[39m], data_shape, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcfactor)\n\u001b[0;32m---> 56\u001b[0m new_args[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m _pack_batch_channel(new_args[\u001b[39m0\u001b[39;49m], data_shape, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbfactor, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcfactor)\n\u001b[1;32m     57\u001b[0m \u001b[39m# if kernel_shape[0] % self.cfactor != 0 or kernel_shape[1] % self.cfactor:\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39m#     # pad channels 对齐 self.cfactor\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \u001b[39m#     new_args[0] = _pad_const(new_args[0], _to_shape(new_args[0].checked_type.shape), self.bfactor, self.cfactor)\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \u001b[39m#     new_args[1] = _pad_const(new_args[1], _to_shape(new_args[1].checked_type.shape), self.cfactor, self.cfactor)\u001b[39;00m\n\u001b[1;32m     62\u001b[0m w_lanes \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mweight_bits\n",
      "File \u001b[0;32m/media/pc/data/lxw/ai/tvm/xinetzone/tvm-book/doc/vta/vta_utils/utils.py:59\u001b[0m, in \u001b[0;36m_pack_batch_channel\u001b[0;34m(data, dshape, bfactor, cfactor)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Pack the data channel dimension.\"\"\"\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mint\u001b[39m(dshape[\u001b[39m0\u001b[39m]) \u001b[39m%\u001b[39m bfactor \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 59\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mint\u001b[39m(dshape[\u001b[39m1\u001b[39m]) \u001b[39m%\u001b[39m cfactor \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(dshape) \u001b[39m==\u001b[39m \u001b[39m4\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(dshape) \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m \u001b[39m# NCHW 或者 NC\u001b[39;00m\n\u001b[1;32m     61\u001b[0m dshape \u001b[39m=\u001b[39m  \u001b[39mlist\u001b[39m(dshape)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import vta\n",
    "\n",
    "env = vta.get_env()\n",
    "bfactor = env.BATCH\n",
    "cfactor = env.BLOCK_OUT\n",
    "weight_bits = env.WGT_WIDTH\n",
    "\n",
    "run_mod = deepcopy(mod)\n",
    "transform = ExprGraphPack(bfactor, cfactor, weight_bits)\n",
    "new_fn = run_mod[\"main\"]\n",
    "new_fn = transform.visit(new_fn)\n",
    "new_body = new_fn.body\n",
    "new_fn = Function(\n",
    "    list(new_fn.params), new_body,\n",
    "    ret_type=new_body.checked_type,\n",
    "    type_params=new_fn.type_params,\n",
    "    attrs=new_fn.attrs,\n",
    "    span=new_fn.span\n",
    ")\n",
    "new_fn = run_opt_pass(new_fn, relay.transform.InferType())\n",
    "tvm.IRModule.from_expr(new_fn).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "www"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VTA 模型的算子融合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创建融合策略："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.relay.dataflow_pattern import (\n",
    "    # TuplePattern, TupleGetItemPattern, \n",
    "    is_op, wildcard, is_constant\n",
    ")\n",
    "def preprocessing_pattern():\n",
    "    r = is_op(\"multiply\")(wildcard(), is_constant())\n",
    "    r = is_op(\"round\")(r)\n",
    "    r = is_op(\"clip\")(r)\n",
    "    r = is_op(\"cast\")(r)\n",
    "    return r\n",
    "\n",
    "def output_pattern():\n",
    "    r = is_op(\"cast\")(wildcard())\n",
    "    r = is_op(\"multiply\")(r, is_constant())\n",
    "    return r\n",
    "\n",
    "def conv_add_activate_pattern():\n",
    "    r\"\"\"Create a pattern to match the following graph.\n",
    "\n",
    "    conv2d\n",
    "        |\n",
    "        (add)\n",
    "        |\n",
    "        (add)\n",
    "        |\n",
    "    (relu|relu6|prelu|sigmoid|relux)\n",
    "    \"\"\"\n",
    "    x = wildcard()\n",
    "    w = wildcard()\n",
    "    bias = wildcard()\n",
    "    bias2 = wildcard()\n",
    "    alpha = wildcard()\n",
    "    \n",
    "    bias_ = is_op(\"relay.op.annotation.simulated_quantize\")(bias, is_constant(), is_constant(), is_constant()) | bias\n",
    "    bias2_ = is_op(\"relay.op.annotation.simulated_quantize\")(bias2, is_constant(), is_constant(), is_constant()) | bias2\n",
    "    alpha_ = is_op(\"relay.op.annotation.simulated_quantize\")(alpha, is_constant(), is_constant(), is_constant()) | alpha\n",
    "\n",
    "    conv_node = is_op(\"nn.conv2d\")(x, w)\n",
    "    conv_node = is_op(\"add\")(conv_node, bias2_) | conv_node\n",
    "    \n",
    "    fixed_point_multiply = is_op(\"fixed_point_multiply\")(conv_node)\n",
    "    fixed_point_multiply = is_op(\"cast\")(fixed_point_multiply)\n",
    "    conv_node = fixed_point_multiply | conv_node\n",
    "    r = is_op(\"add\")(conv_node, bias_) | conv_node\n",
    "    \n",
    "    # 激活函数\n",
    "    r1 = r.optional(lambda x: is_op(\"nn.relu\")(x))\n",
    "    r2 = r.optional(lambda x: is_op(\"clip\")(x)) # relu6\n",
    "    r3 = r.optional(lambda x: is_op(\"nn.prelu\")(x, alpha)) # prelu\n",
    "    r4 = r.optional(lambda x: is_op(\"sigmoid\")(x)) # sigmoid\n",
    "    r = r1 | r2 | r3 | r4\n",
    "\n",
    "    r_s = is_op(\"relay.op.annotation.simulated_quantize\")(r, is_constant(), is_constant(), is_constant()) | r\n",
    "    r_s = is_op(\"annotation.cast_hint\")(r_s) | r_s\n",
    "\n",
    "    r_q = is_op(\"cast\")(r)\n",
    "    r_q = is_op(\"fixed_point_multiply\")(r_q)\n",
    "    r_q = is_op(\"clip\")(r_q)\n",
    "    r_q = is_op(\"cast\")(r_q)\n",
    "    r_q = is_op(\"cast\")(r_q)\n",
    "    r = r_s | r_q\n",
    "    r = is_op(\"annotation.stop_fusion\")(r) | r\n",
    "    return r\n",
    "\n",
    "pattern_table = [\n",
    "    (\"vta_preprocessing\", preprocessing_pattern()),\n",
    "    (\"vta_conv2d\", conv_add_activate_pattern()),\n",
    "    (\"vta_output\", output_pattern()),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实现算子融合："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vta_utils.pack_tool import VTAGraphPackTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vta\n",
    "\n",
    "env = vta.get_env()\n",
    "bfactor = env.BATCH\n",
    "cfactor = env.BLOCK_OUT\n",
    "weight_bits = env.WGT_WIDTH\n",
    "\n",
    "prepare_transform = tvm.transform.Sequential([\n",
    "    relay.transform.InferType(),\n",
    "    relay.transform.MergeComposite(pattern_table), # 算子融合\n",
    "    WithVTAFunctionTransform(), # 为融合函数 vta_conv2d 添加 ConvAttrs 属性\n",
    "    # VTAGraphPackTransform(bfactor, cfactor, weight_bits),\n",
    "    relay.transform.InferType(),\n",
    "\n",
    "])\n",
    "run_mod = deepcopy(mod)\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    run_mod = prepare_transform(run_mod)\n",
    "run_mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.relay.expr import Call, Let, Var\n",
    "from tvm.relay.function import Function, FunctionWithFields\n",
    "from tvm.relay.op.annotation import compiler_begin, compiler_end\n",
    "from tvm.relay import op\n",
    "from tvm.relay.op import op as _op\n",
    "from tvm.relay.testing import run_opt_pass\n",
    "from tvm.relay.dataflow_pattern import (\n",
    "    # TuplePattern, TupleGetItemPattern, \n",
    "    is_op, wildcard, is_constant\n",
    ")\n",
    "from tvm.relay import ExprMutator #, ExprVisitor\n",
    "from tvm.ir.op import Op\n",
    "from vta.top.graphpack import (\n",
    "    _to_shape,\n",
    "    # _unpack_batch_channel,\n",
    "    _channel_const_match,\n",
    "    _const_shape_match,\n",
    "    _weight_shape_match,\n",
    "    # # _weight_shape_match_transpose, # 新增\n",
    "    _pack_weight,\n",
    "    # _pack_weight_conv2d_transpose,\n",
    "    # # _pack_const, # 被修改\n",
    "    _get_tensor_shape,\n",
    "    _get_tensor_type,\n",
    ")\n",
    "from tvm.relay.expr import GlobalVar, Let\n",
    "from tvm.relay.function import Function, FunctionWithFields\n",
    "from vta_utils.utils import _pack_batch_channel\n",
    "from tvm.relay.testing import run_opt_pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_transform = tvm.transform.Sequential([\n",
    "    relay.transform.InferType(),\n",
    "    relay.transform.MergeComposite(pattern_table), # 算子融合\n",
    "    WithVTAFunctionTransform(), # 为融合函数 vta_conv2d 添加 ConvAttrs 属性\n",
    "    # VTAGraphPackTransform(bfactor, cfactor, weight_bits),\n",
    "    relay.transform.InferType(),\n",
    "\n",
    "])\n",
    "\n",
    "run_mod = deepcopy(mod)\n",
    "run_mod = prepare_transform(run_mod)\n",
    "new_fn = run_mod[\"vta_conv2d__1\"]\n",
    "\n",
    "# new_fn = run_opt_pass(new_fn, relay.transform.InferType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_transform = tvm.transform.Sequential([\n",
    "    relay.transform.InferType(),\n",
    "    relay.transform.MergeComposite(pattern_table), # 算子融合\n",
    "    WithVTAFunctionTransform(), # 为融合函数 vta_conv2d 添加 ConvAttrs 属性\n",
    "    # VTAGraphPackTransform(bfactor, cfactor, weight_bits),\n",
    "    relay.transform.InferType(),\n",
    "\n",
    "])\n",
    "\n",
    "run_mod = deepcopy(mod)\n",
    "run_mod = prepare_transform(run_mod)\n",
    "global_vars = [vv for vv in run_mod.get_global_vars() if vv.name_hint!=\"main\"]\n",
    "for op_var in global_vars:\n",
    "    new_fn = run_mod[op_var]\n",
    "    oshape = list(_to_shape(new_fn.checked_type.ret_type.shape))\n",
    "    new_body = new_fn.body\n",
    "    odtype = new_fn.checked_type.ret_type.dtype\n",
    "    input_types = [vv.dtype for vv in new_fn.checked_type.arg_types]\n",
    "    # break\n",
    "    if \"vta_preprocessing\" in op_var.name_hint:\n",
    "        assert new_fn.attrs[\"Composite\"] == \"vta_preprocessing\"\n",
    "        \n",
    "        new_body = _pack_batch_channel(new_body, oshape, bfactor, cfactor)\n",
    "        new_fn = Function(\n",
    "            list(new_fn.params), new_body,\n",
    "            ret_type=new_body.checked_type,\n",
    "            type_params=new_fn.type_params,\n",
    "            attrs=new_fn.attrs,\n",
    "            span=new_fn.span\n",
    "        )\n",
    "        run_mod[op_var] = run_opt_pass(new_fn, relay.transform.InferType())\n",
    "    # elif \"vta_output\" in op_var.name_hint:\n",
    "    #     assert new_fn.attrs[\"Composite\"] == \"vta_output\"\n",
    "    #     assert odtype == \"float32\"\n",
    "    #     new_params = [\n",
    "    #         _pack_batch_channel(param, list(_get_tensor_shape(param)), bfactor, cfactor)\n",
    "    #         for param in new_fn.params\n",
    "    #     ]\n",
    "    #     new_body = _unpack_batch_channel(new_body, list(_get_tensor_shape(new_body)), unpack_transpose=True)\n",
    "    #     # new_fn = Function(\n",
    "    #     #     new_params, new_body,\n",
    "    #     #     # ret_type=new_body.checked_type,\n",
    "    #     #     # type_params=new_fn.type_params,\n",
    "    #     #     attrs=new_fn.attrs,\n",
    "    #     #     span=new_fn.span\n",
    "    #     # )\n",
    "    #     break\n",
    "    #     # data = args[0]\n",
    "    #     # data_shape = _get_tensor_shape(call.args[0])\n",
    "    #     # data = _unpack_batch_channel(data, old_shape, unpack_transpose=True)\n",
    "    #     # return _unpack_batch_channel(data, data_shape, self.unpack_transpose)\n",
    "    elif \"vta_conv2d\" in op_var.name_hint:\n",
    "        assert new_fn.attrs[\"Composite\"] == \"vta_conv2d\"\n",
    "        transform = PackConv2dMutator(bfactor, cfactor, weight_bits)\n",
    "        new_fn = transform.visit(new_fn)\n",
    "        new_body = new_fn.body\n",
    "        new_fn = Function(\n",
    "            list(new_fn.params), new_body,\n",
    "            ret_type=new_body.checked_type,\n",
    "            type_params=new_fn.type_params,\n",
    "            attrs=new_fn.attrs,\n",
    "            span=new_fn.span\n",
    "        )\n",
    "        run_mod[op_var] = run_opt_pass(new_fn, relay.transform.InferType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
