{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义 TOPI 算子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tvm import te, topi, tir as T, relay\n",
    "import tvm\n",
    "from tvm.topi import tag\n",
    "from tvm.relay import op\n",
    "from tvm.relay.op.op import register_compute, register_shape_func\n",
    "from tvm.relay.op.op import register_broadcast_schedule, register_injective_schedule\n",
    "from tvm.relay.op.op import register_pattern, OpPattern\n",
    "from tvm.topi.utils import get_const_tuple\n",
    "from tvm.relay.testing import run_opt_pass\n",
    "import vta\n",
    "from tvm_book.tvm_utils.llvm_utils import run_llvm_graph\n",
    "from vta.top.graphpack import (\n",
    "    _channel_const_match,\n",
    "    _get_tensor_type,\n",
    ")\n",
    "\n",
    "def _channel_shape_match(data, dshape, cfactor):\n",
    "    \"\"\"pad 0 以对齐维度 \"\"\"\n",
    "    dshape =  list(dshape)\n",
    "    pad_width_diff, dshape[1] = _channel_const_match(dshape[1], cfactor)\n",
    "    if pad_width_diff != 0:\n",
    "        pad_width = len(dshape) * [[0, 0]]\n",
    "        pad_width[1] = [0, pad_width_diff]\n",
    "        data = op.nn.pad(data, pad_width)\n",
    "        data = run_opt_pass(data, relay.transform.InferType())\n",
    "    return data, dshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tvm.te.tag_scope(tag=tag.ELEMWISE)\n",
    "def vta_preprocessing(x):\n",
    "    \"\"\"数据预处理\"\"\"\n",
    "    # hp_dtype = \"int64\"\n",
    "    # lp_dtype = \"int32\"\n",
    "    # assert y.dtype == lp_dtype\n",
    "    # assert left_shift.dtype == lp_dtype\n",
    "    # assert right_shift.dtype == lp_dtype\n",
    "    # one = T.const(1, hp_dtype)\n",
    "    def _compute(*indices):\n",
    "        # elements = []\n",
    "        # for element in get_const_tuple(axes):\n",
    "        #     elements += [indices[element]]\n",
    "        # param_indices = tuple(elements)\n",
    "\n",
    "        # 0) 获取值\n",
    "        value = x(*indices)\n",
    "        \n",
    "        return value.astype(x.dtype)\n",
    "\n",
    "    return te.compute(x.shape, _compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = 1, 16, 224, 224\n",
    "dtype = \"float32\"\n",
    "x = te.placeholder(shape, name=\"data\", dtype=dtype)\n",
    "y = vta_preprocessing(x)\n",
    "s = te.create_schedule(y.op)\n",
    "mod = tvm.lower(s, [x, y])\n",
    "mod = relay.transform.InferType()(mod)\n",
    "mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfactor = 16\n",
    "a_min, a_max = -127, 127\n",
    "dtype = \"float32\"\n",
    "out_dtype = \"int8\"\n",
    "shape = 1, 3, 224, 224\n",
    "pad_channel = shape[1] - cfactor\n",
    "pad_width = [(0, 0), (0, pad_channel), (0, 0), (0, 0)]\n",
    "x = relay.var(\"data\", shape=shape, dtype=dtype)\n",
    "const = relay.var(\"scale\", shape=(), dtype=dtype)\n",
    "y = x * const\n",
    "y = op.round(y)\n",
    "y = op.clip(y, a_min, a_max)\n",
    "y = op.cast(y, out_dtype)\n",
    "y, shape = _channel_shape_match(y, shape, cfactor)\n",
    "# new_fn = relay.Function([x], y)\n",
    "mod = tvm.IRModule.from_expr(y)\n",
    "mod = relay.transform.InferType()(mod)\n",
    "mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tvm.IRModule.from_expr(func).show()\n",
    "intrp = relay.create_executor(\"graph\", device=tvm.cpu(0), target=\"llvm\")\n",
    "\n",
    "data_np = np.arange(np.prod(shape)).reshape(shape).astype(\"float32\")\n",
    "op_res, new_data = intrp.evaluate(func)(data_np)\n",
    "np.testing.assert_allclose(data_np, new_data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tvm.relay.transform.transform.DivToMul()>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relay.transform.DivToMul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def before():\n",
    "    x = relay.var(\"x\", shape=(1, 64, 56, 56))\n",
    "    channels = 128\n",
    "    weight = relay.var(\"weight\", shape=(channels, 64, 1, 1))\n",
    "    y = relay.nn.conv2d(\n",
    "        x,\n",
    "        weight,\n",
    "        channels=channels,\n",
    "        kernel_size=(1, 1),\n",
    "        padding=(1, 1),\n",
    "        data_layout=\"NCWH\",\n",
    "        kernel_layout=\"OIHW\",\n",
    "    )\n",
    "    y = relay.nn.relu(y)\n",
    "    y = relay.Function([x, weight], y)\n",
    "    return y\n",
    "\n",
    "a = before()\n",
    "a = run_opt_pass(a, relay.transform.ConvertLayout({\"nn.conv2d\": [\"NCHW1n16c\", \"OIHW16o16i\"]}))\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fn (%x: Tensor[(1, 64, 56, 56), float32] /* ty=Tensor[(1, 64, 56, 56), float32] */, %weight: Tensor[(128, 64, 1, 1), float32] /* ty=Tensor[(128, 64, 1, 1), float32] */) -> Tensor[(1, 128, 58, 58), float32] {\n",
      "  %0 = layout_transform(%x, src_layout=\"NCWH\", dst_layout=\"NCHW1n16c\") /* ty=Tensor[(1, 4, 56, 56, 1, 16), float32] */;\n",
      "  %1 = layout_transform(%weight, src_layout=\"OIHW\", dst_layout=\"OIHW16o16i\") /* ty=Tensor[(8, 4, 1, 1, 16, 16), float32] */;\n",
      "  %2 = nn.conv2d(%0, %1, padding=[1, 1, 1, 1], channels=128, kernel_size=[1, 1], data_layout=\"NCHW1n16c\", kernel_layout=\"OIHW16o16i\") /* ty=Tensor[(1, 8, 58, 58, 1, 16), float32] */;\n",
      "  %3 = nn.relu(%2) /* ty=Tensor[(1, 8, 58, 58, 1, 16), float32] */;\n",
      "  layout_transform(%3, src_layout=\"NCHW1n16c\", dst_layout=\"NCWH\") /* ty=Tensor[(1, 128, 58, 58), float32] */\n",
      "} /* ty=fn (Tensor[(1, 64, 56, 56), float32], Tensor[(128, 64, 1, 1), float32]) -> Tensor[(1, 128, 58, 58), float32] */\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
