{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 快速上手 TVM 自动量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import set_env\n",
    "from d2py.utils.log_config import config_logging\n",
    "from d2py.utils.file import mkdir\n",
    "# 配置日志信息\n",
    "temp_dir = \".temp\"\n",
    "logger_name = \"test\"\n",
    "mkdir(temp_dir)\n",
    "config_logging(\n",
    "    f\"{temp_dir}/{logger_name}.log\", logger_name, \n",
    "    filemode=\"w\", filter_mod_names={\"te_compiler\"}\n",
    ")\n",
    "logger = logging.getLogger(logger_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义简单网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class TestModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.planes = 64\n",
    "        self.conv = nn.Conv2d(3, self.planes, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(self.planes, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True, dtype=torch.float32)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转换前端模型为 relay 模型："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO|2024-01-09 12:50:27,877|test| -> 原始模型：fn (%data: Tensor[(1, 3, 32, 32), float32] /* span=aten::_convolution_0.data:0:0 */, %aten::_convolution_0.weight: Tensor[(64, 3, 7, 7), float32] /* span=aten::_convolution_0.weight:0:0 */, %aten::batch_norm_0.weight: Tensor[(64), float32] /* span=aten::batch_norm_0.weight:0:0 */, %aten::batch_norm_0.bias: Tensor[(64), float32] /* span=aten::batch_norm_0.bias:0:0 */, %aten::batch_norm_0.running_mean: Tensor[(64), float32] /* span=aten::batch_norm_0.running_mean:0:0 */, %aten::batch_norm_0.running_var: Tensor[(64), float32] /* span=aten::batch_norm_0.running_var:0:0 */) {\n",
      "  %0 = nn.conv2d(%data, %aten::_convolution_0.weight, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]) /* span=aten::_convolution_0:0:0 */;\n",
      "  %1 = nn.batch_norm(%0, %aten::batch_norm_0.weight, %aten::batch_norm_0.bias, %aten::batch_norm_0.running_mean, %aten::batch_norm_0.running_var) /* span=aten::batch_norm_0:0:0 */;\n",
      "  %2 = %1.0 /* span=aten::batch_norm_0:0:0 */;\n",
      "  nn.relu(%2) /* span=aten::relu_0:0:0 */\n",
      "}\n",
      "INFO|2024-01-09 12:50:27,880|test| -> 原始模型(绑定参数)：fn (%data: Tensor[(1, 3, 32, 32), float32] /* span=aten::_convolution_0.data:0:0 */) {\n",
      "  %0 = nn.conv2d(%data, meta[relay.Constant][0], strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]) /* span=aten::_convolution_0:0:0 */;\n",
      "  %1 = nn.batch_norm(%0, meta[relay.Constant][1], meta[relay.Constant][2], meta[relay.Constant][3], meta[relay.Constant][4]) /* span=aten::batch_norm_0:0:0 */;\n",
      "  %2 = %1.0 /* span=aten::batch_norm_0:0:0 */;\n",
      "  nn.relu(%2) /* span=aten::relu_0:0:0 */\n",
      "}\n",
      "\n",
      "INFO|2024-01-09 12:50:28,593|test| -> 原始模型(化简后)：fn (%data: Tensor[(1, 3, 32, 32), float32] /* ty=Tensor[(1, 3, 32, 32), float32] span=aten::_convolution_0.data:0:0 */) -> Tensor[(1, 64, 16, 16), float32] {\n",
      "  %0 = nn.conv2d(%data, meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), float32] */, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 16, 16), float32] */;\n",
      "  %1 = add(%0, meta[relay.Constant][1] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 16, 16), float32] */;\n",
      "  nn.relu(%1) /* ty=Tensor[(1, 64, 16, 16), float32] span=aten::relu_0:0:0 */\n",
      "} /* ty=fn (Tensor[(1, 3, 32, 32), float32]) -> Tensor[(1, 64, 16, 16), float32] */\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.relay import transform as _transform\n",
    "from tvm.relay import expr as _expr\n",
    "from tvm.relay import Call, Constant, Function\n",
    "from tvm.ir.op import Op\n",
    "\n",
    "def _bind_params(func, params):\n",
    "    \"\"\"将 params 绑定到 func\"\"\"\n",
    "    name_dict = {}\n",
    "    for arg in func.params:\n",
    "        name = arg.name_hint\n",
    "        if name in name_dict:\n",
    "            name_dict[name] = None\n",
    "        else:\n",
    "            name_dict[name] = arg\n",
    "    bind_dict = {}\n",
    "    for k, v in params.items():\n",
    "        if k not in name_dict:\n",
    "            continue\n",
    "        arg = name_dict[k]\n",
    "        if arg is None:\n",
    "            raise ValueError(f\"Multiple args in the function have name {k}\")\n",
    "        bind_dict[arg] = _expr.const(v)\n",
    "    return _expr.bind(func, bind_dict)\n",
    "\n",
    "input_name = \"data\"\n",
    "input_shape = (1, 3, 32, 32)\n",
    "frontend_mod = torch.jit.trace(TestModel().eval(), torch.randn(*input_shape))\n",
    "# 将前端模型翻译为 relay 模型\n",
    "origin_mod, params = relay.frontend.from_pytorch(frontend_mod, [(input_name, input_shape)])\n",
    "logger.info(f'原始模型：{origin_mod[\"main\"]}')\n",
    "# 将 params 绑定到 origin_mod\n",
    "if params:\n",
    "    origin_mod[\"main\"] = _bind_params(origin_mod[\"main\"], params)\n",
    "logger.info(f'原始模型(绑定参数)：{origin_mod[\"main\"]}')\n",
    "# 化简并折叠常量\n",
    "optimize = tvm.transform.Sequential([\n",
    "        _transform.SimplifyInference(),\n",
    "        _transform.FoldConstant(),\n",
    "        _transform.FoldScaleAxis(),\n",
    "        _transform.CanonicalizeOps(),\n",
    "        _transform.FoldConstant(),\n",
    "])\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    run_mod = optimize(origin_mod)\n",
    "logger.info(f'原始模型(化简后)：{run_mod[\"main\"]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "class _Transform(tvm.relay.ExprMutator):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.binds = {}\n",
    "        self.func_id = 0\n",
    "    def visit_call(self, call):\n",
    "        new_fn = self.visit(call.op)\n",
    "        new_args = [self.visit(arg) for arg in call.args]\n",
    "        call = Call(new_fn, new_args, call.attrs, call.type_args, call.span)\n",
    "        if isinstance(new_fn, Op):\n",
    "            if new_fn.name == \"nn.batch_norm\":\n",
    "                self.binds[f\"{new_fn.name}_{self.func_id}\"] = call\n",
    "                self.func_id += 1\n",
    "        return call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "def @main(%data: Tensor[(1, 3, 32, 32), float32] /* ty=Tensor[(1, 3, 32, 32), float32] span=aten::_convolution_0.data:0:0 */) {\n",
       "  %0 = nn.conv2d(%data, meta[relay.Constant][0] /* ty=Tensor[(64, 3, 7, 7), float32] */, strides=[2, 2], padding=[3, 3, 3, 3], channels=64, kernel_size=[7, 7]) /* ty=Tensor[(1, 64, 16, 16), float32] */;\n",
       "  add(%0, meta[relay.Constant][1] /* ty=Tensor[(64, 1, 1), float32] */) /* ty=Tensor[(1, 64, 16, 16), float32] */\n",
       "}\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relay.analysis.extract_intermdeiate_expr(run_mod, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
