{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试 Roofline 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import set_env\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning) # 忽略用户警告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import platform\n",
    "from io import StringIO\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tvm.testing\n",
    "import tvm.utils\n",
    "from tvm import relay, rpc\n",
    "from tvm.contrib import utils\n",
    "from tvm.contrib.debugger import debug_executor\n",
    "from tvm.relay.testing import mlp\n",
    "from tvm.runtime import profiler_vm\n",
    "from tvm.runtime.profiling import Report\n",
    "from tvm.script import tir as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate_peak_flops_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 14:00:46.799 INFO bind to 0.0.0.0:9091\n",
      "2024-01-19 14:00:46.800 INFO connected from ('127.0.0.1', 37002)\n",
      "2024-01-19 14:00:46.801 INFO start serving at /tmp/tmpb673zo51\n",
      "2024-01-19 14:00:46.940 INFO load_module /tmp/tmpb673zo51/peak_fma_flops.tar\n",
      "2024-01-19 14:00:48.501 INFO bind to 0.0.0.0:9092\n",
      "2024-01-19 14:00:48.538 INFO connected from ('127.0.0.1', 54284)\n",
      "2024-01-19 14:00:48.539 INFO start serving at /tmp/tmp_2qik6wl\n",
      "2024-01-19 14:00:48.684 INFO load_module /tmp/tmp_2qik6wl/peak_fma_flops.tar\n",
      "2024-01-19 14:00:51.826 INFO bind to 0.0.0.0:9091\n",
      "2024-01-19 14:00:51.880 INFO connected from ('127.0.0.1', 43448)\n",
      "2024-01-19 14:00:51.881 INFO start serving at /tmp/tmp_8y155vs\n",
      "2024-01-19 14:00:52.016 INFO load_module /tmp/tmp_8y155vs/peak_fma_flops.tar\n"
     ]
    }
   ],
   "source": [
    "for dtype in [\"float32\", \"int8\", \"int32\"]:\n",
    "    server = rpc.Server(key=\"roofline_flops_cpu\")\n",
    "    remote = rpc.connect(\"127.0.0.1\", server.port, key=\"roofline_flops_cpu\")\n",
    "    target = tvm.target.Target(\"llvm -mattr=+fma,+avx2\")\n",
    "    dev = remote.device(str(target))\n",
    "    # This test uses vectorized instructions so we need a target that supports them\n",
    "    flops = tvm.utils.roofline.x86.estimate_peak_fma_vector_flops(target, dev, remote, dtype)\n",
    "    # Assume we can achieve 1 GFLOP/s per thread, which is 1 FLOP per cycle on a 1GHz cpu.\n",
    "    assert (\n",
    "        flops > 10**9 and flops < 10**14\n",
    "    ), f\"FLOP/s should be between 10^9 and 10^14, but it is {flops}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate_peak_flops_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm_book.config.env import set_cudnn\n",
    "set_cudnn() # 设置 CUDA 环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 14:00:54.378 INFO bind to 0.0.0.0:9092\n",
      "2024-01-19 14:00:54.410 INFO connected from ('127.0.0.1', 55232)\n",
      "2024-01-19 14:00:54.411 INFO start serving at /tmp/tmpmkby12ft\n",
      "2024-01-19 14:00:56.002 INFO load_module /tmp/tmpmkby12ft/peak_mma_flops.tar\n",
      "2024-01-19 14:00:56.861 INFO load_module /tmp/tmpmkby12ft/peak_fma_flops.tar\n"
     ]
    }
   ],
   "source": [
    "server = rpc.Server(key=\"roofline_flops_gpu\")\n",
    "remote = rpc.connect(\"127.0.0.1\", server.port, key=\"roofline_flops_gpu\")\n",
    "target = tvm.target.Target(\"cuda\")\n",
    "dev = remote.device(str(target))\n",
    "# This test uses vectorized instructions so we need a target that supports them\n",
    "flops = tvm.utils.roofline.cuda.estimate_peak_flops_tensorcore(target, dev, remote)\n",
    "# should be able to hit a TFLOP/s with tensor cores\n",
    "assert (\n",
    "    flops > 10**12 and flops < 10**14\n",
    "), f\"FLOP/s should be between 10^12 and 10^14, but it is {flops}\"\n",
    "\n",
    "# this test should run on all gpus\n",
    "flops = tvm.utils.roofline.cuda.estimate_peak_flops_fma(target, dev, remote, \"float32\")\n",
    "# most gpus since 2016 should be able to hit a TFLOP/s with fma instructions\n",
    "assert (\n",
    "    flops > 10**12 and flops < 10**14\n",
    "), f\"FLOP/s should be between 10^12 and 10^14, but it is {flops}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate_peak_bandwidth_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 14:00:58.037 INFO bind to 0.0.0.0:9091\n",
      "2024-01-19 14:00:58.094 INFO connected from ('127.0.0.1', 43462)\n",
      "2024-01-19 14:00:58.095 INFO start serving at /tmp/tmpcxaxh3kt\n",
      "2024-01-19 14:00:58.229 INFO load_module /tmp/tmpcxaxh3kt/peak_bandwidth.tar\n"
     ]
    }
   ],
   "source": [
    "server = rpc.Server(key=\"roofline_bandwidth_cpu\")\n",
    "remote = rpc.connect(\"127.0.0.1\", server.port, key=\"roofline_bandwidth_cpu\")\n",
    "target = tvm.target.Target(\"llvm -mattr=+fma,+avx2\")\n",
    "dev = remote.device(str(target))\n",
    "# This test uses vectorized instructions so we need a target that supports them\n",
    "bandwidth = tvm.utils.roofline.x86.estimate_peak_bandwidth_dram(target, dev, remote)\n",
    "# Assume we can achieve 1 GB/s. DDR2 should transfer somewhere around 6\n",
    "# GB/s, so this should leave enough wiggle room.\n",
    "assert (\n",
    "    bandwidth > 10**9 and bandwidth < 10**12\n",
    "), f\"Bandwidth should be between 10^9 and 10^12, but it is {bandwidth}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate_peak_bandwidth_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 14:01:11.762 INFO bind to 0.0.0.0:9092\n",
      "2024-01-19 14:01:11.815 INFO connected from ('127.0.0.1', 48560)\n",
      "2024-01-19 14:01:11.816 INFO start serving at /tmp/tmpwz5b9dc6\n",
      "2024-01-19 14:01:12.493 INFO load_module /tmp/tmpwz5b9dc6/peak_bandwidth.tar\n"
     ]
    }
   ],
   "source": [
    "server = rpc.Server(key=\"roofline_bandwidth_gpu\")\n",
    "remote = rpc.connect(\"127.0.0.1\", server.port, key=\"roofline_bandwidth_gpu\")\n",
    "target = tvm.target.Target(\"cuda\")\n",
    "dev = remote.device(str(target))\n",
    "# This test uses vectorized instructions so we need a target that supports them\n",
    "bandwidth = tvm.utils.roofline.cuda.estimate_peak_bandwidth_global_mem(target, dev, remote)\n",
    "# should be able to hit a 100 GB/s on a GPU. GTX 280 hits 140 GB/s and\n",
    "# it is really old.\n",
    "assert (\n",
    "    bandwidth > 10**11 and bandwidth < 10**13\n",
    "), f\"Bandwidth should be between 10^9 and 10^12, but it is {bandwidth}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## roofline_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target, dev = \"llvm -mattr=+fma,+avx2\", \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 14:01:28.584 INFO bind to 0.0.0.0:9091\n",
      "2024-01-19 14:01:28.618 INFO connected from ('127.0.0.1', 51894)\n",
      "2024-01-19 14:01:28.619 INFO start serving at /tmp/tmpmu073udv\n",
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n",
      "2024-01-19 14:01:28.871 INFO load_module /tmp/tmpmu073udv/roofline_lib.tar\n",
      "2024-01-19 14:01:30.796 INFO load_module /tmp/tmpmu073udv/peak_fma_flops.tar\n",
      "2024-01-19 14:01:31.740 INFO load_module /tmp/tmpmu073udv/peak_bandwidth.tar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                   Duration (us)  Percent  Device  Count                                          Argument Shapes  Arithmetic Intensity  Bandwidth   Bound  Estimated FLOPs   FLOP/s              Hash  Loaded Bytes  Percent of Theoretical Optimal  VM::Argument Shapes  \n",
      "vm_mod_fused_nn_dense       1,911.23    95.44    cpu0      1  float32[512, 512], float32[512, 512], float32[512, 512]                    18    7.7e+09  memory      268,435,456  1.4e+11  6bf92d0ede030db0    14,696,448                              32                       \n",
      "VM::AllocStorage               13.25     0.66    cpu0      1                                                                                                                                                                                                float32[512, 512]  \n",
      "VM::AllocTensor                 1.98     0.10    cpu0      1                                        float32[512, 512]                                                                                                                                                          \n",
      "VM::UnknownOp                   1.07     0.05    cpu0      3                                                                                                                                                                                                                   \n",
      "----------                                                                                                                                                                                                                                                                     \n",
      "Sum                         1,927.53    96.25              6                                                                                                        268,435,456                               14,696,448                                                       \n",
      "Total                       2,002.57             cpu0      1                                                                                                                                                                                                                   \n",
      "\n",
      "Configuration\n",
      "-------------\n",
      "Number of threads: 24\n",
      "Estimated Peak Bandwidth (DRAM, byte/second): 2.4e+10\n",
      "Executor: VM\n",
      "Estimated Peak FLOP/s (float32 FMA): 2e+12\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = relay.var(\"a\", relay.TensorType((512, 512), \"float32\"))\n",
    "b = relay.var(\"b\", relay.TensorType((512, 512), \"float32\"))\n",
    "c = relay.nn.dense(a, b)\n",
    "mod = tvm.IRModule.from_expr(relay.Function([a, b], c))\n",
    "params = {}\n",
    "\n",
    "server = rpc.Server(key=\"roofline\")\n",
    "remote = rpc.connect(\"127.0.0.1\", server.port, key=\"roofline\")\n",
    "dev = remote.device(target)\n",
    "\n",
    "report = tvm.utils.roofline_analysis(mod, params, target, dev, remote=remote)\n",
    "print(report)\n",
    "\n",
    "assert \"Bound\" in report.table()\n",
    "assert \"Percent of Theoretical Optimal\" in report.table()\n",
    "for call in report.calls:\n",
    "    if \"Percent of Theoretical Optimal\" in call:\n",
    "        if target.startswith(\"llvm\"):\n",
    "            # Ideally we'd like a little tighter bound here, but it is hard to\n",
    "            # know how well this dense will perform without tuning. And we\n",
    "            # don't have an operator that uses a specific number of flops.\n",
    "            assert call[\"Percent of Theoretical Optimal\"].ratio >= 5.0\n",
    "        elif target == \"cuda\":\n",
    "            # The cuda gpu kernel is really poorly optimized\n",
    "            assert 90 >= call[\"Percent of Theoretical Optimal\"].ratio >= 0.01"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
