{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 测试 Roofline 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import set_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "import platform\n",
    "from io import StringIO\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tvm.testing\n",
    "import tvm.utils\n",
    "from tvm import relay, rpc\n",
    "from tvm.contrib import utils\n",
    "from tvm.contrib.debugger import debug_executor\n",
    "from tvm.relay.testing import mlp\n",
    "from tvm.runtime import profiler_vm\n",
    "from tvm.runtime.profiling import Report\n",
    "from tvm.script import tir as T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate_peak_flops_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:33:37.135 INFO bind to 0.0.0.0:9091\n",
      "2024-01-19 13:33:37.137 INFO connected from ('127.0.0.1', 57510)\n",
      "2024-01-19 13:33:37.138 INFO start serving at /tmp/tmpfh9tnqax\n",
      "2024-01-19 13:33:37.311 INFO load_module /tmp/tmpfh9tnqax/peak_fma_flops.tar\n",
      "2024-01-19 13:33:38.785 INFO bind to 0.0.0.0:9092\n",
      "2024-01-19 13:33:38.838 INFO connected from ('127.0.0.1', 33856)\n",
      "2024-01-19 13:33:38.839 INFO start serving at /tmp/tmprw44z7bx\n",
      "2024-01-19 13:33:38.987 INFO load_module /tmp/tmprw44z7bx/peak_fma_flops.tar\n",
      "2024-01-19 13:33:42.105 INFO bind to 0.0.0.0:9091\n",
      "2024-01-19 13:33:42.141 INFO connected from ('127.0.0.1', 50332)\n",
      "2024-01-19 13:33:42.142 INFO start serving at /tmp/tmph5er4tvd\n",
      "2024-01-19 13:33:42.277 INFO load_module /tmp/tmph5er4tvd/peak_fma_flops.tar\n"
     ]
    }
   ],
   "source": [
    "for dtype in [\"float32\", \"int8\", \"int32\"]:\n",
    "    server = rpc.Server(key=\"roofline_flops_cpu\")\n",
    "    remote = rpc.connect(\"127.0.0.1\", server.port, key=\"roofline_flops_cpu\")\n",
    "    target = tvm.target.Target(\"llvm -mattr=+fma,+avx2\")\n",
    "    dev = remote.device(str(target))\n",
    "    # This test uses vectorized instructions so we need a target that supports them\n",
    "    flops = tvm.utils.roofline.x86.estimate_peak_fma_vector_flops(target, dev, remote, dtype)\n",
    "    # Assume we can achieve 1 GFLOP/s per thread, which is 1 FLOP per cycle on a 1GHz cpu.\n",
    "    assert (\n",
    "        flops > 10**9 and flops < 10**14\n",
    "    ), f\"FLOP/s should be between 10^9 and 10^14, but it is {flops}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate_peak_flops_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm_book.config.env import set_cudnn\n",
    "set_cudnn() # 设置 CUDA 环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:33:44.614 INFO bind to 0.0.0.0:9092\n",
      "2024-01-19 13:33:44.668 INFO connected from ('127.0.0.1', 33872)\n",
      "2024-01-19 13:33:44.669 INFO start serving at /tmp/tmp4myep303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc --fatbin -O3 -gencode arch=compute_86,code=sm_86 -o /tmp/tmphkhc1un6/tvm_kernels.fatbin /tmp/tmphkhc1un6/tvm_kernels.cu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:33:45.579 INFO load_module /tmp/tmp4myep303/peak_mma_flops.tar\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc --fatbin -O3 -gencode arch=compute_86,code=sm_86 -o /tmp/tmplrh4lpaw/tvm_kernels.fatbin /tmp/tmplrh4lpaw/tvm_kernels.cu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:33:46.439 INFO load_module /tmp/tmp4myep303/peak_fma_flops.tar\n"
     ]
    }
   ],
   "source": [
    "server = rpc.Server(key=\"roofline_flops_gpu\")\n",
    "remote = rpc.connect(\"127.0.0.1\", server.port, key=\"roofline_flops_gpu\")\n",
    "target = tvm.target.Target(\"cuda\")\n",
    "dev = remote.device(str(target))\n",
    "# This test uses vectorized instructions so we need a target that supports them\n",
    "flops = tvm.utils.roofline.cuda.estimate_peak_flops_tensorcore(target, dev, remote)\n",
    "# should be able to hit a TFLOP/s with tensor cores\n",
    "assert (\n",
    "    flops > 10**12 and flops < 10**14\n",
    "), f\"FLOP/s should be between 10^12 and 10^14, but it is {flops}\"\n",
    "\n",
    "# this test should run on all gpus\n",
    "flops = tvm.utils.roofline.cuda.estimate_peak_flops_fma(target, dev, remote, \"float32\")\n",
    "# most gpus since 2016 should be able to hit a TFLOP/s with fma instructions\n",
    "assert (\n",
    "    flops > 10**12 and flops < 10**14\n",
    "), f\"FLOP/s should be between 10^12 and 10^14, but it is {flops}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate_peak_bandwidth_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 13:33:47.650 INFO bind to 0.0.0.0:9091\n",
      "2024-01-19 13:33:47.705 INFO connected from ('127.0.0.1', 50348)\n",
      "2024-01-19 13:33:47.706 INFO start serving at /tmp/tmpljz1k97w\n",
      "2024-01-19 13:33:47.860 INFO load_module /tmp/tmpljz1k97w/peak_bandwidth.tar\n"
     ]
    }
   ],
   "source": [
    "server = rpc.Server(key=\"roofline_bandwidth_cpu\")\n",
    "remote = rpc.connect(\"127.0.0.1\", server.port, key=\"roofline_bandwidth_cpu\")\n",
    "target = tvm.target.Target(\"llvm -mattr=+fma,+avx2\")\n",
    "dev = remote.device(str(target))\n",
    "# This test uses vectorized instructions so we need a target that supports them\n",
    "bandwidth = tvm.utils.roofline.x86.estimate_peak_bandwidth_dram(target, dev, remote)\n",
    "# Assume we can achieve 1 GB/s. DDR2 should transfer somewhere around 6\n",
    "# GB/s, so this should leave enough wiggle room.\n",
    "assert (\n",
    "    bandwidth > 10**9 and bandwidth < 10**12\n",
    "), f\"Bandwidth should be between 10^9 and 10^12, but it is {bandwidth}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimate_peak_bandwidth_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "server = rpc.Server(key=\"roofline_bandwidth_gpu\")\n",
    "remote = rpc.connect(\"127.0.0.1\", server.port, key=\"roofline_bandwidth_gpu\")\n",
    "target = tvm.target.Target(\"cuda\")\n",
    "dev = remote.device(str(target))\n",
    "# This test uses vectorized instructions so we need a target that supports them\n",
    "bandwidth = tvm.utils.roofline.cuda.estimate_peak_bandwidth_global_mem(target, dev, remote)\n",
    "# should be able to hit a 100 GB/s on a GPU. GTX 280 hits 140 GB/s and\n",
    "# it is really old.\n",
    "assert (\n",
    "    bandwidth > 10**11 and bandwidth < 10**13\n",
    "), f\"Bandwidth should be between 10^9 and 10^12, but it is {bandwidth}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## roofline_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target, dev = \"llvm -mattr=+fma,+avx2\", \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = relay.var(\"a\", relay.TensorType((512, 512), \"float32\"))\n",
    "b = relay.var(\"b\", relay.TensorType((512, 512), \"float32\"))\n",
    "c = relay.nn.dense(a, b)\n",
    "mod = tvm.IRModule.from_expr(relay.Function([a, b], c))\n",
    "params = {}\n",
    "\n",
    "server = rpc.Server(key=\"roofline\")\n",
    "remote = rpc.connect(\"127.0.0.1\", server.port, key=\"roofline\")\n",
    "dev = remote.device(target)\n",
    "\n",
    "report = tvm.utils.roofline_analysis(mod, params, target, dev, remote=remote)\n",
    "print(report)\n",
    "\n",
    "assert \"Bound\" in report.table()\n",
    "assert \"Percent of Theoretical Optimal\" in report.table()\n",
    "for call in report.calls:\n",
    "    if \"Percent of Theoretical Optimal\" in call:\n",
    "        if target.startswith(\"llvm\"):\n",
    "            # Ideally we'd like a little tighter bound here, but it is hard to\n",
    "            # know how well this dense will perform without tuning. And we\n",
    "            # don't have an operator that uses a specific number of flops.\n",
    "            assert call[\"Percent of Theoretical Optimal\"].ratio >= 5.0\n",
    "        elif target == \"cuda\":\n",
    "            # The cuda gpu kernel is really poorly optimized\n",
    "            assert 90 >= call[\"Percent of Theoretical Optimal\"].ratio >= 0.01"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
