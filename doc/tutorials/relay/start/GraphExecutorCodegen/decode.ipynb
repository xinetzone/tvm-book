{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 解读 `GraphExecutorCodegen`\n",
    "\n",
    "## 以双头网络作为引子\n",
    "\n",
    "创建双头输出小网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(dict_keys(['p0']), (2, 1, 3, 3), 'int8')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.relay.build_module import bind_params_by_name\n",
    "\n",
    "x = relay.var(\"x\", shape=(1, 1, 8, 8), dtype=\"int8\")\n",
    "w = relay.var(\"w\", shape=(2, 1, 3, 3), dtype=\"int8\")\n",
    "conv2d = relay.op.nn.conv2d(x, w)\n",
    "relu = relay.op.nn.relu(conv2d)\n",
    "mod = tvm.IRModule.from_expr(relay.Tuple([conv2d, relu]))\n",
    "mod[\"main\"] = bind_params_by_name(mod[\"main\"], \n",
    "                                  {\"w\": tvm.nd.array(np.ones(shape=(2, 1, 3, 3), \n",
    "                                                             dtype=\"int8\"))})\n",
    "rt_lib = relay.build(mod, target=\"llvm\")\n",
    "rt_lib.params.keys(), rt_lib.params[\"p0\"].shape, rt_lib.params[\"p0\"].dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此网络结构如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def @main(%x: Tensor[(1, 1, 8, 8), int8]) {\n",
      "  %0 = nn.conv2d(%x, meta[relay.Constant][0], padding=[0, 0, 0, 0]);\n",
      "  %1 = nn.relu(%0);\n",
      "  (%0, %1)\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(rt_lib.ir_mod)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查看 Graph Json："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arg_nodes = [ 0, 1,]\n",
      "heads = [ [ 2, 0, 0,], [ 3, 0, 0,],]\n",
      "node_row_ptr = [ 0, 1, 2, 3, 4,]\n",
      "[[nodes]]\n",
      "op = \"null\"\n",
      "name = \"x\"\n",
      "inputs = []\n",
      "\n",
      "[[nodes]]\n",
      "op = \"null\"\n",
      "name = \"p0\"\n",
      "inputs = []\n",
      "\n",
      "[[nodes]]\n",
      "op = \"tvm_op\"\n",
      "name = \"tvmgen_default_fused_nn_conv2d\"\n",
      "inputs = [ [ 0, 0, 0,], [ 1, 0, 0,],]\n",
      "\n",
      "[nodes.attrs]\n",
      "num_outputs = \"1\"\n",
      "num_inputs = \"2\"\n",
      "flatten_data = \"0\"\n",
      "func_name = \"tvmgen_default_fused_nn_conv2d\"\n",
      "out_layout = \"\"\n",
      "kernel_layout = \"OIHW\"\n",
      "data_layout = \"NCHW\"\n",
      "hash = \"8f5bab575bcb83dc\"\n",
      "[[nodes]]\n",
      "op = \"tvm_op\"\n",
      "name = \"tvmgen_default_fused_nn_relu\"\n",
      "inputs = [ [ 2, 0, 0,],]\n",
      "\n",
      "[nodes.attrs]\n",
      "num_outputs = \"1\"\n",
      "num_inputs = \"1\"\n",
      "flatten_data = \"0\"\n",
      "func_name = \"tvmgen_default_fused_nn_relu\"\n",
      "hash = \"fd6e720bc47ba75c\"\n",
      "\n",
      "[attrs]\n",
      "dltype = [ \"list_str\", [ \"int8\", \"int8\", \"int8\", \"int8\",],]\n",
      "device_index = [ \"list_int\", [ 1, 1, 1, 1,],]\n",
      "storage_id = [ \"list_int\", [ 0, 1, 2, 3,],]\n",
      "shape = [ \"list_shape\", [ [ 1, 1, 8, 8,], [ 2, 1, 3, 3,], [ 1, 2, 6, 6,], [ 1, 2, 6, 6,],],]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import toml\n",
    "bunch = eval(rt_lib.graph_json)\n",
    "print(toml.dumps(bunch))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 解读 `CreateGraphCodegenMod` 源码\n",
    "\n",
    "定义计算图节点类型枚举类：\n",
    "\n",
    "```c++\n",
    "/*! \\brief Node types */\n",
    "enum GraphNodeType {\n",
    "  kGraphNop,\n",
    "  kGraphInputNode,\n",
    "  kGraphOpNode,\n",
    "};\n",
    "```\n",
    "\n",
    "使用 Python 实现为："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "\n",
    "class GraphNodeType(Enum):\n",
    "    \"\"\"节点枚举类型\n",
    "    Attrs:\n",
    "        kGraphNop: 非算子节点\n",
    "        kGraphInputNode: 参数节点的索引列表，它是计算图的占位符/变量/输入节点 或 constant/param。\n",
    "        kGraphOpNode: 算子节点\n",
    "    \"\"\"\n",
    "    kGraphNop: int = 0\n",
    "    kGraphInputNode: int = 1\n",
    "    kGraphOpNode: int = 2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "节点基类定义如下：\n",
    "\n",
    "```c++\n",
    "/*! \\brief Base Node class */\n",
    "class GraphNode {\n",
    " public:\n",
    "  GraphNode() {}\n",
    "  virtual void Save(dmlc::JSONWriter* writer) const {}\n",
    "  virtual void Load(dmlc::JSONReader* reader) {}\n",
    "  virtual GraphNodeType Type() const { return kGraphNop; }\n",
    "  virtual ~GraphNode() {}\n",
    "\n",
    " public:\n",
    "  int num_outputs_{1};\n",
    "  std::string name_;\n",
    "  GraphAttrs attrs_;\n",
    "};\n",
    "```\n",
    "\n",
    "使用 Python 实现如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from dataclasses import dataclass\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "GraphAttrs = dict[str, Any]\n",
    "\n",
    "@dataclass\n",
    "class GraphNode(ABC):\n",
    "    name: str\n",
    "    attrs: GraphAttrs\n",
    "    \n",
    "    @abstractmethod\n",
    "    def Save(self, writer) -> None:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def Load(self, reader) -> None:\n",
    "        ...\n",
    "\n",
    "    @abstractmethod\n",
    "    def Type(self) -> GraphNodeType:\n",
    "        return GraphNodeType.kGraphNop"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输入节点：\n",
    "\n",
    "```c++\n",
    "/*! \\brief Input Node */\n",
    "class GraphInputNode : public GraphNode {\n",
    " public:\n",
    "  GraphInputNode() {}\n",
    "  GraphInputNode(const std::string& name, const GraphAttrs& attrs) {\n",
    "    name_ = name;\n",
    "    attrs_ = attrs;\n",
    "  }\n",
    "\n",
    "  GraphNodeType Type() const override { return kGraphInputNode; }\n",
    "\n",
    "  void Save(dmlc::JSONWriter* writer) const override {\n",
    "    const std::string op_name{\"null\"};\n",
    "    writer->BeginObject();\n",
    "    writer->WriteObjectKeyValue(\"op\", op_name);\n",
    "    writer->WriteObjectKeyValue(\"name\", this->name_);\n",
    "    writer->WriteObjectKeyValue(\"inputs\", std::list<int>());\n",
    "    writer->EndObject();\n",
    "  }\n",
    "  static std::shared_ptr<GraphNode> make_node_ptr(const std::string& name,\n",
    "                                                  const GraphAttrs& attrs) {\n",
    "    auto ptr = std::make_shared<GraphInputNode>(name, attrs);\n",
    "    return std::dynamic_pointer_cast<GraphNode>(ptr);\n",
    "  }\n",
    "};\n",
    "```\n",
    "\n",
    "使用 Python 实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GraphInputNode(GraphNode):\n",
    "    inputs: list[int]\n",
    "\n",
    "    def Type(self) -> GraphNodeType:\n",
    "        return GraphNodeType.kGraphInputNode\n",
    "    def Save(self, writer) -> None:\n",
    "        bunch = {\n",
    "            \"op\": \"null\",\n",
    "            \"name\": self.name,\n",
    "            \"inputs\": []\n",
    "        }\n",
    "        # 写入到 writer 句柄\n",
    "        ...\n",
    "\n",
    "    def Load(self, reader) -> None:\n",
    "        ...\n",
    "\n",
    "    def make_node_ptr(self):\n",
    "        # make_node(name, attrs)\n",
    "        ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同样使用 Python 实现算子节点类："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class GraphNodeRef:\n",
    "    ident: int # 节点引用索引\n",
    "    index: int = 0 # 暂不知作用\n",
    "    version: int = 0 # 暂不知作用\n",
    "\n",
    "@dataclass\n",
    "class GraphOpNode(GraphNode):\n",
    "    nd_attrs: GraphAttrs\n",
    "    op_name: str\n",
    "    inputs: list[GraphNodeRef]\n",
    "    num_outputs: int = 1\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.attrs[\"func_name\"] = self.op_name\n",
    "        self.attrs[\"flatten_data\"] = \"0\"\n",
    "        self.attrs[\"num_inputs\"] = str(sum(self.inputs))\n",
    "        self.attrs[\"num_outputs\"] = str(self.num_outputs)\n",
    "\n",
    "    def Type(self) -> GraphNodeType:\n",
    "        return GraphNodeType.kGraphOpNode\n",
    "    \n",
    "    def Save(self, writer) -> None:\n",
    "        bunch = {\n",
    "            \"op\": \"tvm_op\",\n",
    "            \"name\": self.name,\n",
    "            \"attrs\": self.attrs,\n",
    "            \"inputs\": self.inputs\n",
    "        }\n",
    "        # 写入到 writer 句柄\n",
    "        ...\n",
    "\n",
    "    def Load(self, reader) -> None:\n",
    "        ...\n",
    "\n",
    "    def make_node_ptr(self):\n",
    "        # make_node(name, nd_attrs, op_name, inputs, attrs, num_outputs)\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面进入正题：\n",
    "\n",
    "## 代码生成器 `GraphExecutorCodegen` \n",
    "\n",
    "图执行器的代码生成器，生成包含 Graph JSON、模块和模块的参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LoweredOutput:\n",
    "    graph_json: str\n",
    "    lowered_funcs: dict[str, tvm.IRModule]\n",
    "    external_mods: list[tvm.IRModule]\n",
    "    params: dict[str, tvm.runtime.NDArray]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GraphExecutorCodegen:\n",
    "    mod: tvm.runtime.Module\n",
    "    targets: list[tvm.target.Target]\n",
    "\n",
    "    def GetStorageInfo(self, expr) -> \"tvm.relay.backend.StorageInfo\":\n",
    "        \"\"\"获取单个表达式的存储信息\"\"\"\n",
    "        ...\n",
    "\n",
    "    def Codegen(self, mod: tvm.IRModule,\n",
    "                func: relay.Function,\n",
    "                mod_name: str) -> \"tvm.relay.backend.LoweredOutput\":\n",
    "        \"\"\"\n",
    "        1. lowering 前需要规划内存并更新 workspace 大小\n",
    "        2. 获取 lowered_main_func\n",
    "        3. 将所有参数转换为输入节点。\n",
    "        4. 收集外部代码生成的任何运行时模块。\n",
    "        5. 收集外部代码提取的任何常量。\n",
    "        6. 收集在 lowering 过程中提取的任何常数。\n",
    "        7. 按目标分隔模块中的函数\n",
    "        8. 需要保存 Graph Json 到输出\n",
    "        \"\"\"\n",
    "        ..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 回到双头网络的例子中\n",
    "\n",
    "下面仔细解读这些 Graph Json 信息。\n",
    "\n",
    "由于双头网络有两个输出，故而 \n",
    "\n",
    "1. `heads = [ [ 2, 0, 0,], [ 3, 0, 0,],]` 指示两个输出节点的索引。\n",
    "2. `arg_nodes = [ 0, 1,]` 说明参数节点的位置。\n",
    "\n",
    "使用 Python 实现："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import field\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GraphAttrs:\n",
    "    \"\"\"`\n",
    "    Args:\n",
    "        dltype: 每个节点的数据类型按顺序排列。\n",
    "        device_index: 按顺序为每个节点分配设备。\n",
    "        storage_id: 存储布局中每个节点的内存 slot id。\n",
    "        shape: 每个节点的 k 阶形状。\n",
    "        storage_id: 存储布局中每个节点的内存 slot id。\n",
    "                    将参数名称映射到一对 ({storage_id: tvm.runtime.NDArray})。在运行时，可以使用 storage_id 查找参数。\n",
    "    \"\"\"\n",
    "    dltype: list\n",
    "    device_index: list\n",
    "    storage_id: list\n",
    "    shape: list\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GraphNodeAttrs:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        flatten_data: 是否需要在执行前将数据扁平化（flattened）\n",
    "        func_name: 融合函数名，对应于 Relay 编译过程生成的库中的符号。\n",
    "        num_inputs: 此节点的 inputs 个数\n",
    "        num_outputs: 此节点产生的 outputs 个数\n",
    "    \"\"\"\n",
    "    func_name: str\n",
    "    num_inputs: str\n",
    "    num_outputs: str\n",
    "    flatten_data: str = \"0\"\n",
    "    hash: str|None = None\n",
    "    \n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GraphNode:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        op: 运算类型，`null` 意味着它是占位符/变量/输入节点，`tvm_op` 意味着这个节点可以被执行\n",
    "        name: 节点名字\n",
    "        inputs: 运算的 inputs 位置，inputs 是包含 `(nodeid, index, version)` 的元组列表。(可选)\n",
    "    \"\"\"\n",
    "    op: str\n",
    "    name: str\n",
    "    inputs: list[int] = field(default_factory=list)\n",
    "    attrs: Any = None\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class GraphJson:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        arg_nodes:参数节点的索引列表，它是计算图的占位符/变量/输入节点或 constant/param。\n",
    "        heads: 输出节点的索引列表。\n",
    "        node_row_ptr: 存储 forward 路径的历史，所以推断任务中可以跳过某些算子来构建子图。\n",
    "        attrs: 可以包含版本号或类似的有用信息。\n",
    "        nodes: 节点是占位符或可计算节点。\n",
    "    \"\"\"\n",
    "    arg_nodes: list[int]\n",
    "    heads: list[GraphNodeRef]\n",
    "    node_row_ptr: list[int]\n",
    "    attrs: GraphAttrs\n",
    "    nodes: list[GraphNode]\n",
    "\n",
    "    def __post_init__(self):\n",
    "        self.heads = [GraphNodeRef(*head) for head in self.heads]\n",
    "        self.attrs = GraphAttrs(**self.attrs)\n",
    "        self.nodes = [GraphNode(**node) for node in self.nodes]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "代码被维护在 `tvm_book` API 中。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import asdict\n",
    "from tvm_book.tvm_utils.graph_json import GraphJson\n",
    "from tvm_book.data.dataclass import TensorType\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Node:\n",
    "    inputs: list[TensorType]\n",
    "    outputs: list[TensorType]\n",
    "    attrs: dict[str, Any]\n",
    "\n",
    "\n",
    "graph_json = GraphJson(**eval(rt_lib.graph_json))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "转换为字典："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['arg_nodes', 'heads', 'node_row_ptr', 'attrs', 'nodes'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asdict(graph_json).keys()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其他信息："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GraphNodeRef(ident=2, index=0, version=0),\n",
       " GraphNodeRef(ident=3, index=0, version=0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_json.heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphAttrs(dltype=['list_str', ['int8', 'int8', 'int8', 'int8']], device_index=['list_int', [1, 1, 1, 1]], storage_id=['list_int', [0, 1, 2, 3]], shape=['list_shape', [[1, 1, 8, 8], [2, 1, 3, 3], [1, 2, 6, 6], [1, 2, 6, 6]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_json.attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[GraphNode(op='null', name='x', inputs=[], attrs=None),\n",
       " GraphNode(op='null', name='p0', inputs=[], attrs=None),\n",
       " GraphNode(op='tvm_op', name='tvmgen_default_fused_nn_conv2d', inputs=[[0, 0, 0], [1, 0, 0]], attrs={'num_outputs': '1', 'num_inputs': '2', 'flatten_data': '0', 'func_name': 'tvmgen_default_fused_nn_conv2d', 'out_layout': '', 'kernel_layout': 'OIHW', 'data_layout': 'NCHW', 'hash': '8f5bab575bcb83dc'}),\n",
       " GraphNode(op='tvm_op', name='tvmgen_default_fused_nn_relu', inputs=[[2, 0, 0]], attrs={'num_outputs': '1', 'num_inputs': '1', 'flatten_data': '0', 'func_name': 'tvmgen_default_fused_nn_relu', 'hash': 'fd6e720bc47ba75c'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_json.nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['list_shape', [[1, 1, 8, 8], [2, 1, 3, 3], [1, 2, 6, 6], [1, 2, 6, 6]]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_json.attrs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = []\n",
    "dtypes = graph_json.attrs.dltype[1]\n",
    "device_indexes = graph_json.attrs.device_index[1]\n",
    "storage_ids = graph_json.attrs.storage_id[1]\n",
    "shapes = graph_json.attrs.shape[1]\n",
    "for shape, dtype, storage_id, device_index, node in zip(shapes, dtypes, storage_ids, device_indexes, graph_json.nodes):\n",
    "    attr = {\n",
    "        \"storage_id\": storage_id,\n",
    "        \"device_index\": device_index,\n",
    "        \"inputs\": node.inputs,\n",
    "        \"op\": node.op,\n",
    "        \"op_type\": TensorType(shape=shape, dtype=dtype, name=node.name),\n",
    "    }\n",
    "    if node.name == \"tvm_op\":\n",
    "        attr.update(**node.attrs)\n",
    "    attrs.append(attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'storage_id': 0,\n",
       "  'device_index': 1,\n",
       "  'inputs': [],\n",
       "  'op': 'null',\n",
       "  'op_type': TensorType(shape=[1, 1, 8, 8], dtype='int8', name='x')},\n",
       " {'storage_id': 1,\n",
       "  'device_index': 1,\n",
       "  'inputs': [],\n",
       "  'op': 'null',\n",
       "  'op_type': TensorType(shape=[2, 1, 3, 3], dtype='int8', name='p0')},\n",
       " {'storage_id': 2,\n",
       "  'device_index': 1,\n",
       "  'inputs': [[0, 0, 0], [1, 0, 0]],\n",
       "  'op': 'tvm_op',\n",
       "  'op_type': TensorType(shape=[1, 2, 6, 6], dtype='int8', name='tvmgen_default_fused_nn_conv2d')},\n",
       " {'storage_id': 3,\n",
       "  'device_index': 1,\n",
       "  'inputs': [[2, 0, 0]],\n",
       "  'op': 'tvm_op',\n",
       "  'op_type': TensorType(shape=[1, 2, 6, 6], dtype='int8', name='tvmgen_default_fused_nn_relu')}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e0af55fbb1c4b4e8ca009f3673b968438b459a89daa1170f52b672ab74da765c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
