{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PackedFunc\n",
    "\n",
    "参考：[运行时系统](https://xinetzone.github.io/tvm/docs/arch/runtime.html)\n",
    "\n",
    "`Function` 在 TVM 中起着沟通 frontend 和 backend 的关键作用。`Function` 提供了类型擦除接口（type-erased interface），您可以使用位置参数回调函数。\n",
    "\n",
    "- 编译后的模块返回 `Function`。\n",
    "- TVM 后端还将其 API 注册并暴露为 `Function`。\n",
    "\n",
    "{class}`~tvm.runtime.packed_func.PackedFunc` 常见使用场景：\n",
    "\n",
    "- 自动暴露 C++ API 到 Python。\n",
    "- 从 Python 端调用 PackedFunc。\n",
    "- 在生成代码（generated code）中回调 Python 回调来检查结果。\n",
    "- 将 Python 钩子（hook）引入 C++ 后端。\n",
    "\n",
    "\n",
    "(global-func)=\n",
    "## 全局函数\n",
    "\n",
    "- {func}`tvm.register_func` 用于注册全局函数。\n",
    "\n",
    "下面的代码将 `my_packed_func` 注册为全局函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "\n",
    "targs = (10, 10.0, \"hello\")\n",
    "@tvm.register_func\n",
    "def my_packed_func(*args):\n",
    "    assert(tuple(args) == targs)\n",
    "    return 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- {func}`tvm.get_global_func`：获取全局函数。\n",
    "\n",
    "注意，这里只是从全局函数表中返回它，然后从 Python 端回调它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.runtime.packed_func import PackedFunc\n",
    "\n",
    "f = tvm.get_global_func(\"my_packed_func\")\n",
    "assert isinstance(f, PackedFunc)\n",
    "y = f(*targs)\n",
    "assert y == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "但是，也可以从 C++ 后端或在编译后的 TVM 代码中回调相同的函数。\n",
    "\n",
    "## Python 调用 C++ 接口\n",
    "\n",
    "使用 C++ 定义加法运算，并提供 Makefile：\n",
    "\n",
    "`````{tab-set}\n",
    "\n",
    "````{tab-item} C++\n",
    "```c++\n",
    "#include <tvm/runtime/packed_func.h>\n",
    "#include <tvm/runtime/registry.h>\n",
    "using namespace tvm::runtime;\n",
    "\n",
    "void MyAdd(TVMArgs args, TVMRetValue* rv) {\n",
    "  // 自动将参数转换为所需的类型。\n",
    "  int a = args[0];\n",
    "  int b = args[1];\n",
    "  // 自动分配返回值 rv\n",
    "  *rv = a + b;\n",
    "}\n",
    "\n",
    "// 注册全局 packed function\n",
    "TVM_REGISTER_GLOBAL(\"myadd\").set_body(MyAdd);\n",
    "```\n",
    "````\n",
    "````{tab-item} Makefile\n",
    "```Makefile\n",
    "# Minimum Makefile for the extension package\n",
    "TVM_ROOT=$(shell cd TVM路径; pwd)\n",
    "PKG_CFLAGS = -std=c++17 -O2 -fPIC\\\n",
    "\t-I${TVM_ROOT}/include\\\n",
    "\t-I${TVM_ROOT}/3rdparty/dmlc-core/include\\\n",
    "\t-I${TVM_ROOT}/3rdparty/dlpack/include\\\n",
    "\t-DDMLC_USE_LOGGING_LIBRARY=\\<tvm/runtime/logging.h\\>\n",
    "\n",
    "\n",
    "PKG_LDFLAGS =-L${TVM_ROOT}/build\n",
    "UNAME_S := $(shell uname -s)\n",
    "\n",
    "ifeq ($(UNAME_S), Darwin)\n",
    "\tPKG_LDFLAGS += -undefined dynamic_lookup\n",
    "endif\n",
    "\n",
    "lib/libtvm_ext.so: src/tvm_ext.cc\n",
    "\t@mkdir -p $(@D)\n",
    "\t$(CXX) $(PKG_CFLAGS) -shared -o $@ $^ $(PKG_LDFLAGS)\n",
    "```\n",
    "````\n",
    "`````\n",
    "\n",
    "执行 `make`，输出动态库到 `lib/libtvm_ext.so`，接着，Python 代码添加如下内容，便可直接调用 C++ 接口："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import ctypes\n",
    "\n",
    "def load_lib():\n",
    "    \"\"\"加载库，函数将被注册到 TVM\"\"\"\n",
    "    curr_dir = Path(\"tests\").resolve()\n",
    "    # 作为全局加载，这样全局 extern symbol 对其他 dll 是可见的。\n",
    "    curr_path = str(curr_dir/\"lib/libtvm_ext.so\")\n",
    "    lib = ctypes.CDLL(curr_path, ctypes.RTLD_GLOBAL)\n",
    "    return lib\n",
    "\n",
    "\n",
    "_LIB = load_lib()\n",
    "\n",
    "myadd = tvm.get_global_func(\"myadd\")\n",
    "myadd(4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "{class}`~tvm.runtime.packed_func.PackedFunc` 也可以作为参数传递。\n",
    "\n",
    "在 C++ 端定义：\n",
    "\n",
    "```c++\n",
    "TVM_REGISTER_GLOBAL(\"callhello\")\n",
    ".set_body([](TVMArgs args, TVMRetValue* rv) {\n",
    "  PackedFunc f = args[0];\n",
    "  f(\"hello world\");\n",
    "});\n",
    "```\n",
    "\n",
    "python 端可以："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello world\n"
     ]
    }
   ],
   "source": [
    "def f(msg):\n",
    "  print(msg)\n",
    "\n",
    "\n",
    "callhello = tvm.get_global_func(\"callhello\")\n",
    "callhello(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C++ 调用 Python API\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `convert` 函数\n",
    "\n",
    "\n",
    "{func}`~tvm.runtime.object_generic.convert` 将给定的 `value` 转换为 TVM 对象。\n",
    "\n",
    "比如，列表："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.ir.container.Array"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tvm.runtime.convert([1, 2, 3])\n",
    "assert len(a) == 3\n",
    "assert a[-1].value == 3\n",
    "a_slice = a[-3:-1]\n",
    "assert (a_slice[0].value, a_slice[1].value) == (1, 2)\n",
    "type(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以序列化为 JSON："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_str = tvm.ir.save_json(a)\n",
    "# 加载\n",
    "a_loaded = tvm.ir.load_json(json_str)\n",
    "type(json_str)\n",
    "tvm.ir.assert_structural_equal(a_loaded, a, map_free_vars=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "字典："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tvm.ir.container.Map"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amap = tvm.runtime.convert({\"a\": 2, \"b\": 3})\n",
    "type(amap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其他："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[runtime.NDArray(0x42f0470), runtime.NDArray(0x42f0470)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tvm.nd.array([1, 2, 3])\n",
    "arr = tvm.runtime.convert([x, x])\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tvm.runtime.packed_func.PackedFunc at 0x7f389a84e280>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvm.runtime.convert(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hook Python 函数作为 Extern\n",
    "\n",
    "下面的例子注册了 python 函数到 TVM 运行时系统，并使用它来完成计算的一个阶段。这使得 TVM 更加灵活。例如，可以插入前端回调来检查中间结果，或者将定制代码与 TVM 混合使用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
      "To print formatted TVM script, please install the formatter 'Black':\n",
      "/media/pc/data/tmp/cache/conda/envs/tvmz/bin/python -m pip install \"black==22.3.0\" --upgrade --user\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(var_A: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle, var_C: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle):\n",
       "    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "    A <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_A, (<span style=\"color: #008000\">10</span>,), offset_factor<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>)\n",
       "    C <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>match_buffer(var_C, (<span style=\"color: #008000\">10</span>,), offset_factor<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>)\n",
       "    <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;C&quot;</span>):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(A[<span style=\"color: #008000\">0</span>:<span style=\"color: #008000\">10</span>])\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(C[<span style=\"color: #008000\">0</span>:<span style=\"color: #008000\">10</span>])\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_packed(<span style=\"color: #BA2121\">&quot;tvm.contrib.my_tvm_addone&quot;</span>, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>tvm_stack_make_array(A<span style=\"color: #AA22FF; font-weight: bold\">.</span>data, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>tvm_stack_make_shape(<span style=\"color: #008000\">10</span>), <span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">1</span>, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>), A<span style=\"color: #AA22FF; font-weight: bold\">.</span>elem_offset), T<span style=\"color: #AA22FF; font-weight: bold\">.</span>tvm_stack_make_array(C<span style=\"color: #AA22FF; font-weight: bold\">.</span>data, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>tvm_stack_make_shape(<span style=\"color: #008000\">10</span>), <span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">1</span>, T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>), C<span style=\"color: #AA22FF; font-weight: bold\">.</span>elem_offset))\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my_tvm_addone signatures: <class 'tvm.runtime.ndarray.NDArray'>, <class 'tvm.runtime.ndarray.NDArray'>\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tvm import te\n",
    "\n",
    "@tvm.register_func(\"tvm.contrib.my_tvm_addone\")\n",
    "def my_tvm_addone(x, y):\n",
    "    print(f\"my_tvm_addone signatures: {type(x)}, {type(y)}\")\n",
    "    tvm.nd.array(x.numpy() + 1).copyto(y)\n",
    "\n",
    "\n",
    "n = 10\n",
    "dev = tvm.cpu(0)\n",
    "A = te.placeholder((n,), name=\"A\")\n",
    "B = te.extern(\n",
    "    A.shape,\n",
    "    [A],\n",
    "    lambda ins, outs: tvm.tir.call_packed(\"tvm.contrib.my_tvm_addone\",\n",
    "                                          ins[0], outs[0]),\n",
    "    name=\"C\",\n",
    ")\n",
    "te_func = te.create_prim_func([A, B])\n",
    "te_func.show()\n",
    "f = tvm.build(te_func, \"llvm\")\n",
    "a = tvm.nd.array(np.random.uniform(size=(n,)).astype(A.dtype), dev)\n",
    "b = tvm.nd.array(np.random.uniform(size=(n,)).astype(B.dtype), dev)\n",
    "f(a, b)\n",
    "np.testing.assert_allclose(b.numpy(), a.numpy() + 1, rtol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch 调用 TVM 接口\n",
    "\n",
    "参考：[在环境中集成现有运行库](https://mlc.ai/zh/chapter_end_to_end/index.html#id10)\n",
    "\n",
    "DLPack 数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.dlpack\n",
    "from tvm.contrib.dlpack import to_pytorch_func\n",
    "\n",
    "a = np.random.randn(1337)\n",
    "tvm_a = tvm.nd.array(a)\n",
    "np.testing.assert_equal(tvm.nd.from_dlpack(tvm_a.to_dlpack()).numpy(), a)\n",
    "x = torch.rand(56, 56)\n",
    "tvm_x = tvm.nd.from_dlpack(torch.utils.dlpack.to_dlpack(x))\n",
    "y = tvm.nd.from_dlpack(tvm_x)\n",
    "np.testing.assert_equal(x.numpy(), tvm_x.numpy())\n",
    "np.testing.assert_equal(y.numpy(), tvm_x.numpy())\n",
    "np.testing.assert_equal(\n",
    "    torch.utils.dlpack.from_dlpack(y.to_dlpack()).numpy(), tvm_x.numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pc/data/lxw/ai/tvm/xinetzone/__pypackages__/3.10/lib/tvm/script/highlight.py:117: UserWarning: No module named 'black'\n",
      "To print formatted TVM script, please install the formatter 'Black':\n",
      "/media/pc/data/tmp/cache/conda/envs/tvmz/bin/python -m pip install \"black==22.3.0\" --upgrade --user\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "\n",
       "<span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(X: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">137</span>, <span style=\"color: #008000\">137</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), Y: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">137</span>, <span style=\"color: #008000\">137</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>), compute: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">137</span>, <span style=\"color: #008000\">137</span>), <span style=\"color: #BA2121\">&quot;float32&quot;</span>)):\n",
       "    T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr({<span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>)})\n",
       "    <span style=\"color: #007979; font-style: italic\"># with T.block(&quot;root&quot;):</span>\n",
       "    <span style=\"color: #008000; font-weight: bold\">for</span> i, j, k <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">137</span>, <span style=\"color: #008000\">137</span>, <span style=\"color: #008000\">137</span>):\n",
       "        <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>block(<span style=\"color: #BA2121\">&quot;compute&quot;</span>):\n",
       "            v_i, v_j, v_k <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>axis<span style=\"color: #AA22FF; font-weight: bold\">.</span>remap(<span style=\"color: #BA2121\">&quot;SSR&quot;</span>, [i, j, k])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>reads(X[v_i, v_k], Y[v_k, v_j])\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>writes(compute[v_i, v_j])\n",
       "            <span style=\"color: #008000; font-weight: bold\">with</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>init():\n",
       "                compute[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>float32(<span style=\"color: #008000\">0</span>)\n",
       "            compute[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">=</span> compute[v_i, v_j] <span style=\"color: #AA22FF; font-weight: bold\">+</span> X[v_i, v_k] <span style=\"color: #AA22FF; font-weight: bold\">*</span> Y[v_k, v_j]\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tvm_func(n):\n",
    "    XX = te.placeholder((n, n), name=\"X\")\n",
    "    YY = te.placeholder((n, n), name=\"Y\")\n",
    "    k = te.reduce_axis((0, n), name=\"k\")\n",
    "    ZZ = te.compute((n, n), lambda i, j: te.sum(XX[i, k] * YY[k, j], axis=k))\n",
    "    return te.create_prim_func([XX, YY, ZZ])\n",
    "\n",
    "te_func = tvm_func(tvm.runtime.convert(137))\n",
    "te_func.show()\n",
    "f = tvm.build(te_func, name=\"f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = torch.rand(137, 137)\n",
    "yy = torch.rand(137, 137)\n",
    "zz = xx.mm(yy)\n",
    "zz2 = torch.empty(137, 137)\n",
    "f_pytorch = to_pytorch_func(f)\n",
    "f_pytorch(xx, yy, zz2)\n",
    "np.testing.assert_allclose(zz.numpy(), zz2.numpy(), rtol=1e-4, atol=1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d0d307675f12182d62ca143bf4e5db321e57c24ab1edf40ce60a9751b29adda0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
