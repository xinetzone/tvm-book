{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 编译外部库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/media/pc/data/lxw/ai/tvm\n"
     ]
    }
   ],
   "source": [
    "import set_env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.relay import ExprMutator\n",
    "from tvm.relay.op.annotation import compiler_begin, compiler_end\n",
    "from tvm.relay.backend.runtime import Runtime\n",
    "from tvm.relay.backend import te_compiler\n",
    "from tvm.contrib.utils import tempdir\n",
    "\n",
    "def update_lib(lib, source_dir=\"/media/pc/data/lxw/ai/tvm\"):\n",
    "    kwargs = {\n",
    "        \"options\" : [\n",
    "            \"-O2\", \"-std=c++17\", \n",
    "            f\"-I{source_dir}/src/runtime/contrib\", \n",
    "            f\"-I{source_dir}/include\",\n",
    "            f\"-I{source_dir}/3rdparty/dlpack/include\",\n",
    "            f\"-I{source_dir}/3rdparty/dmlc-core/include\",\n",
    "        ]\n",
    "    }\n",
    "    tmp_path = tempdir()\n",
    "    lib_name = \"lib.so\"\n",
    "    lib_path = tmp_path.relpath(lib_name)\n",
    "    lib.export_library(lib_path, fcompile=False, **kwargs)\n",
    "    lib = tvm.runtime.load_module(lib_path)\n",
    "    return lib\n",
    "\n",
    "def check_result(\n",
    "    mod,\n",
    "    map_inputs,\n",
    "    out_shape,\n",
    "    result,\n",
    "    tol=1e-5,\n",
    "    target=\"llvm\",\n",
    "    device=tvm.cpu(),\n",
    "    params=None,\n",
    "    runtime=Runtime(\"cpp\"),\n",
    "):\n",
    "    def check_vm_result():\n",
    "        te_compiler.get().clear()\n",
    "        with tvm.transform.PassContext(opt_level=3):\n",
    "            exe = relay.vm.compile(mod, target=target, params=params)\n",
    "        code, lib = exe.save()\n",
    "        lib = update_lib(lib)\n",
    "        exe = tvm.runtime.vm.Executable.load_exec(code, lib)\n",
    "        vm = tvm.runtime.vm.VirtualMachine(exe, device)\n",
    "        outs = vm.run(**map_inputs)\n",
    "        outs = outs if isinstance(outs, tvm.runtime.container.ADT) else [outs]\n",
    "        results = result if isinstance(result, list) else [result]\n",
    "        for out, ref in zip(outs, results):\n",
    "            np.testing.assert_allclose(out.numpy(), ref, rtol=tol, atol=tol)\n",
    "    check_vm_result()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以 `z = x + y` 为例子说明："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32], <span style=\"color: #AA22FF; font-weight: bold\">%</span>y: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32]) {\n",
       "  add(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x, <span style=\"color: #AA22FF; font-weight: bold\">%</span>y)\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = relay.var(\"x\", shape=(8, 8))\n",
    "y = relay.var(\"y\", shape=(8, 8))\n",
    "z = x + y\n",
    "f = relay.Function([x, y], z)\n",
    "mod = tvm.IRModule()\n",
    "mod[\"main\"] = f\n",
    "mod.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编写简单的注解函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@relay.transform.function_pass(opt_level=0)\n",
    "class MyAnnotator:\n",
    "    def transform_function(self, func, mod, dev):\n",
    "        class Annotator(ExprMutator):\n",
    "            def visit_call(self, call):\n",
    "                new_args = []\n",
    "                for arg in call.args:\n",
    "                    ann = compiler_begin(self.visit(arg), \"ccompiler\")\n",
    "                    new_args.append(ann)\n",
    "                new_call = relay.Call(call.op, new_args)\n",
    "                return compiler_end(new_call, \"ccompiler\")\n",
    "\n",
    "        return Annotator().visit(func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将 `+` 的输入输入和输出进行注解："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>y: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] {\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> annotation<span style=\"color: #AA22FF; font-weight: bold\">.</span>compiler_begin(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x, compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> annotation<span style=\"color: #AA22FF; font-weight: bold\">.</span>compiler_begin(<span style=\"color: #AA22FF; font-weight: bold\">%</span>y, compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> add(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  annotation<span style=\"color: #AA22FF; font-weight: bold\">.</span>compiler_end(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">2</span>, compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod = MyAnnotator()(mod)\n",
    "mod.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 {class}`~tvm.relay.transform.PartitionGraph` 分割计算图："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>y: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] {\n",
       "  <span style=\"color: #AA22FF\">@tvmgen_default_ccompiler_main_0</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x, <span style=\"color: #AA22FF; font-weight: bold\">%</span>y) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@tvmgen_default_ccompiler_main_0</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_0_i0: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_0_i1: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, Compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>, Primitive<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, Inline<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, global_symbol<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;tvmgen_default_ccompiler_main_0&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] {\n",
       "  add(<span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_0_i0, <span style=\"color: #AA22FF; font-weight: bold\">%</span>ccompiler_0_i1) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod = relay.transform.PartitionGraph()(mod)\n",
    "mod.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证结果一致性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:56:02] /media/pc/data/lxw/ai/tvm/src/relay/backend/vm/compiler.cc:1199: All lowered functions have been build by BYOC -- generating an empty TVM module\n"
     ]
    }
   ],
   "source": [
    "x_data = np.random.rand(8, 8).astype(\"float32\")\n",
    "y_data = np.random.rand(8, 8).astype(\"float32\")\n",
    "check_result(mod, {\"x\": x_data, \"y\": y_data}, (8, 8), x_data + y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 注解白名单"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 利用 pass 管理器编写简单的注释器白名单\n",
    "@relay.transform.function_pass(opt_level=0)\n",
    "class AllowedListAnnotator:\n",
    "    def __init__(self, op_list, compiler):\n",
    "        assert isinstance(op_list, (list, tuple, set))\n",
    "        self.op_list = op_list\n",
    "        self.compiler = compiler\n",
    "\n",
    "    def transform_function(self, func, mod, dev):\n",
    "\n",
    "        annotator = self\n",
    "\n",
    "        class Annotator(tvm.relay.ExprMutator):\n",
    "            def visit_call(self, call):\n",
    "                op_name = call.op.name\n",
    "                if op_name in annotator.op_list:\n",
    "                    new_args = []\n",
    "                    for arg in call.args:\n",
    "                        ann = compiler_begin(super().visit(arg), annotator.compiler)\n",
    "                        new_args.append(ann)\n",
    "                    new_call = relay.Call(call.op, new_args, call.attrs, call.type_args)\n",
    "                    return compiler_end(new_call, annotator.compiler)\n",
    "                else:\n",
    "                    return super().visit_call(call)\n",
    "\n",
    "        return Annotator().visit(func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32], <span style=\"color: #AA22FF; font-weight: bold\">%</span>y: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32]) {\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> add(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x, <span style=\"color: #AA22FF; font-weight: bold\">%</span>y);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> log(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span>);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> exp(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span>);\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">3</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> (<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">2</span>);\n",
       "  concatenate(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">3</span>)\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = relay.var(\"x\", shape=(8, 8))\n",
    "y = relay.var(\"y\", shape=(8, 8))\n",
    "add = x + y\n",
    "log = relay.log(add)\n",
    "exp = relay.exp(add)\n",
    "concat = relay.concatenate([log, exp], axis=0)\n",
    "f = relay.Function([x, y], concat)\n",
    "mod = tvm.IRModule()\n",
    "mod[\"main\"] = f\n",
    "mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected():\n",
    "    mod = tvm.IRModule()\n",
    "    x = relay.var(\"x\", shape=(8, 8))\n",
    "    y = relay.var(\"y\", shape=(8, 8))\n",
    "    x0 = relay.var(\"x0\", shape=(8, 8))\n",
    "    y0 = relay.var(\"y0\", shape=(8, 8))\n",
    "    add = x0 + y0\n",
    "    # Function that uses C compiler\n",
    "    func = relay.Function([x0, y0], add)\n",
    "    func = set_func_attr(func, \"ccompiler\", \"tvmgen_default_ccompiler_main_0\")\n",
    "    glb_0 = relay.GlobalVar(\"tvmgen_default_ccompiler_main_0\")\n",
    "    mod[glb_0] = func\n",
    "    add_call = relay.Call(glb_0, [x, y])\n",
    "    # Function that uses default compiler. Ops are fused in this function.\n",
    "    p0 = relay.var(\"p0\", shape=(8, 8))\n",
    "    log = relay.log(p0)\n",
    "    exp = relay.exp(p0)\n",
    "    concat = relay.concatenate([log, exp], axis=0)\n",
    "    fused_func = relay.Function([p0], concat)\n",
    "    fused_func = fused_func.with_attr(\"Primitive\", tvm.tir.IntImm(\"int32\", 1))\n",
    "    fused_call = relay.Call(fused_func, [add_call])\n",
    "    main = relay.Function([x, y], fused_call)\n",
    "    mod[\"main\"] = main\n",
    "    mod = transform.InferType()(mod)\n",
    "    return mod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_func_attr(func, compile_name, symbol_name):\n",
    "    func = func.with_attr(\"Primitive\", tvm.tir.IntImm(\"int32\", 1))\n",
    "    func = func.with_attr(\"Inline\", tvm.tir.IntImm(\"int32\", 1))\n",
    "    func = func.with_attr(\"Compiler\", compile_name)\n",
    "    func = func.with_attr(\"global_symbol\", symbol_name)\n",
    "    return func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expected():\n",
    "    mod = tvm.IRModule()\n",
    "    x = relay.var(\"x\", shape=(8, 8))\n",
    "    y = relay.var(\"y\", shape=(8, 8))\n",
    "    x0 = relay.var(\"x0\", shape=(8, 8))\n",
    "    y0 = relay.var(\"y0\", shape=(8, 8))\n",
    "    add = x0 + y0\n",
    "    # Function that uses C compiler\n",
    "    func = relay.Function([x0, y0], add)\n",
    "    func = set_func_attr(func, \"ccompiler\", \"tvmgen_default_ccompiler_main_0\")\n",
    "    glb_0 = relay.GlobalVar(\"tvmgen_default_ccompiler_main_0\")\n",
    "    mod[glb_0] = func\n",
    "    add_call = relay.Call(glb_0, [x, y])\n",
    "    # Function that uses default compiler. Ops are fused in this function.\n",
    "    p0 = relay.var(\"p0\", shape=(8, 8))\n",
    "    log = relay.log(p0)\n",
    "    exp = relay.exp(p0)\n",
    "    concat = relay.concatenate([log, exp], axis=0)\n",
    "    fused_func = relay.Function([p0], concat)\n",
    "    fused_func = fused_func.with_attr(\"Primitive\", tvm.tir.IntImm(\"int32\", 1))\n",
    "    fused_call = relay.Call(fused_func, [add_call])\n",
    "    main = relay.Function([x, y], fused_call)\n",
    "    mod[\"main\"] = main\n",
    "    mod = relay.transform.InferType()(mod)\n",
    "    return mod\n",
    "\n",
    "x = relay.var(\"x\", shape=(8, 8))\n",
    "y = relay.var(\"y\", shape=(8, 8))\n",
    "add = x + y\n",
    "log = relay.log(add)\n",
    "exp = relay.exp(add)\n",
    "concat = relay.concatenate([log, exp], axis=0)\n",
    "f = relay.Function([x, y], concat)\n",
    "mod = tvm.IRModule()\n",
    "mod[\"main\"] = f\n",
    "mod = AllowedListAnnotator([\"add\", \"subtract\", \"multiply\"], \"ccompiler\")(mod)\n",
    "mod = relay.transform.PartitionGraph()(mod)\n",
    "fused_mod = relay.transform.FuseOps(2)(mod)\n",
    "expected_mod = expected()\n",
    "assert tvm.ir.structural_equal(fused_mod, expected_mod, map_free_vars=True)\n",
    "\n",
    "x_data = np.random.rand(8, 8).astype(\"float32\")\n",
    "y_data = np.random.rand(8, 8).astype(\"float32\")\n",
    "np_add = x_data + y_data\n",
    "res = np.concatenate([np.log(np_add), np.exp(np_add)])\n",
    "check_result(mod, {\"x\": x_data, \"y\": y_data}, (16, 8), res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>y: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">8</span>), float32] {\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">3</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> <span style=\"color: #AA22FF\">@tvmgen_default_ccompiler_main_0</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x, <span style=\"color: #AA22FF; font-weight: bold\">%</span>y) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">4</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> fn (<span style=\"color: #AA22FF; font-weight: bold\">%</span>p0: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, Primitive<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">8</span>), float32] {\n",
       "    <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> log(<span style=\"color: #AA22FF; font-weight: bold\">%</span>p0) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "    <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> exp(<span style=\"color: #AA22FF; font-weight: bold\">%</span>p0) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "    <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> (<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>(Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32], Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32]) <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "    concatenate(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">2</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "  } <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>fn (Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32]) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">4</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">3</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@tvmgen_default_ccompiler_main_0</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x0: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>y0: Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, Primitive<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, Inline<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, Compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;ccompiler&quot;</span>, global_symbol<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;tvmgen_default_ccompiler_main_0&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] {\n",
       "  add(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x0, <span style=\"color: #AA22FF; font-weight: bold\">%</span>y0) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">8</span>, <span style=\"color: #008000\">8</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "expected_mod.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他外部编译器支持"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_extern_compiler_sanitized_ops():\n",
    "    def expected():\n",
    "        mod = tvm.IRModule()\n",
    "        x = relay.var(\"x\", shape=(8, 8))\n",
    "        y = relay.var(\"y\", shape=(8, 8))\n",
    "        x0 = relay.var(\"x0\", shape=(8, 8))\n",
    "        y0 = relay.var(\"y0\", shape=(8, 8))\n",
    "        add = x0 + y0\n",
    "        # Function that uses C compiler\n",
    "        func = relay.Function([x0, y0], add)\n",
    "        func = set_func_attr(func, \"unsanitary-name++\", \"tvmgen_default_unsanitary_name___main_0\")\n",
    "        glb_0 = relay.GlobalVar(\"tvmgen_default_unsanitary_name___main_0\")\n",
    "        mod[glb_0] = func\n",
    "        add_call = relay.Call(glb_0, [x, y])\n",
    "        # Function that uses default compiler. Ops are fused in this function.\n",
    "        p0 = relay.var(\"p0\", shape=(8, 8))\n",
    "        log = relay.log(p0)\n",
    "        exp = relay.exp(p0)\n",
    "        concat = relay.concatenate([log, exp], axis=0)\n",
    "        fused_func = relay.Function([p0], concat)\n",
    "        fused_func = fused_func.with_attr(\"Primitive\", tvm.tir.IntImm(\"int32\", 1))\n",
    "        fused_call = relay.Call(fused_func, [add_call])\n",
    "        main = relay.Function([x, y], fused_call)\n",
    "        mod[\"main\"] = main\n",
    "        mod = transform.InferType()(mod)\n",
    "        return mod\n",
    "\n",
    "    x = relay.var(\"x\", shape=(8, 8))\n",
    "    y = relay.var(\"y\", shape=(8, 8))\n",
    "    add = x + y\n",
    "    log = relay.log(add)\n",
    "    exp = relay.exp(add)\n",
    "    concat = relay.concatenate([log, exp], axis=0)\n",
    "    f = relay.Function([x, y], concat)\n",
    "    mod = tvm.IRModule()\n",
    "    mod[\"main\"] = f\n",
    "    mod = AllowedListAnnotator([\"add\", \"subtract\", \"multiply\"], \"unsanitary-name++\")(mod)\n",
    "    mod = transform.PartitionGraph()(mod)\n",
    "    fused_mod = transform.FuseOps(2)(mod)\n",
    "    expected_mod = expected()\n",
    "    assert tvm.ir.structural_equal(fused_mod, expected_mod, map_free_vars=True)\n",
    "\n",
    "\n",
    "def test_extern_ccompiler_multiple_functions():\n",
    "    def expected():\n",
    "        mod = tvm.IRModule()\n",
    "        x = relay.var(\"x\", shape=(8, 8))\n",
    "        y = relay.var(\"y\", shape=(8, 8))\n",
    "        x0 = relay.var(\"x0\", shape=(8, 8))\n",
    "        y0 = relay.var(\"y0\", shape=(8, 8))\n",
    "        add = x0 + y0\n",
    "        # Function that uses C compiler\n",
    "        func = relay.Function([x0, y0], add)\n",
    "        func = set_func_attr(func, \"ccompiler\", \"tvmgen_default_ccompiler_main_0\")\n",
    "        glb_0 = relay.GlobalVar(\"tvmgen_default_ccompiler_main_0\")\n",
    "        mod[glb_0] = func\n",
    "        add_call = relay.Call(glb_0, [x, y])\n",
    "        # Function that uses default compiler. Ops are fused in this function.\n",
    "        p0 = relay.var(\"p0\", shape=(8, 8))\n",
    "        log = relay.log(p0)\n",
    "        exp = relay.exp(p0)\n",
    "        concat = relay.concatenate([log, exp], axis=0)\n",
    "        fused_func = relay.Function([p0], concat)\n",
    "        fused_func = fused_func.with_attr(\"Primitive\", tvm.tir.IntImm(\"int32\", 1))\n",
    "        fused_call = relay.Call(fused_func, [add_call])\n",
    "        main = relay.Function([x, y], fused_call)\n",
    "        mod[\"main\"] = main\n",
    "        # define the second one\n",
    "        a = relay.var(\"a\", shape=(16, 16))\n",
    "        b = relay.var(\"b\", shape=(16, 16))\n",
    "        a0 = relay.var(\"a0\", shape=(16, 16))\n",
    "        b0 = relay.var(\"b0\", shape=(16, 16))\n",
    "        add = a0 + b0\n",
    "        # Function that uses C compiler\n",
    "        func = relay.Function([a0, b0], add)\n",
    "        func = set_func_attr(func, \"ccompiler\", \"tvmgen_default_ccompiler_subfunction_0\")\n",
    "        glb_0 = relay.GlobalVar(\"tvmgen_default_ccompiler_subfunction_0\")\n",
    "        mod[glb_0] = func\n",
    "        add_call = relay.Call(glb_0, [a, b])\n",
    "        # Function that uses default compiler. Ops are fused in this function.\n",
    "        p0 = relay.var(\"p0\", shape=(16, 16))\n",
    "        log = relay.log(p0)\n",
    "        exp = relay.exp(p0)\n",
    "        concat = relay.concatenate([log, exp], axis=0)\n",
    "        fused_func = relay.Function([p0], concat)\n",
    "        fused_func = fused_func.with_attr(\"Primitive\", tvm.tir.IntImm(\"int32\", 1))\n",
    "        fused_call = relay.Call(fused_func, [add_call])\n",
    "        sunfunction = relay.Function([a, b], fused_call)\n",
    "        mod[\"subfunction\"] = sunfunction\n",
    "        mod = transform.InferType()(mod)\n",
    "        return mod\n",
    "\n",
    "    x = relay.var(\"x\", shape=(8, 8))\n",
    "    y = relay.var(\"y\", shape=(8, 8))\n",
    "    add = x + y\n",
    "    log = relay.log(add)\n",
    "    exp = relay.exp(add)\n",
    "    concat = relay.concatenate([log, exp], axis=0)\n",
    "    f = relay.Function([x, y], concat)\n",
    "    mod = tvm.IRModule()\n",
    "    mod[\"main\"] = f\n",
    "    # define second function\n",
    "    a = relay.var(\"a\", shape=(16, 16))\n",
    "    b = relay.var(\"b\", shape=(16, 16))\n",
    "    add = a + b\n",
    "    log = relay.log(add)\n",
    "    exp = relay.exp(add)\n",
    "    concat = relay.concatenate([log, exp], axis=0)\n",
    "    f2 = relay.Function([a, b], concat)\n",
    "    mod[\"subfunction\"] = f2\n",
    "    mod = AllowedListAnnotator([\"add\", \"subtract\", \"multiply\"], \"ccompiler\")(mod)\n",
    "    mod = transform.PartitionGraph()(mod)\n",
    "\n",
    "    fused_mod = transform.FuseOps(2)(mod)\n",
    "    expected_mod = expected()\n",
    "    assert tvm.ir.structural_equal(fused_mod, expected_mod, map_free_vars=True)\n",
    "\n",
    "    x_data = np.random.rand(8, 8).astype(\"float32\")\n",
    "    y_data = np.random.rand(8, 8).astype(\"float32\")\n",
    "    np_add = x_data + y_data\n",
    "    res = np.concatenate([np.log(np_add), np.exp(np_add)])\n",
    "    check_result(mod, {\"x\": x_data, \"y\": y_data}, (16, 8), res)\n",
    "\n",
    "\n",
    "def test_extern_ccompiler():\n",
    "    x = relay.var(\"x\", shape=(2, 2))\n",
    "    y = relay.var(\"y\", shape=(2, 2))\n",
    "    z = x + x\n",
    "    p = y * y\n",
    "    f = relay.Function([x, y], p - z)\n",
    "    x_data = np.random.rand(2, 2).astype(\"float32\")\n",
    "    y_data = np.random.rand(2, 2).astype(\"float32\")\n",
    "    mod = tvm.IRModule()\n",
    "    mod[\"main\"] = f\n",
    "    mod = AllowedListAnnotator([\"add\", \"subtract\", \"multiply\"], \"ccompiler\")(mod)\n",
    "    mod = transform.PartitionGraph()(mod)\n",
    "\n",
    "    check_result(mod, {\"x\": x_data, \"y\": y_data}, (2, 2), (y_data * y_data) - (x_data + x_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WholeGraphAnnotator(ExprMutator):\n",
    "    \"\"\"\n",
    "    An annotator that creates a compiler for an entire graph.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, compiler):\n",
    "        super().__init__()\n",
    "        self.compiler = compiler\n",
    "        self.last_call = True\n",
    "\n",
    "    def visit_call(self, call):\n",
    "        curr_last = self.last_call\n",
    "        self.last_call = False\n",
    "\n",
    "        params = []\n",
    "        for arg in call.args:\n",
    "            param = super().visit(arg)\n",
    "            if isinstance(param, relay.expr.Var):\n",
    "                param = compiler_begin(param, self.compiler)\n",
    "            params.append(param)\n",
    "\n",
    "        new_call = relay.Call(call.op, params, call.attrs)\n",
    "        if curr_last:\n",
    "            new_call = compiler_end(new_call, self.compiler)\n",
    "        return new_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = \"float32\"\n",
    "ishape = (1, 32, 14, 14)\n",
    "w1shape = (32, 1, 3, 3)\n",
    "def get_func():\n",
    "    data = relay.var(\"data\", shape=(ishape), dtype=dtype)\n",
    "    weight1 = relay.var(\"weight1\", shape=(w1shape), dtype=dtype)\n",
    "    depthwise_conv2d_1 = relay.nn.conv2d(\n",
    "        data, weight1, kernel_size=(3, 3), padding=(1, 1), groups=32\n",
    "    )\n",
    "    depthwise_conv2d_2 = relay.nn.conv2d(\n",
    "        depthwise_conv2d_1, weight1, kernel_size=(3, 3), padding=(1, 1), groups=32\n",
    "    )\n",
    "    out = relay.add(depthwise_conv2d_1, depthwise_conv2d_2)\n",
    "\n",
    "    return relay.Function([data, weight1], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>data: Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>weight1: Tensor[(<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), float32] {\n",
       "  <span style=\"color: #AA22FF\">@tvmgen_default_dnnl_main_0</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>data, <span style=\"color: #AA22FF; font-weight: bold\">%</span>weight1) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "\n",
       "<span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@tvmgen_default_dnnl_main_0</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>dnnl_0_i0: Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>dnnl_0_i1: Tensor[(<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, Compiler<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;dnnl&quot;</span>, Primitive<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, Inline<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, global_symbol<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;tvmgen_default_dnnl_main_0&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), float32] {\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>conv2d(<span style=\"color: #AA22FF; font-weight: bold\">%</span>dnnl_0_i0, <span style=\"color: #AA22FF; font-weight: bold\">%</span>dnnl_0_i1, padding<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">32</span>, kernel_size<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>]) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>conv2d(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>dnnl_0_i1, padding<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">1</span>], groups<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">32</span>, kernel_size<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>]) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  add(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">32</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "func = get_func()\n",
    "mod = tvm.IRModule()\n",
    "mod[\"main\"] = WholeGraphAnnotator(\"dnnl\").visit(get_func())\n",
    "mod = relay.transform.PartitionGraph()(mod)\n",
    "mod = relay.transform.InferType()(mod)\n",
    "mod.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
