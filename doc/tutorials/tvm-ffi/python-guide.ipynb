{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a433be42",
   "metadata": {},
   "source": [
    "# Python 指南\n",
    "\n",
    "参考：[Python 指南](https://tvm.apache.org/ffi/guides/python_guide.html#)\n",
    "\n",
    "在高层次上，tvm_ffi Python 包提供了一流的 Python 支持\n",
    "\n",
    "- 表示 TVM FFI 中值的 Python 类 任何 ABI。\n",
    "- 调用 TVM FFI ABI 兼容函数的机制。\n",
    "- Python 值和 tvm_ffi 值之间的转换。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01752854",
   "metadata": {},
   "source": [
    "## Tensor\n",
    "\n",
    "tvm_ffi 提供了托管的 DLPack 兼容 Tensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dad751c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# 保证 jupyter 中 nvcc 可以被找到并添加 CUDA 头文件路径\n",
    "os.environ['PATH'] += ':/usr/local/cuda/bin'\n",
    "# 添加 CUDA 头文件路径到 CPATH 环境变量，确保编译器能找到 cuda_runtime_api.h\n",
    "if 'CPATH' in os.environ:\n",
    "    os.environ['CPATH'] += ':/usr/local/cuda/include'\n",
    "else:\n",
    "    os.environ['CPATH'] = '/usr/local/cuda/include'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1423fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tvm_ffi\n",
    "\n",
    "# 演示 NumPy 和 TVM FFI 之间的 DLPack 转换\n",
    "np_data = np.array([1, 2, 3, 4], dtype=np.float32)\n",
    "tvm_array = tvm_ffi.from_dlpack(np_data)\n",
    "# 转换回 NumPy\n",
    "np_result = np.from_dlpack(tvm_array)\n",
    "# 验证结果是否与原始数据相等\n",
    "np.testing.assert_array_equal(np_result, np_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6936d99d",
   "metadata": {},
   "source": [
    "在大多数情况下，不必显式创建张量。Python 接口可以接受 {class}`torch.Tensor` 和 {class}`numpy.ndarray` 对象并自动将它们转换为 {class}`tvm_ffi.Tensor`。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e84b82",
   "metadata": {},
   "source": [
    "## 函数和回调"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f166b2b3",
   "metadata": {},
   "source": [
    "{class}`tvm_ffi.Function` 为 C++ 中的 `ffi::Function` 提供了 Python 接口。您可以通过 {func}`tvm_ffi.get_global_func` 检索全局注册的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd064fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm_ffi\n",
    "\n",
    "# testing.echo 是在 C++ 中定义和注册的函数，\n",
    "# 其实现是简单的 lambda 表达式 [](ffi::Any x) { return x; }，该函数接收参数并原样返回。\n",
    "fecho = tvm_ffi.get_global_func(\"testing.echo\")\n",
    "assert fecho(1) == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c2e93c",
   "metadata": {},
   "source": [
    "可以将 Python 函数作为参数传递给另一个 FFI 函数作为回调。在后台，调用 {func}`tvm_ffi.convert` 将 Python 函数转换为 {class}`tvm_ffi.Function`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5dc8bc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm_ffi\n",
    "\n",
    "# testing.apply 是在 C++ 中注册的函数\n",
    "# [](ffi::Function f, ffi::Any val) { return f(x); }\n",
    "fapply = tvm_ffi.get_global_func(\"testing.apply\")\n",
    "# 调用 fapply 并传入 lambda 回调函数作为 f\n",
    "assert fapply(lambda x: x + 1, 1) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b02154d",
   "metadata": {},
   "source": [
    "这是非常强大的模式，允许将 Python 回调注入 C++ 代码中。您还可以将 Python 回调注册为全局函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c05add00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm_ffi\n",
    "\n",
    "@tvm_ffi.register_global_func(\"example.add_one\")\n",
    "def add_one(a):\n",
    "    return a + 1\n",
    "\n",
    "assert tvm_ffi.get_global_func(\"example.add_one\")(1) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a31453",
   "metadata": {},
   "source": [
    "## 容器类型"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f71bfb6",
   "metadata": {},
   "source": [
    "当 FFI 函数从列表/元组中获取参数时，它们将被转换为 {class}`tvm_ffi.Array`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6599f03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm_ffi\n",
    "\n",
    "# Lists 变成 Arrays\n",
    "arr = tvm_ffi.convert([1, 2, 3, 4])\n",
    "assert isinstance(arr, tvm_ffi.Array)\n",
    "assert len(arr) == 4\n",
    "assert arr[0] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92dce707",
   "metadata": {},
   "source": [
    "字典将转换为 {class}`tvm_ffi.Map`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00481b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm_ffi\n",
    "\n",
    "map_obj = tvm_ffi.convert({\"a\": 1, \"b\": 2})\n",
    "assert isinstance(map_obj, tvm_ffi.Map)\n",
    "assert len(map_obj) == 2\n",
    "assert map_obj[\"a\"] == 1\n",
    "assert map_obj[\"b\"] == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f553a261",
   "metadata": {},
   "source": [
    "当从 FFI 函数返回容器值时，它们也分别存储在这些类型中。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32345dc0",
   "metadata": {},
   "source": [
    "## 内联模块\n",
    "\n",
    "还可以加载内联模块 ，其中 C++/CUDA 代码直接嵌入到 Python 脚本中，然后动态编译。例如，可以定义简单的内核，该内核为数组的每个元素加一，如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fd9953",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tvm_ffi import Module\n",
    "import tvm_ffi.cpp\n",
    "\n",
    "# define the cpp source code\n",
    "cpp_source = '''\n",
    "     void add_one_cpu(tvm::ffi::TensorView x, tvm::ffi::TensorView y) {\n",
    "       // 库函数的实现\n",
    "       TVM_FFI_ICHECK(x->ndim == 1) << \"x 必须是一维张量\"; \n",
    "       DLDataType f32_dtype{kDLFloat, 32, 1};\n",
    "       TVM_FFI_ICHECK(x->dtype == f32_dtype) << \"x 必须是浮点张量\";\n",
    "       TVM_FFI_ICHECK(y->ndim == 1) << \"y 必须是一维张量\";\n",
    "       TVM_FFI_ICHECK(y->dtype == f32_dtype) << \"y 必须是浮点张量\";\n",
    "       TVM_FFI_ICHECK(x->shape[0] == y->shape[0]) << \"x 和 y 必须具有相同的形状\";\n",
    "       for (int i = 0; i < x->shape[0]; ++i) {\n",
    "         static_cast<float*>(y->data)[i] = static_cast<float*>(x->data)[i] + 1;\n",
    "       }\n",
    "     }\n",
    "'''\n",
    "\n",
    "# 编译 C++ 源代码并加载模块\n",
    "mod: Module = tvm_ffi.cpp.load_inline(\n",
    "    name='hello', cpp_sources=cpp_source, functions='add_one_cpu'\n",
    ")\n",
    "\n",
    "# 使用加载模块中的函数执行运算\n",
    "x = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)\n",
    "y = torch.empty_like(x)\n",
    "mod.add_one_cpu(x, y)\n",
    "torch.testing.assert_close(x + 1, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7caea48",
   "metadata": {},
   "source": [
    "上面的代码使用 Python 脚本定义了 C++ 函数 add_one_cpu，动态编译它，然后加载编译后的 {class}`tvm_ffi.Module` 对象，通过 {func}`tvm_ffi.cpp.load_inline` 进行。然后，您可以像往常一样从模块调用函数 `add_one_cpu`。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856fd402",
   "metadata": {},
   "source": [
    "## 加载模块"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20ecf73",
   "metadata": {},
   "source": [
    "还可以通过 {func}`tvm_ffi.cpp.build_inline` 构建内联模块而无需直接加载。该函数会返回已构建的共享库，您可以随后使用 {func}`tvm_ffi.load_module` 来加载它。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ceb94f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the cpp source code and load the module\n",
    "lib_path: str = tvm_ffi.cpp.build_inline(\n",
    "    name='hello',\n",
    "    cpp_sources=cpp_source,\n",
    "    functions='add_one_cpu'\n",
    ")\n",
    "\n",
    "# load the module\n",
    "mod: Module = tvm_ffi.load_module(lib_path)\n",
    "\n",
    "# use the function from the loaded module to perform\n",
    "x = torch.tensor([1, 2, 3, 4, 5], dtype=torch.float32)\n",
    "y = torch.empty_like(x)\n",
    "mod.add_one_cpu(x, y)\n",
    "torch.testing.assert_close(x + 1, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad715079",
   "metadata": {},
   "source": [
    "## 错误处理\n",
    "\n",
    "FFI 函数可能会引发错误。在这种情况下，Python 包会自动将错误转换为 Python 中相应的错误类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20b82ecd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "message",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# defined in C++\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# [](String kind, String msg) { throw Error(kind, msg, backtrace); }\u001b[39;00m\n\u001b[32m      5\u001b[39m test_raise_error = tvm_ffi.get_global_func(\u001b[33m\"\u001b[39m\u001b[33mtesting.test_raise_error\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mtest_raise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mValueError\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpython/tvm_ffi/cython/function.pxi:678\u001b[39m, in \u001b[36mcore.Function.__call__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msrc/ffi/extra/testing.cc:158\u001b[39m, in \u001b[36mvoid tvm::ffi::TestRaiseError(String, String)\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mValueError\u001b[39m: message"
     ]
    }
   ],
   "source": [
    "import tvm_ffi\n",
    "\n",
    "# defined in C++\n",
    "# [](String kind, String msg) { throw Error(kind, msg, backtrace); }\n",
    "test_raise_error = tvm_ffi.get_global_func(\"testing.test_raise_error\")\n",
    "\n",
    "test_raise_error(\"ValueError\", \"message\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e62a63",
   "metadata": {},
   "source": [
    "还可以通过 {func}`tvm_ffi.register_error` 函数注册额外的错误派发。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f21eb00",
   "metadata": {},
   "source": [
    "## 高级：注册自定义对象"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6828be",
   "metadata": {},
   "source": [
    "对于高级用例，可能需要注册自定义对象。这可以通过 TVM-FFI API 中的反射注册表来实现。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adad7abb",
   "metadata": {},
   "source": [
    "以 tvm_ffi 包的测试模块中 C++ 代码 为例："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3734e162",
   "metadata": {},
   "source": [
    "```cpp\n",
    "#include <tvm/ffi/reflection/registry.h>\n",
    "\n",
    "// Step 1: Define the object class (stores the actual data)\n",
    "class TestIntPairObj : public tvm::ffi::Object {\n",
    "public:\n",
    "  int64_t a;\n",
    "  int64_t b;\n",
    "\n",
    "  TestIntPairObj() = default;\n",
    "  TestIntPairObj(int64_t a, int64_t b) : a(a), b(b) {}\n",
    "\n",
    "  // Required: declare type information\n",
    "TVM_FFI_DECLARE_OBJECT_INFO_FINAL(\"testing.TestIntPair\", TestIntPairObj, tvm::ffi::Object);\n",
    "};\n",
    "\n",
    "// Step 2: Define the reference wrapper (user-facing interface)\n",
    "class TestIntPair : public tvm::ffi::ObjectRef {\n",
    "public:\n",
    "  // Constructor\n",
    "  explicit TestIntPair(int64_t a, int64_t b) {\n",
    "    data_ = tvm::ffi::make_object<TestIntPairObj>(a, b);\n",
    "  }\n",
    "\n",
    "  // Required: define object reference methods\n",
    "  TVM_FFI_DEFINE_OBJECT_REF_METHODS_NULLABLE(TestIntPair, tvm::ffi::ObjectRef, TestIntPairObj);\n",
    "};\n",
    "\n",
    "TVM_FFI_STATIC_INIT_BLOCK() {\n",
    "  namespace refl = tvm::ffi::reflection;\n",
    "  // register the object into the system\n",
    "  // register field accessors and a global static function `__create__` as ffi::Function\n",
    "  refl::ObjectDef<TestIntPairObj>()\n",
    "    .def_ro(\"a\", &TestIntPairObj::a)\n",
    "    .def_ro(\"b\", &TestIntPairObj::b)\n",
    "    .def_static(\"__create__\", [](int64_t a, int64_t b) -> TestIntPair {\n",
    "      return TestIntPair(a, b);\n",
    "    });\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923d76d0",
   "metadata": {},
   "source": [
    "然后，可以为库中的对象创建包装类，如下所示：\n",
    "\n",
    "```python\n",
    "import tvm_ffi\n",
    "\n",
    "# Register the class\n",
    "@tvm_ffi.register_object(\"testing.TestIntPair\")\n",
    "class TestIntPair(tvm_ffi.Object):\n",
    "    def __init__(self, a, b):\n",
    "        # This is a special method to call an FFI function whose return\n",
    "        # value exactly initializes the object handle of the object\n",
    "        self.__init_handle_by_constructor__(TestIntPair.__create__, a, b)\n",
    "\n",
    "test_int_pair = TestIntPair(1, 2)\n",
    "# We can access the fields by name\n",
    "# The properties are populated by the reflection mechanism\n",
    "assert test_int_pair.a == 1\n",
    "assert test_int_pair.b == 2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58900647",
   "metadata": {},
   "source": [
    "在后台，利用反射注册表注册的信息为每个类生成高效的字段访问器和方法。\n",
    "\n",
    "重要的是，当你有多重继承时，你需要在基类和子类上调用 {func}`tvm_ffi.register_object`。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
