{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# target_codegen_c_host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tvm\n",
    "import tvm.testing\n",
    "from tvm import te\n",
    "import numpy as np\n",
    "from tvm.contrib.utils import tempdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c_host add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"/media/pc/data/lxw/ai/tvm\"\n",
    "kwargs = {\n",
    "    \"options\" : [\n",
    "        \"-O2\", \"-std=c++17\", \n",
    "        \"-I\" + f\"{source_dir}/src/runtime/contrib\", \n",
    "        \"-I\" + f\"{source_dir}/include\",\n",
    "        \"-I\" + f\"{source_dir}/3rdparty/dlpack/include\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = 1024\n",
    "n = tvm.runtime.convert(nn)\n",
    "A = te.placeholder((n,), name=\"A\")\n",
    "B = te.placeholder((n,), name=\"B\")\n",
    "C = te.compute(A.shape, lambda *i: A(*i) + B(*i), name=\"C\")\n",
    "s = te.create_schedule(C.op)\n",
    "\n",
    "def check_c(kwargs):\n",
    "    mhost = tvm.build(s, [A, B, C], \"c\", name=\"test_fadd\")\n",
    "    temp = tempdir()\n",
    "    path_dso = temp.relpath(\"temp.so\")\n",
    "    mhost.export_library(path_dso, fcompile=False, **kwargs)\n",
    "    m = tvm.runtime.load_module(path_dso)\n",
    "    fadd = m[\"test_fadd\"]\n",
    "    dev = tvm.cpu(0)\n",
    "    # launch the kernel.\n",
    "    n = nn\n",
    "    a = tvm.nd.array(np.random.uniform(size=n).astype(A.dtype), dev)\n",
    "    b = tvm.nd.array(np.random.uniform(size=n).astype(B.dtype), dev)\n",
    "    c = tvm.nd.array(np.zeros(n, dtype=C.dtype), dev)\n",
    "    fadd(a, b, c)\n",
    "    np.testing.assert_allclose(c.numpy(), a.numpy() + b.numpy())\n",
    "\n",
    "check_c(kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = 1024\n",
    "n = tvm.runtime.convert(nn)\n",
    "A = te.placeholder((n,), name=\"A\")\n",
    "B = te.placeholder((n,), name=\"B\")\n",
    "AA = te.compute((n,), lambda *i: A(*i), name=\"A\")\n",
    "BB = te.compute((n,), lambda *i: B(*i), name=\"B\")\n",
    "T = te.compute(A.shape, lambda *i: AA(*i) + BB(*i), name=\"T\")\n",
    "C = te.compute(A.shape, lambda *i: T(*i), name=\"C\")\n",
    "s = te.create_schedule(C.op)\n",
    "xo, xi = s[C].split(C.op.axis[0], factor=4)\n",
    "xo1, xo2 = s[C].split(xo, factor=13)\n",
    "s[C].parallel(xo2)\n",
    "s[C].pragma(xo1, \"parallel_launch_point\")\n",
    "s[C].pragma(xo2, \"parallel_stride_pattern\")\n",
    "s[C].pragma(xo2, \"parallel_barrier_when_finish\")\n",
    "# FIXME(tvm-team): vector operators are not supported for codegen to C yet\n",
    "# s[C].vectorize(xi)\n",
    "\n",
    "def check_c():\n",
    "    # Specifically allow offset to test codepath when offset is available\n",
    "    Ab = tvm.tir.decl_buffer(\n",
    "        A.shape, A.dtype, elem_offset=te.size_var(\"Aoffset\"), offset_factor=8, name=\"A\"\n",
    "    )\n",
    "    binds = {A: Ab}\n",
    "    # BUILD and invoke the kernel.\n",
    "    f1 = tvm.lower(s, [A, B, C], name=\"test_fadd_pipeline\")\n",
    "    mhost = tvm.build(f1, target=\"c\")\n",
    "\n",
    "    temp = tempdir()\n",
    "    path_dso = temp.relpath(\"temp.so\")\n",
    "    mhost.export_library(path_dso, fcompile=False, **kwargs)\n",
    "    m = tvm.runtime.load_module(path_dso)\n",
    "    fadd = m[\"test_fadd_pipeline\"]\n",
    "    dev = tvm.cpu(0)\n",
    "    # launch the kernel.\n",
    "    n = nn\n",
    "    a = tvm.nd.array(np.random.uniform(size=n).astype(A.dtype), dev)\n",
    "    b = tvm.nd.array(np.random.uniform(size=n).astype(B.dtype), dev)\n",
    "    c = tvm.nd.array(np.zeros(n, dtype=C.dtype), dev)\n",
    "    fadd(a, b, c)\n",
    "    np.testing.assert_allclose(c.numpy(), a.numpy() + b.numpy())\n",
    "\n",
    "check_c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## reinterpret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = 1024\n",
    "n = tvm.runtime.convert(nn)\n",
    "A = te.placeholder((n,), name=\"A\", dtype=\"int32\")\n",
    "B = te.compute(\n",
    "    A.shape, lambda *i: tvm.tir.call_intrin(\"float32\", \"tir.reinterpret\", 2 + A(*i)), name=\"B\"\n",
    ")\n",
    "s = te.create_schedule(B.op)\n",
    "\n",
    "def check_c():\n",
    "    mhost = tvm.build(s, [A, B], \"c\", name=\"test_reinterpret\")\n",
    "    temp = tempdir()\n",
    "    path_dso = temp.relpath(\"temp.so\")\n",
    "    mhost.export_library(path_dso, fcompile=False, **kwargs)\n",
    "    m = tvm.runtime.load_module(path_dso)\n",
    "    fadd = m[\"test_reinterpret\"]\n",
    "    dev = tvm.cpu(0)\n",
    "    n = nn\n",
    "    a = tvm.nd.array(np.random.randint(-(2**30), 2**30, size=n).astype(A.dtype), dev)\n",
    "    b = tvm.nd.array(np.zeros(n, dtype=B.dtype), dev)\n",
    "    fadd(a, b)\n",
    "    np.testing.assert_allclose(b.numpy(), (2 + a.numpy()).view(\"float32\"))\n",
    "\n",
    "check_c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = 1024\n",
    "n = tvm.runtime.convert(nn)\n",
    "A = te.placeholder((n,), name=\"A\", dtype=\"float32\")\n",
    "B = te.compute(A.shape, lambda *i: tvm.tir.call_intrin(\"float32\", \"tir.ceil\", A(*i)), name=\"B\")\n",
    "s = te.create_schedule(B.op)\n",
    "\n",
    "def check_c():\n",
    "    mhost = tvm.build(s, [A, B], \"c\", name=\"test_ceil\")\n",
    "    temp = tempdir()\n",
    "    path_dso = temp.relpath(\"temp.so\")\n",
    "    mhost.export_library(path_dso, fcompile=False, **kwargs)\n",
    "    m = tvm.runtime.load_module(path_dso)\n",
    "    fceil = m[\"test_ceil\"]\n",
    "    dev = tvm.cpu(0)\n",
    "    n = nn\n",
    "    a = tvm.nd.array(np.random.rand(n).astype(A.dtype), dev)\n",
    "    b = tvm.nd.array(np.zeros(n, dtype=B.dtype), dev)\n",
    "    fceil(a, b)\n",
    "    np.testing.assert_allclose(b.numpy(), (np.ceil(a.numpy()).view(\"float32\")))\n",
    "\n",
    "check_c()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = 1024\n",
    "n = tvm.runtime.convert(nn)\n",
    "A = te.placeholder((n,), name=\"A\", dtype=\"float32\")\n",
    "B = te.compute(A.shape, lambda *i: tvm.tir.call_intrin(\"float32\", \"tir.floor\", A(*i)), name=\"B\")\n",
    "s = te.create_schedule(B.op)\n",
    "\n",
    "def check_c():\n",
    "    mhost = tvm.build(s, [A, B], \"c\", name=\"test_floor\")\n",
    "    temp = tempdir()\n",
    "    path_dso = temp.relpath(\"temp.so\")\n",
    "    mhost.export_library(path_dso, fcompile=False, **kwargs)\n",
    "    m = tvm.runtime.load_module(path_dso)\n",
    "    ffloor = m[\"test_floor\"]\n",
    "    dev = tvm.cpu(0)\n",
    "    n = nn\n",
    "    a = tvm.nd.array(np.random.rand(n).astype(A.dtype), dev)\n",
    "    b = tvm.nd.array(np.zeros(n, dtype=B.dtype), dev)\n",
    "    ffloor(a, b)\n",
    "    np.testing.assert_allclose(b.numpy(), (np.floor(a.numpy()).view(\"float32\")))\n",
    "\n",
    "check_c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = 1024\n",
    "n = tvm.runtime.convert(nn)\n",
    "A = te.placeholder((n,), name=\"A\", dtype=\"float32\")\n",
    "B = te.compute(A.shape, lambda *i: tvm.tir.call_intrin(\"float32\", \"tir.round\", A(*i)), name=\"B\")\n",
    "s = te.create_schedule(B.op)\n",
    "\n",
    "def check_c():\n",
    "    mhost = tvm.build(s, [A, B], \"c\", name=\"test_round\")\n",
    "    temp = tempdir()\n",
    "    path_dso = temp.relpath(\"temp.so\")\n",
    "    mhost.export_library(path_dso, fcompile=False, **kwargs)\n",
    "    m = tvm.runtime.load_module(path_dso)\n",
    "    fround = m[\"test_round\"]\n",
    "    dev = tvm.cpu(0)\n",
    "    n = nn\n",
    "    a = tvm.nd.array(np.random.rand(n).astype(A.dtype), dev)\n",
    "    b = tvm.nd.array(np.zeros(n, dtype=B.dtype), dev)\n",
    "    fround(a, b)\n",
    "    np.testing.assert_allclose(b.numpy(), (np.round(a.numpy()).view(\"float32\")))\n",
    "\n",
    "check_c()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## call_packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fake_func(fname=\"fake.func\", name=\"A\"):\n",
    "    ib = tvm.tir.ir_builder.create()\n",
    "    A = ib.pointer(\"float32\", name=name)\n",
    "    fake_func1 = tvm.tir.call_packed(fname, A[0])\n",
    "\n",
    "    ib.emit(fake_func1)\n",
    "    body = ib.get()\n",
    "    return A, body\n",
    "\n",
    "def check_global_packed_func():\n",
    "    fname = \"fake.func\"\n",
    "    A, body = fake_func(fname)\n",
    "    func1 = tvm.tir.PrimFunc([A], body).with_attr(\"global_symbol\", \"func1\")\n",
    "    B, body = fake_func()\n",
    "    func2 = tvm.tir.PrimFunc([B], body).with_attr(\"global_symbol\", \"func2\")\n",
    "    mod = tvm.IRModule({\"fake_func1\": func1, \"fake_func2\": func2})\n",
    "    mod.show()\n",
    "    fcode = tvm.build(mod, None, \"c\")\n",
    "    src = fcode.get_source()\n",
    "    # print(src)\n",
    "    # there are two locations calling the packed func\n",
    "    assert src.count(fname) == 2\n",
    "\n",
    "    suffix = \"_packed\"\n",
    "    packed_func_name = fname + suffix\n",
    "    # func name will be standardized by GetUniqueName and not exists anymore\n",
    "    assert src.find(packed_func_name) == -1\n",
    "\n",
    "    packed_func_real_name = \"_\".join(fname.split(\".\")) + suffix\n",
    "    func_declaration = \"static void* %s = NULL;\" % packed_func_real_name\n",
    "    # src only has 1 valid declaration\n",
    "    assert src.count(func_declaration) == 1\n",
    "\n",
    "check_global_packed_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
