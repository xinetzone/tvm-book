{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fake_quantization_to_integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.relay.transform import fake_quantization_to_integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_fq_to_int(expr, args, allow_rounding_error=False):\n",
    "    mod = tvm.IRModule.from_expr(expr)\n",
    "    mod = tvm.relay.transform.InferType()(mod)\n",
    "    mod_int = tvm.relay.transform.FakeQuantizationToInteger()(mod)\n",
    "    assert not tvm.ir.structural_equal(mod, mod_int)\n",
    "    result = (\n",
    "        relay.create_executor(\"vm\", mod=mod, device=tvm.cpu(), target=\"llvm\")\n",
    "        .evaluate()(*args)\n",
    "        .numpy()\n",
    "    )\n",
    "    result_int = (\n",
    "        relay.create_executor(\"vm\", mod=mod_int, device=tvm.cpu(), target=\"llvm\")\n",
    "        .evaluate()(*args)\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "    if allow_rounding_error:\n",
    "        assert np.all(np.abs(result.astype(\"int32\") - result_int.astype(\"int32\")) <= 1)\n",
    "    else:\n",
    "        assert np.array_equal(result, result_int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试 fake_quantize_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = relay.var(\"x\", shape=[1, 3, 224, 224], dtype=\"int8\")\n",
    "w = relay.var(\"w\", shape=[16, 3, 5, 5], dtype=\"int8\")\n",
    "one = relay.const(1.0)\n",
    "zero = relay.const(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
     ]
    }
   ],
   "source": [
    "for out_dtype in [\"uint8\", \"int8\"]:\n",
    "    op = relay.op.nn.conv2d(\n",
    "        relay.qnn.op.dequantize(x, relay.const(2.0), zero),\n",
    "        relay.qnn.op.dequantize(w, relay.const(0.5), zero),\n",
    "        kernel_size=[5, 5],\n",
    "    )\n",
    "\n",
    "    op = relay.qnn.op.quantize(op, one, zero, out_dtype=out_dtype)\n",
    "\n",
    "    x_np = np.random.randint(-128, 127, size=[1, 3, 224, 224], dtype=\"int8\")\n",
    "    w_np = np.random.randint(-128, 127, size=[16, 3, 5, 5], dtype=\"int8\")\n",
    "\n",
    "    compare_fq_to_int(op, [x_np, w_np])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "expr = op\n",
    "mod = tvm.IRModule.from_expr(expr)\n",
    "mod = tvm.relay.transform.InferType()(mod)\n",
    "mod_int = tvm.relay.transform.FakeQuantizationToInteger()(mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x: Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), int8] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), int8] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w: Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">5</span>, <span style=\"color: #008000\">5</span>), int8] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">5</span>, <span style=\"color: #008000\">5</span>), int8] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">220</span>, <span style=\"color: #008000\">220</span>), int8] {\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> qnn<span style=\"color: #AA22FF; font-weight: bold\">.</span>dequantize(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x, <span style=\"color: #008000\">2</span>f <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>float32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>int32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> qnn<span style=\"color: #AA22FF; font-weight: bold\">.</span>dequantize(<span style=\"color: #AA22FF; font-weight: bold\">%</span>w, <span style=\"color: #008000\">0.5</span>f <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>float32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>int32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;float32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">5</span>, <span style=\"color: #008000\">5</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">2</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> nn<span style=\"color: #AA22FF; font-weight: bold\">.</span>conv2d(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">1</span>, padding<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>], kernel_size<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">5</span>, <span style=\"color: #008000\">5</span>]) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">220</span>, <span style=\"color: #008000\">220</span>), float32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  qnn<span style=\"color: #AA22FF; font-weight: bold\">.</span>quantize(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">2</span>, <span style=\"color: #008000\">1</span>f <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>float32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>int32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int8&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">220</span>, <span style=\"color: #008000\">220</span>), int8] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #AA22FF\">@main</span>(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x: Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), int8] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">224</span>, <span style=\"color: #008000\">224</span>), int8] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w: Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">5</span>, <span style=\"color: #008000\">5</span>), int8] <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">5</span>, <span style=\"color: #008000\">5</span>), int8] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>) <span style=\"color: #AA22FF; font-weight: bold\">-&gt;</span> Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">220</span>, <span style=\"color: #008000\">220</span>), int8] {\n",
       "  <span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">=</span> qnn<span style=\"color: #AA22FF; font-weight: bold\">.</span>conv2d(<span style=\"color: #AA22FF; font-weight: bold\">%</span>x, <span style=\"color: #AA22FF; font-weight: bold\">%</span>w, <span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>int32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>int32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #008000\">2</span>f <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>float32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #008000\">0.5</span>f <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>float32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, padding<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">0</span>], kernel_size<span style=\"color: #AA22FF; font-weight: bold\">=</span>[<span style=\"color: #008000\">5</span>, <span style=\"color: #008000\">5</span>], out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int32&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">220</span>, <span style=\"color: #008000\">220</span>), int32] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>;\n",
       "  qnn<span style=\"color: #AA22FF; font-weight: bold\">.</span>requantize(<span style=\"color: #AA22FF; font-weight: bold\">%</span><span style=\"color: #008000\">0</span>, <span style=\"color: #008000\">1</span>f <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>float32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>int32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #008000\">1</span>f <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>float32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, <span style=\"color: #008000\">0</span> <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>int32 <span style=\"color: #AA22FF; font-weight: bold\">*/</span>, axis<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #008000\">1</span>, out_dtype<span style=\"color: #AA22FF; font-weight: bold\">=</span><span style=\"color: #BA2121\">&quot;int8&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">/*</span> ty<span style=\"color: #AA22FF; font-weight: bold\">=</span>Tensor[(<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">220</span>, <span style=\"color: #008000\">220</span>), int8] <span style=\"color: #AA22FF; font-weight: bold\">*/</span>\n",
       "}\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mod.show()\n",
    "mod_int.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'#[version = \"0.0.5\"]\\ndef @main(%x: Tensor[(1, 3, 224, 224), int8] /* ty=Tensor[(1, 3, 224, 224), int8] */, %w: Tensor[(16, 3, 5, 5), int8] /* ty=Tensor[(16, 3, 5, 5), int8] */) -> Tensor[(1, 16, 220, 220), int8] {\\n  %0 = qnn.conv2d(%x, %w, 0 /* ty=int32 */, 0 /* ty=int32 */, 2f /* ty=float32 */, 0.5f /* ty=float32 */, padding=[0, 0, 0, 0], kernel_size=[5, 5], out_dtype=\"int32\") /* ty=Tensor[(1, 16, 220, 220), int32] */;\\n  qnn.requantize(%0, 1f /* ty=float32 */, 0 /* ty=int32 */, 1f /* ty=float32 */, 0 /* ty=int32 */, axis=1, out_dtype=\"int8\") /* ty=Tensor[(1, 16, 220, 220), int8] */\\n}\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_int.astext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fake_quantize_conv_per_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for out_dtype in [\"int8\", \"uint8\"]:\n",
    "    x = relay.var(\"x\", shape=[1, 3, 224, 224], dtype=\"int8\")\n",
    "    w = relay.var(\"w\", shape=[16, 3, 5, 5], dtype=\"int8\")\n",
    "    one = relay.const([1.0] * 16)\n",
    "    zero_point = relay.const([np.random.randint(0, 255)] * 16)\n",
    "\n",
    "    op = relay.op.nn.conv2d(\n",
    "        relay.qnn.op.dequantize(x, relay.const(2.0), relay.const(0)),\n",
    "        relay.qnn.op.dequantize(\n",
    "            w, relay.const(np.random.random([16]).astype(\"float32\")), zero_point, axis=0\n",
    "        ),\n",
    "        kernel_size=[5, 5],\n",
    "        channels=16,\n",
    "    )\n",
    "    op = relay.qnn.op.quantize(op, relay.const(1.0), relay.const(0), out_dtype=out_dtype)\n",
    "\n",
    "    x_np = np.random.randint(-128, 127, size=[1, 3, 224, 224], dtype=\"int8\")\n",
    "    w_np = np.random.randint(-128, 127, size=[16, 3, 5, 5], dtype=\"int8\")\n",
    "\n",
    "    compare_fq_to_int(op, [x_np, w_np], allow_rounding_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
