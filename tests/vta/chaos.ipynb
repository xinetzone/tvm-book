{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 临时测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "import tvm\n",
    "from tvm import te\n",
    "import vta\n",
    "import numpy as np\n",
    "from tvm import rpc\n",
    "from vta.testing import simulator\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Workload:\n",
    "    batch_size: int\n",
    "    height: int\n",
    "    width: int\n",
    "    in_channels: int\n",
    "    out_channels: int\n",
    "    kernel_h: int\n",
    "    kernel_w: int\n",
    "    pad_h: int\n",
    "    pad_w: int\n",
    "    stride_h: int\n",
    "    stride_w: int\n",
    "\n",
    "    def __post_init__(self):\n",
    "        # Derive output feature map dimensions\n",
    "        self.fout_height = (self.height + 2 * self.pad_h - self.kernel_h) // self.stride_h + 1\n",
    "        self.fout_width = (self.width + 2 * self.pad_w - self.kernel_w) // self.stride_w + 1\n",
    "\n",
    "    def data(self, env: vta.environment.Environment):\n",
    "        # Input feature map: (N, IC, H, W, n, ic)\n",
    "        return (\n",
    "            self.batch_size // env.BATCH,\n",
    "            self.in_channels // env.BLOCK_IN,\n",
    "            self.height,\n",
    "            self.width,\n",
    "            env.BATCH,\n",
    "            env.BLOCK_IN,\n",
    "        )\n",
    "    \n",
    "    def kernel(self, env: vta.environment.Environment):\n",
    "        # Kernel: (OC, IC, H, W, oc, ic)\n",
    "        return (\n",
    "            self.out_channels // env.BLOCK_OUT,\n",
    "            self.in_channels // env.BLOCK_IN,\n",
    "            self.kernel_h,\n",
    "            self.kernel_w,\n",
    "            env.BLOCK_OUT,\n",
    "            env.BLOCK_IN,\n",
    "        )\n",
    "    \n",
    "    def output(self, env: vta.environment.Environment):\n",
    "        # Output feature map: (N, OC, H, W, n, oc)\n",
    "        return (\n",
    "            self.batch_size // env.BATCH,\n",
    "            self.out_channels // env.BLOCK_OUT,\n",
    "            self.fout_height,\n",
    "            self.fout_width,\n",
    "            env.BATCH,\n",
    "            env.BLOCK_OUT,\n",
    "        )\n",
    "\n",
    "# Load VTA parameters from the 3rdparty/vta-hw/config/vta_config.json file\n",
    "env = vta.get_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = Workload(1, 14, 14, 256, 256, 3, 3, 1, 1, 1, 1)\n",
    "assert self.batch_size % env.BATCH == 0\n",
    "assert self.in_channels % env.BLOCK_IN == 0\n",
    "assert self.out_channels % env.BLOCK_OUT == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolution reduction axes\n",
    "dy = te.reduce_axis((0, self.kernel_h), name=\"dy\")\n",
    "dx = te.reduce_axis((0, self.kernel_w), name=\"dx\")\n",
    "ic = te.reduce_axis((0, self.in_channels // env.BLOCK_IN), name=\"ic\")\n",
    "ic_tns = te.reduce_axis((0, env.BLOCK_IN), name=\"ic_tns\")\n",
    "# Input placeholder tensors\n",
    "data = te.placeholder(self.data(env), name=\"data\", dtype=env.inp_dtype)\n",
    "kernel = te.placeholder(self.kernel(env), name=\"kernel\", dtype=env.wgt_dtype)\n",
    "\n",
    "# Copy buffers:\n",
    "#   Apply spatial padding to input feature map\n",
    "data_buf = tvm.topi.nn.pad(data, [0, 0, self.pad_h, self.pad_w, 0, 0], name=\"data_buf\")\n",
    "kernel_buf = te.compute(self.kernel(env), lambda *i: kernel(*i), \"kernel_buf\")\n",
    "\n",
    "# Declare 2D convolution\n",
    "res_conv = te.compute(\n",
    "    self.output(env),\n",
    "    lambda bo, co, i, j, bi, ci: te.sum(\n",
    "        data_buf[bo, ic, i * self.stride_h + dy, j * self.stride_w + dx, bi, ic_tns].astype(env.acc_dtype)\n",
    "        * kernel_buf[co, ic, dy, dx, ci, ic_tns].astype(env.acc_dtype),\n",
    "        axis=[ic, dy, dx, ic_tns],\n",
    "    ),\n",
    "    name=\"res_conv\",\n",
    ")\n",
    "\n",
    "# Add shift stage for fix-point normalization\n",
    "res_shr = te.compute(self.output(env), lambda *i: res_conv(*i) >> 8, name=\"res_shr\")\n",
    "# Apply clipping between (0, input max value)\n",
    "inp_max = (1 << (env.INP_WIDTH - 1)) - 1\n",
    "res_max = te.compute(self.output(env), lambda *i: tvm.te.max(res_shr(*i), 0), \"res_max\")\n",
    "res_min = te.compute(self.output(env), lambda *i: tvm.te.min(res_max(*i), inp_max), \"res_min\")\n",
    "# Result Tensor\n",
    "res = te.compute(self.output(env), lambda *i: res_min(*i).astype(env.inp_dtype), name=\"res\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义 tiling sizes\n",
    "b_block = 1 // env.BATCH\n",
    "oc_block = 1 #128 // env.BLOCK_OUT\n",
    "ic_block = 1 #// env.BLOCK_IN\n",
    "h_block = 1\n",
    "w_block = 14\n",
    "\n",
    "s = te.create_schedule(res.op)\n",
    "# 沿着空间和输出通道维度平铺输出张量（因为默认情况下做单批推理，沿着批维分割没有效果）\n",
    "b, oc, y, x, b_tns, oc_tns = s[res].op.axis\n",
    "b_out, b_inn = s[res].split(b, factor=b_block)\n",
    "oc_out, oc_inn = s[res].split(oc, factor=oc_block)\n",
    "y_out, y_inn = s[res].split(y, factor=h_block)\n",
    "x_out, x_inn = s[res].split(x, factor=w_block)\n",
    "s[res].reorder(b_out, oc_out, y_out, x_out, b_inn, oc_inn, y_inn, x_inn, b_tns, oc_tns)\n",
    "\n",
    "# 将中间计算移动到每个输出计算 tile 中\n",
    "s[res_conv].compute_at(s[res], x_out)\n",
    "s[res_shr].compute_at(s[res], x_out)\n",
    "s[res_max].compute_at(s[res], x_out)\n",
    "s[res_min].compute_at(s[res], x_out)\n",
    "\n",
    "# 沿着规约轴（输入通道）应用额外的循环分割（loop split）\n",
    "b_inn, oc_inn, y_inn, x_inn, b_tns, oc_tns = s[res_conv].op.axis\n",
    "ic_out, ic_inn = s[res_conv].split(ic, factor=ic_block)\n",
    "# 重排轴\n",
    "s[res_conv].reorder(ic_out, b_inn, oc_inn, y_inn, ic_inn, dy, dx, x_inn, b_tns, oc_tns, ic_tns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:38:01] /media/pc/data/lxw/ai/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.vta.command_handle\n",
      "[19:38:01] /media/pc/data/lxw/ai/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.vta.command_handle\n",
      "[19:38:01] /media/pc/data/lxw/ai/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.vta.command_handle\n",
      "[19:38:01] /media/pc/data/lxw/ai/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.vta.command_handle\n",
      "[19:38:01] /media/pc/data/lxw/ai/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.vta.command_handle\n",
      "[19:38:01] /media/pc/data/lxw/ai/tvm/src/script/printer/tir/expr.cc:246: Warning: No TScriptPrinterName attribute for tir.vta.command_handle\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"highlight\" style=\"background: \"><pre style=\"line-height: 125%;\"><span></span><span style=\"color: #007979; font-style: italic\"># from tvm.script import ir as I</span>\n",
       "<span style=\"color: #007979; font-style: italic\"># from tvm.script import tir as T</span>\n",
       "\n",
       "\n",
       "<span style=\"color: #AA22FF\">@I</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>ir_module\n",
       "<span style=\"color: #008000; font-weight: bold\">class</span> <span style=\"color: #0000FF; font-weight: bold\">Module</span>:\n",
       "    <span style=\"color: #AA22FF\">@T</span><span style=\"color: #AA22FF; font-weight: bold\">.</span>prim_func\n",
       "    <span style=\"color: #008000; font-weight: bold\">def</span> <span style=\"color: #0000FF\">main</span>(\n",
       "        data: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>), <span style=\"color: #BA2121\">&quot;int8&quot;</span>),\n",
       "        kernel: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">16</span>), <span style=\"color: #BA2121\">&quot;int8&quot;</span>),\n",
       "        res: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">1</span>, <span style=\"color: #008000\">16</span>), <span style=\"color: #BA2121\">&quot;int8&quot;</span>),\n",
       "    ):\n",
       "        T<span style=\"color: #AA22FF; font-weight: bold\">.</span>func_attr(\n",
       "            {\n",
       "                <span style=\"color: #BA2121\">&quot;from_legacy_te_schedule&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>),\n",
       "                <span style=\"color: #BA2121\">&quot;global_symbol&quot;</span>: <span style=\"color: #BA2121\">&quot;main&quot;</span>,\n",
       "                <span style=\"color: #BA2121\">&quot;tir.noalias&quot;</span>: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>bool(<span style=\"color: #008000; font-weight: bold\">True</span>),\n",
       "            }\n",
       "        )\n",
       "        res_ptr: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle(<span style=\"color: #BA2121\">&quot;int8&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_extern(\n",
       "            <span style=\"color: #BA2121\">&quot;handle&quot;</span>,\n",
       "            <span style=\"color: #BA2121\">&quot;VTABufferCPUPtr&quot;</span>,\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>tvm_thread_context(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>tir<span style=\"color: #AA22FF; font-weight: bold\">.</span>vta<span style=\"color: #AA22FF; font-weight: bold\">.</span>command_handle()),\n",
       "            res<span style=\"color: #AA22FF; font-weight: bold\">.</span>data,\n",
       "        )\n",
       "        kernel_ptr: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle(<span style=\"color: #BA2121\">&quot;int8&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_extern(\n",
       "            <span style=\"color: #BA2121\">&quot;handle&quot;</span>,\n",
       "            <span style=\"color: #BA2121\">&quot;VTABufferCPUPtr&quot;</span>,\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>tvm_thread_context(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>tir<span style=\"color: #AA22FF; font-weight: bold\">.</span>vta<span style=\"color: #AA22FF; font-weight: bold\">.</span>command_handle()),\n",
       "            kernel<span style=\"color: #AA22FF; font-weight: bold\">.</span>data,\n",
       "        )\n",
       "        data_ptr: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle(<span style=\"color: #BA2121\">&quot;int8&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_extern(\n",
       "            <span style=\"color: #BA2121\">&quot;handle&quot;</span>,\n",
       "            <span style=\"color: #BA2121\">&quot;VTABufferCPUPtr&quot;</span>,\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>tvm_thread_context(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>tir<span style=\"color: #AA22FF; font-weight: bold\">.</span>vta<span style=\"color: #AA22FF; font-weight: bold\">.</span>command_handle()),\n",
       "            data<span style=\"color: #AA22FF; font-weight: bold\">.</span>data,\n",
       "        )\n",
       "        data_buf <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>allocate([<span style=\"color: #008000\">65536</span>], <span style=\"color: #BA2121\">&quot;int8&quot;</span>, <span style=\"color: #BA2121\">&quot;global&quot;</span>)\n",
       "        data_buf_ptr: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle(<span style=\"color: #BA2121\">&quot;int8&quot;</span>, <span style=\"color: #BA2121\">&quot;global&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_extern(\n",
       "            <span style=\"color: #BA2121\">&quot;handle&quot;</span>,\n",
       "            <span style=\"color: #BA2121\">&quot;VTABufferCPUPtr&quot;</span>,\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>tvm_thread_context(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>tir<span style=\"color: #AA22FF; font-weight: bold\">.</span>vta<span style=\"color: #AA22FF; font-weight: bold\">.</span>command_handle()),\n",
       "            data_buf,\n",
       "        )\n",
       "        kernel_buf <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>allocate([<span style=\"color: #008000\">589824</span>], <span style=\"color: #BA2121\">&quot;int8&quot;</span>, <span style=\"color: #BA2121\">&quot;global&quot;</span>)\n",
       "        kernel_buf_ptr: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle(<span style=\"color: #BA2121\">&quot;int8&quot;</span>, <span style=\"color: #BA2121\">&quot;global&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_extern(\n",
       "            <span style=\"color: #BA2121\">&quot;handle&quot;</span>,\n",
       "            <span style=\"color: #BA2121\">&quot;VTABufferCPUPtr&quot;</span>,\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>tvm_thread_context(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>tir<span style=\"color: #AA22FF; font-weight: bold\">.</span>vta<span style=\"color: #AA22FF; font-weight: bold\">.</span>command_handle()),\n",
       "            kernel_buf,\n",
       "        )\n",
       "        res_conv <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>allocate([<span style=\"color: #008000\">224</span>], <span style=\"color: #BA2121\">&quot;int32&quot;</span>, <span style=\"color: #BA2121\">&quot;global&quot;</span>)\n",
       "        res_conv_ptr: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>handle(<span style=\"color: #BA2121\">&quot;int32&quot;</span>, <span style=\"color: #BA2121\">&quot;global&quot;</span>) <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>call_extern(\n",
       "            <span style=\"color: #BA2121\">&quot;handle&quot;</span>,\n",
       "            <span style=\"color: #BA2121\">&quot;VTABufferCPUPtr&quot;</span>,\n",
       "            T<span style=\"color: #AA22FF; font-weight: bold\">.</span>tvm_thread_context(T<span style=\"color: #AA22FF; font-weight: bold\">.</span>tir<span style=\"color: #AA22FF; font-weight: bold\">.</span>vta<span style=\"color: #AA22FF; font-weight: bold\">.</span>command_handle()),\n",
       "            res_conv,\n",
       "        )\n",
       "        buffer <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">65536</span>,), <span style=\"color: #BA2121\">&quot;int8&quot;</span>, data<span style=\"color: #AA22FF; font-weight: bold\">=</span>data_buf_ptr)\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i1, i2, i3, i5 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">16</span>):\n",
       "            cse_var_1: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32 <span style=\"color: #AA22FF; font-weight: bold\">=</span> i3 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">16</span>\n",
       "            buffer_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">50176</span>,), <span style=\"color: #BA2121\">&quot;int8&quot;</span>, data<span style=\"color: #AA22FF; font-weight: bold\">=</span>data_ptr)\n",
       "            buffer[i1 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">4096</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> i2 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">256</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> cse_var_1 <span style=\"color: #AA22FF; font-weight: bold\">+</span> i5] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>if_then_else(\n",
       "                <span style=\"color: #008000\">1</span> <span style=\"color: #AA22FF; font-weight: bold\">&lt;=</span> i2 <span style=\"color: #008000; font-weight: bold\">and</span> i2 <span style=\"color: #AA22FF; font-weight: bold\">&lt;</span> <span style=\"color: #008000\">15</span> <span style=\"color: #008000; font-weight: bold\">and</span> <span style=\"color: #008000\">1</span> <span style=\"color: #AA22FF; font-weight: bold\">&lt;=</span> i3 <span style=\"color: #008000; font-weight: bold\">and</span> i3 <span style=\"color: #AA22FF; font-weight: bold\">&lt;</span> <span style=\"color: #008000\">15</span>,\n",
       "                buffer_1[i1 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">3136</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> i2 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">224</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> cse_var_1 <span style=\"color: #AA22FF; font-weight: bold\">+</span> i5 <span style=\"color: #AA22FF; font-weight: bold\">-</span> <span style=\"color: #008000\">240</span>],\n",
       "                T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int8(<span style=\"color: #008000\">0</span>),\n",
       "            )\n",
       "        buffer_1 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">589824</span>,), <span style=\"color: #BA2121\">&quot;int8&quot;</span>, data<span style=\"color: #AA22FF; font-weight: bold\">=</span>kernel_buf_ptr)\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i0, i1, i2, i3, i4, i5 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">16</span>):\n",
       "            cse_var_2: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32 <span style=\"color: #AA22FF; font-weight: bold\">=</span> (\n",
       "                i0 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">36864</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> i1 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">2304</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> i2 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">768</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> i3 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">256</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> i4 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">16</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> i5\n",
       "            )\n",
       "            buffer_2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">589824</span>,), <span style=\"color: #BA2121\">&quot;int8&quot;</span>, data<span style=\"color: #AA22FF; font-weight: bold\">=</span>kernel_ptr)\n",
       "            buffer_1[cse_var_2] <span style=\"color: #AA22FF; font-weight: bold\">=</span> buffer_2[cse_var_2]\n",
       "        <span style=\"color: #008000; font-weight: bold\">for</span> i1_outer, i2_outer <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">14</span>):\n",
       "            buffer_2 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">224</span>,), <span style=\"color: #BA2121\">&quot;int32&quot;</span>, data<span style=\"color: #AA22FF; font-weight: bold\">=</span>res_conv_ptr)\n",
       "            <span style=\"color: #008000; font-weight: bold\">for</span> j_init, ci_init <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">16</span>):\n",
       "                buffer_2[j_init <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">16</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> ci_init] <span style=\"color: #AA22FF; font-weight: bold\">=</span> <span style=\"color: #008000\">0</span>\n",
       "            <span style=\"color: #008000; font-weight: bold\">for</span> ic_outer, dy, dx, j, ci, ic_tns <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">3</span>, <span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">16</span>, <span style=\"color: #008000\">16</span>):\n",
       "                cse_var_4: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32 <span style=\"color: #AA22FF; font-weight: bold\">=</span> j <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">16</span>\n",
       "                cse_var_3: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32 <span style=\"color: #AA22FF; font-weight: bold\">=</span> cse_var_4 <span style=\"color: #AA22FF; font-weight: bold\">+</span> ci\n",
       "                buffer_2[cse_var_3] <span style=\"color: #AA22FF; font-weight: bold\">=</span> buffer_2[cse_var_3] <span style=\"color: #AA22FF; font-weight: bold\">+</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Cast(\n",
       "                    <span style=\"color: #BA2121\">&quot;int32&quot;</span>,\n",
       "                    buffer[\n",
       "                        ic_outer <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">4096</span>\n",
       "                        <span style=\"color: #AA22FF; font-weight: bold\">+</span> i2_outer <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">256</span>\n",
       "                        <span style=\"color: #AA22FF; font-weight: bold\">+</span> dy <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">256</span>\n",
       "                        <span style=\"color: #AA22FF; font-weight: bold\">+</span> cse_var_4\n",
       "                        <span style=\"color: #AA22FF; font-weight: bold\">+</span> dx <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">16</span>\n",
       "                        <span style=\"color: #AA22FF; font-weight: bold\">+</span> ic_tns\n",
       "                    ],\n",
       "                ) <span style=\"color: #AA22FF; font-weight: bold\">*</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Cast(\n",
       "                    <span style=\"color: #BA2121\">&quot;int32&quot;</span>,\n",
       "                    buffer_1[\n",
       "                        i1_outer <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">36864</span>\n",
       "                        <span style=\"color: #AA22FF; font-weight: bold\">+</span> ic_outer <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">2304</span>\n",
       "                        <span style=\"color: #AA22FF; font-weight: bold\">+</span> dy <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">768</span>\n",
       "                        <span style=\"color: #AA22FF; font-weight: bold\">+</span> dx <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">256</span>\n",
       "                        <span style=\"color: #AA22FF; font-weight: bold\">+</span> ci <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">16</span>\n",
       "                        <span style=\"color: #AA22FF; font-weight: bold\">+</span> ic_tns\n",
       "                    ],\n",
       "                )\n",
       "            buffer_3 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">224</span>,), <span style=\"color: #BA2121\">&quot;int32&quot;</span>, data<span style=\"color: #AA22FF; font-weight: bold\">=</span>res_conv_ptr)\n",
       "            <span style=\"color: #008000; font-weight: bold\">for</span> i3, i5 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">16</span>):\n",
       "                cse_var_5: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32 <span style=\"color: #AA22FF; font-weight: bold\">=</span> i3 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">16</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> i5\n",
       "                buffer_3[cse_var_5] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>shift_right(buffer_2[cse_var_5], <span style=\"color: #008000\">8</span>)\n",
       "            buffer_4 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">224</span>,), <span style=\"color: #BA2121\">&quot;int32&quot;</span>, data<span style=\"color: #AA22FF; font-weight: bold\">=</span>res_conv_ptr)\n",
       "            <span style=\"color: #008000; font-weight: bold\">for</span> i3, i5 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">16</span>):\n",
       "                cse_var_6: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32 <span style=\"color: #AA22FF; font-weight: bold\">=</span> i3 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">16</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> i5\n",
       "                buffer_4[cse_var_6] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>max(buffer_3[cse_var_6], <span style=\"color: #008000\">0</span>)\n",
       "            buffer_5 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">224</span>,), <span style=\"color: #BA2121\">&quot;int32&quot;</span>, data<span style=\"color: #AA22FF; font-weight: bold\">=</span>res_conv_ptr)\n",
       "            <span style=\"color: #008000; font-weight: bold\">for</span> i3, i5 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">16</span>):\n",
       "                cse_var_7: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32 <span style=\"color: #AA22FF; font-weight: bold\">=</span> i3 <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">16</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> i5\n",
       "                buffer_5[cse_var_7] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>min(buffer_4[cse_var_7], <span style=\"color: #008000\">127</span>)\n",
       "            <span style=\"color: #008000; font-weight: bold\">for</span> i3_inner, i5 <span style=\"color: #008000; font-weight: bold\">in</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>grid(<span style=\"color: #008000\">14</span>, <span style=\"color: #008000\">16</span>):\n",
       "                cse_var_8: T<span style=\"color: #AA22FF; font-weight: bold\">.</span>int32 <span style=\"color: #AA22FF; font-weight: bold\">=</span> i3_inner <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">16</span>\n",
       "                buffer_6 <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Buffer((<span style=\"color: #008000\">50176</span>,), <span style=\"color: #BA2121\">&quot;int8&quot;</span>, data<span style=\"color: #AA22FF; font-weight: bold\">=</span>res_ptr)\n",
       "                buffer_6[i1_outer <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">3136</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> i2_outer <span style=\"color: #AA22FF; font-weight: bold\">*</span> <span style=\"color: #008000\">224</span> <span style=\"color: #AA22FF; font-weight: bold\">+</span> cse_var_8 <span style=\"color: #AA22FF; font-weight: bold\">+</span> i5] <span style=\"color: #AA22FF; font-weight: bold\">=</span> T<span style=\"color: #AA22FF; font-weight: bold\">.</span>Cast(\n",
       "                    <span style=\"color: #BA2121\">&quot;int8&quot;</span>, buffer_5[cse_var_8 <span style=\"color: #AA22FF; font-weight: bold\">+</span> i5]\n",
       "                )\n",
       "</pre></div>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vta.lower(s, [data, kernel, res], simple_mode=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VTA 仅支持 2 个虚拟线程\n",
    "v_threads = 2\n",
    "\n",
    "# 沿输出通道外轴执行虚拟线程 split \n",
    "_, tx = s[res].split(oc_out, factor=v_threads)\n",
    "s[res].reorder(tx, b_out)\n",
    "s[res].bind(tx, te.thread_axis(\"cthread\"))\n",
    "# Set scope of SRAM buffers\n",
    "s[data_buf].set_scope(env.inp_scope)\n",
    "s[kernel_buf].set_scope(env.wgt_scope)\n",
    "s[res_conv].set_scope(env.acc_scope)\n",
    "s[res_shr].set_scope(env.acc_scope)\n",
    "s[res_min].set_scope(env.acc_scope)\n",
    "s[res_max].set_scope(env.acc_scope)\n",
    "\n",
    "# Block data and kernel cache reads\n",
    "s[data_buf].compute_at(s[res_conv], ic_out)\n",
    "s[kernel_buf].compute_at(s[res_conv], ic_out)\n",
    "\n",
    "# Use DMA copy pragma on DRAM->SRAM operations\n",
    "s[data_buf].pragma(s[data_buf].op.axis[0], env.dma_copy)\n",
    "s[kernel_buf].pragma(s[kernel_buf].op.axis[0], env.dma_copy)\n",
    "\n",
    "# 在每个结果块中对 SRAM->DRAM 操作使用 DMA copy pragma（这意味着这些 copy 应该沿着 b_inn 或结果轴 4 执行）\n",
    "s[res].pragma(s[res].op.axis[4], env.dma_copy)\n",
    "# Apply tensorization over the batch tensor tile axis\n",
    "s[res_conv].tensorize(b_tns, env.gemm)\n",
    "\n",
    "# Add an ALU pragma over the shift and clipping operations\n",
    "s[res_shr].pragma(s[res_shr].op.axis[0], env.alu)\n",
    "s[res_min].pragma(s[res_min].op.axis[0], env.alu)\n",
    "s[res_max].pragma(s[res_max].op.axis[0], env.alu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[19:38:02] /media/pc/data/lxw/ai/tvm/src/tir/transforms/arg_binder.cc:95: Warning: Trying to bind buffer to another one with lower alignment requirement  required_alignment=256, provided_alignment=64\n"
     ]
    }
   ],
   "source": [
    "# This library facilitates 2D convolution testing\n",
    "from tvm.topi.testing import conv2d_nchw_python\n",
    "# Compile the TVM module\n",
    "with vta.build_config(disabled_pass={\"tir.CommonSubexprElimTIR\"}):\n",
    "    my_conv = vta.build(\n",
    "        s, [data, kernel, res], tvm.target.Target(\"ext_dev\", host=env.target_host), name=\"my_conv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-13 19:38:02.262 INFO load_module /tmp/tmp790d4vbd/conv2d.o\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution statistics:\n",
      "\tinp_load_nbytes :          2293760\n",
      "\twgt_load_nbytes :          8257536\n",
      "\tacc_load_nbytes :                0\n",
      "\tuop_load_nbytes :              144\n",
      "\tout_store_nbytes:            50176\n",
      "\tgemm_counter    :           451584\n",
      "\talu_counter     :             9408\n",
      "Successful 2D convolution test!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "remote = rpc.LocalSession()\n",
    "temp = tvm.contrib.utils.tempdir()\n",
    "my_conv.save(temp.relpath(\"conv2d.o\"))\n",
    "remote.upload(temp.relpath(\"conv2d.o\"))\n",
    "f = remote.load_module(\"conv2d.o\")\n",
    "\n",
    "# Get the remote device context\n",
    "ctx = remote.ext_dev(0)\n",
    "\n",
    "# Initialize the data and kernel arrays randomly in the int range\n",
    "# of (-128, 128] in NCHW layout\n",
    "data_np = np.random.randint(-128, 128, size=(self.batch_size, self.in_channels, self.height, self.width)).astype(\n",
    "    data.dtype\n",
    ")\n",
    "kernel_np = np.random.randint(\n",
    "    -128, 128, size=(self.out_channels, self.in_channels, self.kernel_h, self.kernel_w)\n",
    ").astype(kernel.dtype)\n",
    "\n",
    "# Apply packing to the data and kernel arrays from a 2D NCHW\n",
    "# to a 4D NCHWnc packed layout\n",
    "data_packed = data_np.reshape(\n",
    "    self.batch_size // env.BATCH, env.BATCH, self.in_channels // env.BLOCK_IN, env.BLOCK_IN, self.height, self.width\n",
    ").transpose((0, 2, 4, 5, 1, 3))\n",
    "\n",
    "kernel_packed = kernel_np.reshape(\n",
    "    self.out_channels // env.BLOCK_OUT,\n",
    "    env.BLOCK_OUT,\n",
    "    self.in_channels // env.BLOCK_IN,\n",
    "    env.BLOCK_IN,\n",
    "    self.kernel_h,\n",
    "    self.kernel_w,\n",
    ").transpose((0, 2, 4, 5, 1, 3))\n",
    "\n",
    "# Format the input/output arrays with tvm.nd.array to the DLPack standard\n",
    "data_nd = tvm.nd.array(data_packed, ctx)\n",
    "kernel_nd = tvm.nd.array(kernel_packed, ctx)\n",
    "res_nd = tvm.nd.array(np.zeros(self.output(env)).astype(res.dtype), ctx)\n",
    "\n",
    "# Clear stats\n",
    "if env.TARGET in [\"sim\", \"tsim\"]:\n",
    "    simulator.clear_stats()\n",
    "\n",
    "# Invoke the module to perform the computation\n",
    "f(data_nd, kernel_nd, res_nd)\n",
    "\n",
    "# Verify against numpy implementation\n",
    "res_ref = conv2d_nchw_python(\n",
    "    data_np.astype(env.acc_dtype),\n",
    "    kernel_np.astype(env.acc_dtype),\n",
    "    (self.stride_h, self.stride_w),\n",
    "    (self.pad_h, self.pad_w),\n",
    ").astype(env.acc_dtype)\n",
    "res_ref = res_ref >> env.INP_WIDTH\n",
    "res_ref = np.clip(res_ref, 0, inp_max)\n",
    "res_ref = res_ref.astype(res.dtype)\n",
    "res_ref = res_ref.reshape(\n",
    "    (\n",
    "        self.batch_size // env.BATCH,\n",
    "        env.BATCH,\n",
    "        self.out_channels // env.BLOCK_OUT,\n",
    "        env.BLOCK_OUT,\n",
    "        self.fout_height,\n",
    "        self.fout_width,\n",
    "    )\n",
    ").transpose((0, 2, 4, 5, 1, 3))\n",
    "tvm.testing.assert_allclose(res_ref, res_nd.numpy())\n",
    "\n",
    "# Print stats\n",
    "if env.TARGET in [\"sim\", \"tsim\"]:\n",
    "    sim_stats = simulator.stats()\n",
    "    print(\"Execution statistics:\")\n",
    "    for k, v in sim_stats.items():\n",
    "        print(\"\\t{:<16}: {:>16}\".format(k, v))\n",
    "\n",
    "print(\"Successful 2D convolution test!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
