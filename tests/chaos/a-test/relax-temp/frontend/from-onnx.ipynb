{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relax ONNX 前端"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relax\n",
    "from tvm.relax.frontend.onnx import from_onnx\n",
    "\n",
    "import onnx\n",
    "from onnx import helper, TensorProto, ModelProto, mapping\n",
    "import onnxruntime\n",
    "\n",
    "bg = np.random.MT19937(0)\n",
    "rg = np.random.Generator(bg)\n",
    "# from tvm.relax.ir.instrument import WellFormedInstrument\n",
    "# tvm.transform.PassContext.current().override_instruments([WellFormedInstrument()])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模拟输入："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_inputs(\n",
    "    model: ModelProto, inputs: dict[str, np.ndarray]|None = None\n",
    ") -> dict[str, np.ndarray]:\n",
    "    input_values = {}\n",
    "    # 遍历模型输入并提取它们的形状。\n",
    "    for i in model.graph.input:\n",
    "        if inputs is not None and i.name in inputs and inputs[i.name] is not None:\n",
    "            input_values[i.name] = inputs[i.name]\n",
    "            continue\n",
    "        shape = []\n",
    "        for dim in i.type.tensor_type.shape.dim:\n",
    "            shape.append(dim.dim_value)\n",
    "\n",
    "        # 从输入提取数据类型\n",
    "        if i.type.tensor_type.elem_type:\n",
    "            dtype = helper.tensor_dtype_to_np_dtype(i.type.tensor_type.elem_type)\n",
    "        else:\n",
    "            dtype = \"float32\"\n",
    "\n",
    "        # 为每个输入生成随机输入。\n",
    "        if dtype == \"bool\":\n",
    "            # random_value = np.random.choice(a=[False, True], size=shape)\n",
    "            random_value = rg.choice(a=[False, True], size=shape)\n",
    "        else:\n",
    "            # random_value = np.random.normal(size=shape).astype(dtype)\n",
    "            random_value = rg.standard_normal(size=shape).astype(dtype)\n",
    "        input_values[i.name] = random_value\n",
    "    return input_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "检查一致性："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_correctness(\n",
    "    model: ModelProto, inputs: dict[str, np.ndarray]|None = None, opset: int = None\n",
    ") -> None:\n",
    "    \"\"\"通过导入器在 onnxruntime 和 TVM 上运行 ONNX 模型，并确认结果匹配。否则，将引发异常。\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model: 应该测试的输入 ONNX 模型。\n",
    "    inputs: 可选的字典，包含 ONNX 模型中每个输入的值。\n",
    "        \n",
    "    opset: 用于 onnx 导入器的 opset 版本。\n",
    "    \"\"\"\n",
    "    if opset is not None:\n",
    "        model.opset_import[0].version = opset\n",
    "\n",
    "    # 如果没有提供输入，则从 ONNX 图中提取它们并生成随机值，我们将使用这些随机值进行测试。\n",
    "    inputs = generate_random_inputs(model, inputs)\n",
    "\n",
    "    # 通过 onnx 运行模型以获得预期结果。\n",
    "    ort_session = onnxruntime.InferenceSession(\n",
    "        model.SerializeToString(), providers=[\"CPUExecutionProvider\"]\n",
    "    )\n",
    "    ort_output = ort_session.run([], inputs)\n",
    "\n",
    "    # 通过 onnx 导入器将 onnx 模型转换为 relax 格式。\n",
    "    tvm_model = from_onnx(model, opset=opset, keep_params_in_input=True)\n",
    "    # 转换为推理模式的算子。\n",
    "    tvm_model = relax.transform.DecomposeOpsForInference()(tvm_model)\n",
    "    # 将任何 relax 算子合法化为 tensorir。\n",
    "    tvm_model = relax.transform.LegalizeOps()(tvm_model)\n",
    "\n",
    "    # 将模型与参数分离。\n",
    "    tvm_model, params = relax.frontend.detach_params(tvm_model)\n",
    "    # 将 relax graph 编译成 VM，然后运行。\n",
    "    with tvm.transform.PassContext(opt_level=3):\n",
    "        ex = relax.build(tvm_model, target=\"llvm\")\n",
    "        vm = relax.VirtualMachine(ex, tvm.cpu())\n",
    "    # 准备输入\n",
    "    input_list = [\n",
    "        inputs[key.name_hint] for key in tvm_model[\"main\"].params if key.name_hint in inputs\n",
    "    ]\n",
    "    if params:\n",
    "        input_list += params[\"main\"]\n",
    "\n",
    "    # 运行模型并检查输出。\n",
    "    vm.set_input(\"main\", *input_list)\n",
    "    vm.invoke_stateful(\"main\")\n",
    "    tvm_output = vm.get_outputs(\"main\")\n",
    "    # 如果只有一个输出，则将其包装为列表。\n",
    "    if isinstance(tvm_output, tvm.nd.NDArray):\n",
    "        tvm_output = [tvm_output]\n",
    "    # 如果输出是 shape tuple，则将其转换为 ndarray 以进行比较。\n",
    "    if isinstance(tvm_output, tvm.runtime.ShapeTuple):\n",
    "        tvm_output = [tvm.nd.array([int(i) for i in tvm_output])]\n",
    "\n",
    "    tvm_num_outputs = len(tvm_output)\n",
    "    # 形状元组需要特殊处理。\n",
    "    if isinstance(tvm_output, tvm.runtime.ShapeTuple):\n",
    "        tvm_num_outputs = 1\n",
    "\n",
    "    # 检查输出数量是否匹配。\n",
    "    assert tvm_num_outputs == len(ort_output), \"Unequal number of outputs\"\n",
    "\n",
    "    for (tvm_out, ort_out) in zip(tvm_output, ort_output):\n",
    "        # TODO 允许可配置的容差值。\n",
    "        # 有时 None 被用于表示未使用的输出。\n",
    "        if ort_out is not None:\n",
    "            np.testing.assert_allclose(tvm_out.numpy(), ort_out, atol=1e-5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 算子测试\n",
    "\n",
    "### `sanitize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/pc/data/tmp/cache/conda/envs/tvmx/lib/python3.10/site-packages/tvm/relax/frontend/onnx/onnx_frontend.py:1899: UserWarning: Renaming name . to _\n",
      "  warnings.warn((\"Renaming name %s to %s\" % (name, new_name)))\n",
      "/media/pc/data/tmp/cache/conda/envs/tvmx/lib/python3.10/site-packages/tvm/relax/frontend/onnx/onnx_frontend.py:1899: UserWarning: Renaming name 123 to input_123\n",
      "  warnings.warn((\"Renaming name %s to %s\" % (name, new_name)))\n",
      "/media/pc/data/tmp/cache/conda/envs/tvmx/lib/python3.10/site-packages/tvm/relax/frontend/onnx/onnx_frontend.py:1899: UserWarning: Renaming name _ to __1\n",
      "  warnings.warn((\"Renaming name %s to %s\" % (name, new_name)))\n",
      "/media/pc/data/tmp/cache/conda/envs/tvmx/lib/python3.10/site-packages/tvm/relax/frontend/onnx/onnx_frontend.py:1899: UserWarning: Renaming name input_123 to input_123_1\n",
      "  warnings.warn((\"Renaming name %s to %s\" % (name, new_name)))\n"
     ]
    }
   ],
   "source": [
    "workloads = [\n",
    "    ([\".\", \"123\"], [\"_\", \"input_123\"]),\n",
    "    ([\".\", \"_\"], [\"_\", \"__1\"]),\n",
    "    ([\"123\", \"input_123\"], [\"input_123\", \"input_123_1\"]),\n",
    "]\n",
    "for input_names, expected_names in workloads:\n",
    "    node = helper.make_node(\"Add\", inputs=input_names, outputs=[\"output\"])\n",
    "    graph = helper.make_graph(\n",
    "        [node],\n",
    "        \"test\",\n",
    "        inputs=[\n",
    "            helper.make_tensor_value_info(str(var), TensorProto.FLOAT, [32, 32])\n",
    "            for var in input_names\n",
    "        ],\n",
    "        outputs=[\n",
    "            helper.make_tensor_value_info(\"output\", TensorProto.FLOAT, [32, 32]),\n",
    "        ],\n",
    "    )\n",
    "    model = helper.make_model(graph, producer_name=\"test_sanitizer\")\n",
    "\n",
    "    tvm_model = from_onnx(model)\n",
    "\n",
    "    for i, param in enumerate(tvm_model[\"main\"].params):\n",
    "        assert param.name_hint == expected_names[i]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 辅助函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_unary(op_name, shape, attrs={}, domain=None):\n",
    "    test_node = helper.make_node(op_name, [\"x\"], [\"y\"], **attrs, domain=domain)\n",
    "    graph = helper.make_graph(\n",
    "        [test_node],\n",
    "        \"elemwise_test\",\n",
    "        inputs=[\n",
    "            helper.make_tensor_value_info(\"x\", TensorProto.FLOAT, shape),\n",
    "        ],\n",
    "        outputs=[helper.make_tensor_value_info(\"y\", TensorProto.FLOAT, shape)],\n",
    "    )\n",
    "\n",
    "    model = helper.make_model(graph, producer_name=\"elemwise_test\")\n",
    "    check_correctness(model)\n",
    "\n",
    "\n",
    "def verify_binary(op_name, shape_a, shape_b, shape_c, attrs={}, domain=None):\n",
    "    test_node = helper.make_node(op_name, [\"a\", \"b\"], [\"c\"], **attrs, domain=domain)\n",
    "    graph = helper.make_graph(\n",
    "        [test_node],\n",
    "        \"binary_test\",\n",
    "        inputs=[\n",
    "            helper.make_tensor_value_info(\"a\", TensorProto.FLOAT, shape_a),\n",
    "            helper.make_tensor_value_info(\"b\", TensorProto.FLOAT, shape_b),\n",
    "        ],\n",
    "        outputs=[helper.make_tensor_value_info(\"c\", TensorProto.FLOAT, shape_c)],\n",
    "    )\n",
    "\n",
    "    model = helper.make_model(graph, producer_name=\"binary_test\")\n",
    "    check_correctness(model)\n",
    "\n",
    "\n",
    "def verify_compare(op_name, shape, attrs={}, domain=None):\n",
    "    test_node = helper.make_node(op_name, [\"a\", \"b\"], [\"c\"], **attrs, domain=domain)\n",
    "    graph = helper.make_graph(\n",
    "        [test_node],\n",
    "        \"compare_test\",\n",
    "        inputs=[\n",
    "            helper.make_tensor_value_info(\"a\", TensorProto.FLOAT, shape),\n",
    "            helper.make_tensor_value_info(\"b\", TensorProto.FLOAT, shape),\n",
    "        ],\n",
    "        outputs=[helper.make_tensor_value_info(\"c\", TensorProto.BOOL, shape)],\n",
    "    )\n",
    "\n",
    "    model = helper.make_model(graph, producer_name=\"compare_test\")\n",
    "    check_correctness(model)\n",
    "\n",
    "\n",
    "def verify_ternary(op_name, shape_a, shape_b, shape_c, shape_d, attrs={}, domain=None):\n",
    "    test_node = helper.make_node(op_name, [\"a\", \"b\", \"c\"], [\"d\"], **attrs, domain=domain)\n",
    "    graph = helper.make_graph(\n",
    "        [test_node],\n",
    "        \"ternary_test\",\n",
    "        inputs=[\n",
    "            helper.make_tensor_value_info(\"a\", TensorProto.FLOAT, shape_a),\n",
    "            helper.make_tensor_value_info(\"b\", TensorProto.FLOAT, shape_b),\n",
    "            helper.make_tensor_value_info(\"c\", TensorProto.FLOAT, shape_c),\n",
    "        ],\n",
    "        outputs=[helper.make_tensor_value_info(\"d\", TensorProto.FLOAT, shape_d)],\n",
    "    )\n",
    "\n",
    "    model = helper.make_model(graph, producer_name=\"ternary_test\")\n",
    "    check_correctness(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tvmx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
