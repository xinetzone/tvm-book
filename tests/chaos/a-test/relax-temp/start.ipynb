{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relax 快速上手"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import set_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relax\n",
    "from tvm._ffi.base import TVMError\n",
    "from tvm.script import relax as R, tir as T, ir as I"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `unique`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@I.ir_module\n",
    "class InputModule:\n",
    "    @R.function\n",
    "    def foo(x: R.Tensor((\"m\", \"n\"), \"int64\")):\n",
    "        y = R.unique(x, sorted=False)\n",
    "        y_sorted = R.unique(x)\n",
    "        return y, y_sorted\n",
    "\n",
    "def run_cpu(mod, func_name, *input):\n",
    "    target = tvm.target.Target(\"llvm\")\n",
    "    ex = relax.build(mod, target)\n",
    "    vm = relax.VirtualMachine(ex, tvm.cpu())\n",
    "    return vm[func_name](*input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_numpy = np.random.randint(0, 16, (16, 16))\n",
    "data = tvm.nd.array(data_numpy)\n",
    "result, result_sorted = run_cpu(InputModule, \"foo\", data)\n",
    "expected_output_sorted, indices = np.unique(data_numpy, return_index=True)\n",
    "expected_output = [data_numpy.flatten()[index] for index in sorted(indices, reverse=True)]\n",
    "np.testing.assert_array_equal(expected_output_sorted, result_sorted.numpy())\n",
    "np.testing.assert_array_equal(expected_output, result.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 其他测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@tvm.script.ir_module\n",
    "class PrintTest:\n",
    "    @R.function(pure=False)\n",
    "    def foo(x: R.Tensor((), \"int32\")):\n",
    "        # results have to be bound, but we don't use them\n",
    "        # TODO: We should allow calls whose results are not bound for side effects;\n",
    "        #       it would be easy syntactic sugar to add.\n",
    "        p1 = R.print(x)\n",
    "        p2 = R.print(x, format=\"Number: {}\")\n",
    "        t = (x, x)\n",
    "        p3 = R.print(t, format=\"Tuple: {}\")\n",
    "        p4 = R.print(x, t)\n",
    "        p5 = R.print(x, x, format=\"Custom print: {} {}\")\n",
    "        p6 = R.print(x, t, format=\"Another print: {} {}\")\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_print():\n",
    "    try:\n",
    "        stdout = sys.stdout\n",
    "        with tempfile.TemporaryFile(mode=\"w+\") as test_out:\n",
    "            sys.stdout = test_out\n",
    "            run_cpu(PrintTest, \"foo\", tvm.nd.array(np.array(1).astype(\"int32\")))\n",
    "            test_out.seek(0)\n",
    "            printed_text = str(test_out.read())\n",
    "            expected = \"1\\nNumber: 1\\nTuple: (1, 1)\\n1 (1, 1)\\nCustom print: 1 1\\nAnother print: 1 (1, 1)\\n\"\n",
    "            assert printed_text in expected, (\"printed_text is \", printed_text)\n",
    "    finally:\n",
    "        sys.stdout = stdout\n",
    "\n",
    "\n",
    "@tvm.script.ir_module\n",
    "class AssertOpTest:\n",
    "    @R.function(pure=False)\n",
    "    def passes(x: R.Tensor((), \"int32\")):\n",
    "        p1 = R.assert_op(relax.const(True))\n",
    "        return x\n",
    "\n",
    "    @R.function(pure=False)\n",
    "    def pass_with_args(x: R.Tensor((), \"int32\")):\n",
    "        p1 = R.assert_op(relax.const(True), x, format=\"You won't see me\")\n",
    "        return x\n",
    "\n",
    "    @R.function(pure=False)\n",
    "    def simple_fail(x: R.Tensor((), \"int32\")):\n",
    "        p1 = R.assert_op(relax.const(False))\n",
    "        return x\n",
    "\n",
    "    @R.function(pure=False)\n",
    "    def fail_with_message(x: R.Tensor((), \"int32\")):\n",
    "        p1 = R.assert_op(relax.const(False), format=\"I failed...\")\n",
    "        return x\n",
    "\n",
    "    @R.function(pure=False)\n",
    "    def fail_with_args(x: R.Tensor((), \"int32\")):\n",
    "        # no format\n",
    "        p1 = R.assert_op(relax.const(False), [x, x])\n",
    "        return x\n",
    "\n",
    "    @R.function(pure=False)\n",
    "    def fail_with_formatted_message(x: R.Tensor((), \"int32\")):\n",
    "        p1 = R.assert_op(relax.const(False), x, format=\"Number: {}\")\n",
    "        return x\n",
    "\n",
    "\n",
    "def test_assert_op():\n",
    "    def check_assertion_error(func_name, func_arg, expected_message):\n",
    "        passed = False\n",
    "        try:\n",
    "            run_cpu(AssertOpTest, func_name, func_arg)\n",
    "            passed = True\n",
    "        except TVMError as e:\n",
    "            # TVM will print out a TVMError that will contain the\n",
    "            # generated error at the bottom of a stack trace\n",
    "            assert \"AssertionError\" in e.args[0]\n",
    "            assert expected_message in e.args[0]\n",
    "        assert not passed\n",
    "\n",
    "    run_cpu(AssertOpTest, \"passes\", tvm.nd.array(np.array(1).astype(\"int32\")))\n",
    "    run_cpu(AssertOpTest, \"pass_with_args\", tvm.nd.array(np.array(2).astype(\"int32\")))\n",
    "    check_assertion_error(\n",
    "        \"simple_fail\", tvm.nd.array(np.array(3).astype(\"int32\")), \"Assertion Failed\"\n",
    "    )\n",
    "    check_assertion_error(\n",
    "        \"fail_with_message\", tvm.nd.array(np.array(4).astype(\"int32\")), \"I failed...\"\n",
    "    )\n",
    "    check_assertion_error(\"fail_with_args\", tvm.nd.array(np.array(5).astype(\"int32\")), \"5, 5\")\n",
    "    check_assertion_error(\n",
    "        \"fail_with_formatted_message\", tvm.nd.array(np.array(6).astype(\"int32\")), \"Number: 6\"\n",
    "    )\n",
    "\n",
    "\n",
    "@tvm.script.ir_module\n",
    "class ShapeOfTest:\n",
    "    @R.function\n",
    "    def get_shape(t: R.Tensor(ndim=-1, dtype=\"int32\")) -> R.Shape(ndim=-1):\n",
    "        return R.shape_of(t)\n",
    "\n",
    "    @R.function\n",
    "    def get_constrained_shape(t: R.Tensor(ndim=1, dtype=\"int32\")) -> R.Shape(ndim=1):\n",
    "        # require the input tensor to have rank 1\n",
    "        return R.shape_of(t)\n",
    "\n",
    "    @R.function\n",
    "    def get_scalar_shape() -> R.Shape(()):\n",
    "        x: R.Tensor((), \"int32\") = R.const(1, dtype=\"int32\")\n",
    "        return R.shape_of(x)\n",
    "\n",
    "    @R.function\n",
    "    def get_constant_shape() -> R.Shape((2, 2)):\n",
    "        x: R.Tensor((2, 2), \"int32\") = R.const(\n",
    "            np.array([[1, 2], [3, 4]], dtype=\"int32\"), dtype=\"int32\"\n",
    "        )\n",
    "        return R.shape_of(x)\n",
    "\n",
    "\n",
    "def test_op_shape_of():\n",
    "    unit_shape = run_cpu(ShapeOfTest, \"get_scalar_shape\")\n",
    "    assert unit_shape == tvm.runtime.ShapeTuple([])\n",
    "\n",
    "    const_shape = run_cpu(ShapeOfTest, \"get_constant_shape\")\n",
    "    assert const_shape == tvm.runtime.ShapeTuple([2, 2])\n",
    "\n",
    "    scalar_shape = run_cpu(ShapeOfTest, \"get_shape\", tvm.nd.array(np.array(1, dtype=\"int32\")))\n",
    "    assert scalar_shape == tvm.runtime.ShapeTuple([])\n",
    "\n",
    "    tensor_shape = run_cpu(\n",
    "        ShapeOfTest, \"get_shape\", tvm.nd.array(np.zeros((1, 2, 3)).astype(\"int32\"))\n",
    "    )\n",
    "    assert tensor_shape == tvm.runtime.ShapeTuple([1, 2, 3])\n",
    "\n",
    "    constrained_shape = run_cpu(\n",
    "        ShapeOfTest, \"get_constrained_shape\", tvm.nd.array(np.zeros((1,)).astype(\"int32\"))\n",
    "    )\n",
    "    assert constrained_shape == tvm.runtime.ShapeTuple([1])\n",
    "\n",
    "\n",
    "@tvm.script.ir_module\n",
    "class ShapeToTensorTest:\n",
    "    @R.function\n",
    "    def const_shape(shape: R.Shape(ndim=-1)) -> R.Tensor(ndim=-1):\n",
    "        return R.shape_to_tensor(shape)\n",
    "\n",
    "    @R.function\n",
    "    def symbolic_shape(shape: R.Shape((\"m\", \"n\"))) -> R.Tensor(ndim=-1):\n",
    "        m = T.int64()\n",
    "        n = T.int64()\n",
    "        return R.shape_to_tensor(shape)\n",
    "\n",
    "\n",
    "def test_op_shape_to_tensor():\n",
    "    # Check struct info\n",
    "    isinstance(ShapeToTensorTest[\"const_shape\"].body.struct_info, tvm.relax.TensorStructInfo)\n",
    "    assert ShapeToTensorTest[\"const_shape\"].body.struct_info.ndim == 1\n",
    "    isinstance(ShapeToTensorTest[\"symbolic_shape\"].body.struct_info, tvm.relax.TensorStructInfo)\n",
    "    assert ShapeToTensorTest[\"symbolic_shape\"].body.struct_info.ndim == 1\n",
    "\n",
    "    # Check its functionality\n",
    "    out2d = run_cpu(ShapeToTensorTest, \"const_shape\", tvm.runtime.ShapeTuple([3, 2]))\n",
    "    assert isinstance(out2d, tvm.runtime.ndarray.NDArray)\n",
    "    assert np.array_equal(out2d.numpy(), np.array([3, 2]))\n",
    "\n",
    "    out3d = run_cpu(ShapeToTensorTest, \"const_shape\", tvm.runtime.ShapeTuple([3, 3, 2]))\n",
    "    assert isinstance(out3d, tvm.runtime.ndarray.NDArray)\n",
    "    assert np.array_equal(out3d.numpy(), np.array([3, 3, 2]))\n",
    "\n",
    "    out4d = run_cpu(ShapeToTensorTest, \"const_shape\", tvm.runtime.ShapeTuple([3, 3, 2, 2]))\n",
    "    assert isinstance(out4d, tvm.runtime.ndarray.NDArray)\n",
    "    assert np.array_equal(out4d.numpy(), np.array([3, 3, 2, 2]))\n",
    "\n",
    "    outs = run_cpu(ShapeToTensorTest, \"symbolic_shape\", tvm.runtime.ShapeTuple([3, 2]))\n",
    "    assert isinstance(outs, tvm.runtime.ndarray.NDArray)\n",
    "    assert np.array_equal(outs.numpy(), np.array([3, 2]))\n",
    "\n",
    "\n",
    "def test_op_call_pure_packed():\n",
    "    @tvm.script.ir_module\n",
    "    class CallPureTest:\n",
    "        @R.function\n",
    "        def pure_copy(x: R.Tensor((3, 4), \"float32\")):\n",
    "            z = R.call_pure_packed(\n",
    "                \"vm.builtin.copy\", x, sinfo_args=(R.Tensor((3, 4), dtype=\"float32\"))\n",
    "            )\n",
    "            return z\n",
    "\n",
    "    np.random.seed(0)  # to avoid flakiness\n",
    "    arr = np.random.rand(3, 4).astype(\"float32\")\n",
    "    copy_found = run_cpu(CallPureTest, \"pure_copy\", tvm.nd.array(arr))\n",
    "    assert (copy_found.numpy() == arr).all()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "34e95b0948f576614c7863cc780d83f61f9551597d4ec05ab5fbb4cfe73deb20"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
