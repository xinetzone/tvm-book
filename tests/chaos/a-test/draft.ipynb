{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TIR 入门\n",
    "\n",
    "参考：[TensorIR 的突击课程](https://daobook.github.io/tvm/docs/tutorial/tensor_ir_blitz_course.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;129m@tvm\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mscript\u001b[38;5;129;01m.\u001b[39;00mir_module\n",
      "\u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mModule\u001b[39;00m:\n",
      "    \u001b[38;5;129m@T\u001b[39m\u001b[38;5;129;01m.\u001b[39;00mprim_func\n",
      "    \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m(A: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[\u001b[38;5;28m8\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m], B: T\u001b[38;5;129;01m.\u001b[39;00mBuffer[\u001b[38;5;28m8\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;129;01m-\u001b[39;00m\u001b[38;5;129;01m>\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "        \u001b[38;5;30;03m# function attr dict\u001b[39;00m\n",
      "        T\u001b[38;5;129;01m.\u001b[39;00mfunc_attr({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mglobal_symbol\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtir.noalias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m})\n",
      "        \u001b[38;5;30;03m# body\u001b[39;00m\n",
      "        \u001b[38;5;30;03m# with T.block(\"root\")\u001b[39;00m\n",
      "        \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;28;01min\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mserial(\u001b[38;5;28m8\u001b[39m):\n",
      "            \u001b[38;5;28;01mwith\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mblock(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "                vi \u001b[38;5;129;01m=\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00maxis\u001b[38;5;129;01m.\u001b[39;00mspatial(\u001b[38;5;28m8\u001b[39m, i)\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mreads(A[vi])\n",
      "                T\u001b[38;5;129;01m.\u001b[39;00mwrites(B[vi])\n",
      "                B[vi] \u001b[38;5;129;01m=\u001b[39;00m A[vi] \u001b[38;5;129;01m+\u001b[39;00m T\u001b[38;5;129;01m.\u001b[39;00mfloat32(\u001b[38;5;28m1\u001b[39m)\n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tvm\n",
    "from tvm.ir.module import IRModule\n",
    "from tvm.script import tir as T\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "@tvm.script.ir_module\n",
    "class MyModule:\n",
    "    @T.prim_func\n",
    "    def main(a: T.handle, b: T.handle):\n",
    "        # 通过句柄在函数之间交换数据，这类似于指针。\n",
    "        T.func_attr({\"global_symbol\": \"main\", \"tir.noalias\": True})\n",
    "        # 从句柄创建缓冲区。\n",
    "        A = T.match_buffer(a, (8,), dtype=\"float32\")\n",
    "        B = T.match_buffer(b, (8,), dtype=\"float32\")\n",
    "        for i in range(8):\n",
    "            # 块是计算的抽象。\n",
    "            with T.block(\"B\"):\n",
    "                # 定义空间块迭代器，并将其绑定到值 i。\n",
    "                vi = T.axis.spatial(8, i)\n",
    "                B[vi] = A[vi] + 1.0\n",
    "\n",
    "\n",
    "ir_module = MyModule\n",
    "ir_module.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'tvm.relax' from '/media/pc/data/4tb/lxw/libs/anaconda3/envs/py38/lib/python3.8/site-packages/tvm/relax/__init__.py'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvm.relax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `@tvm.script.ir_module`：表示被其 annotate 的类别 MyModule，就是一个待编译的 IRModule\n",
    "- `@T.prim_func`：表示被其 annotate 的成员函数 main，就是 IRModule 的一个 PrimFunc\n",
    "\n",
    "`script` 中 `T.*` 的部分，就对应着 AST 中的树节点。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "编译："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# mod = tvm.build(ir_module, target=\"c\")\n",
    "mod = tvm.build(ir_module, target=\"llvm\")\n",
    "# mod = tvm.build(ir_module, target=\"cuda\")\n",
    "\n",
    "a = tvm.nd.array(np.arange(8).astype(\"float32\"))\n",
    "print(a)\n",
    "# [0. 1. 2. 3. 4. 5. 6. 7.]\n",
    "\n",
    "b = tvm.nd.array(np.zeros((8,)).astype(\"float32\"))\n",
    "mod(a, b)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tvm.build` 的最后一个参数 `target`，就是用来选择用哪一个 CodeGen 来编译 TIR AST。\n",
    "\n",
    "例如，如果要编译为 CPU 运行的代码，那么参数可以是 `target=\"c\"`，也可以是 `target=\"llvm\"`；如果要编译为 GPU 运行的代码，那么参数是 `target=\"cuda\"`。\n",
    "\n",
    "`tvm.build` 会根据 `target` 参数，寻找已经注册的编译函数。在 TVM 中，用宏定义 `TVM_REGISTER_GLOBAL` 注册编译函数：\n",
    "\n",
    "```c++\n",
    "// src/target/source/codegen_c_host.cc\n",
    "TVM_REGISTER_GLOBAL(\"target.build.c\").set_body_typed(BuildCHost);\n",
    "\n",
    "// src/target/opt/build_cuda_on.cc\n",
    "TVM_REGISTER_GLOBAL(\"target.build.cuda\").set_body_typed(BuildCUDA);\n",
    "\n",
    "// src/target/llvm/llvm_module.cc\n",
    "TVM_REGISTER_GLOBAL(\"target.build.llvm\")\n",
    "    .set_body_typed([](IRModule mod, Target target) -> runtime::Module {\n",
    "      auto n = make_object<LLVMModuleNode>();\n",
    "      n->Init(mod, target);\n",
    "      return runtime::Module(n);\n",
    "    })\n",
    "```\n",
    "\n",
    "对于 C++ 和 CUDA，`tvm.build` 有两个步骤：\n",
    "\n",
    "```\n",
    "TIR -> C++/CUDA -> bin\n",
    "```\n",
    "\n",
    "先通过相应的 CodeGen，生成源代码；然后调用相应的编译器，生成可执行文件并且打包为 runtime。\n",
    "\n",
    "如果 `target=\"llvm\"`，由于 LLVM IR 仍然只是一种中间表示，还需要根据 `target` 当中更详细的硬件参数，找到目标编译硬件，然后调用相应的 CodeGen（省略部分辅助代码）：\n",
    "\n",
    "```c++\n",
    "void Init(const IRModule& mod, const Target& target) {\n",
    "  // Step 1: Initialize CodeGen for LLVM with different target\n",
    "  InitializeLLVM();\n",
    "  tm_ = GetLLVMTargetMachine(target);\n",
    "  std::unique_ptr<CodeGenLLVM> cg = CodeGenLLVM::Create(tm_.get());\n",
    "\n",
    "  // Step 2: Add all tir::PrimFunc in IRModule to compile list\n",
    "  std::vector<PrimFunc> funcs;\n",
    "  for (auto kv : mod->functions) {\n",
    "    if (!kv.second->IsInstance<PrimFuncNode>()) {\n",
    "      // (@jroesch): we relax constraints here, Relay functions will just be ignored.\n",
    "      DLOG(INFO) << \"Can only lower IR Module with PrimFuncs, but got \"\n",
    "                  << kv.second->GetTypeKey();\n",
    "      continue;\n",
    "    }\n",
    "    auto f = Downcast<PrimFunc>(kv.second);\n",
    "    funcs.push_back(f);\n",
    "  }\n",
    "\n",
    "  // Step 3: Lower IRModule to LLVM IR code\n",
    "  module_ = cg->Finish();\n",
    "}\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此外，还可以使用张量表达式 DSL（domain-specific language）来编写简单的算子，并将其转换为 IRModule。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm import te\n",
    "\n",
    "A = te.placeholder((8,), dtype=\"float32\", name=\"A\")\n",
    "B = te.compute((8,), lambda *i: A(*i) + 1.0, name=\"B\")\n",
    "func = te.create_prim_func([A, B])\n",
    "ir_module_from_te = IRModule({\"main\": func})\n",
    "ir_module_from_te.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TIR 能 lower 成目标源代码，关键是 CodeGen。上面提到的 CodeGenCHost，以及 CodeGenCUDA，都是继承自 CodeGenC，即将 TIR lower 为 C++ 代码。\n",
    "\n",
    "因为 TIR AST 是 Graph 结构（Tree 也是一种特殊的树），因此 CodeGenC 根本上是一个 Graph 遍历器。当 CodeGenC 遍历到某个 TIR Node 的时候，根据 TIR Node 的类型和属性，翻译为相应的 C++ 代码。下面是 CodeGenC 的部分定义，位于 `tvm/src/target/source/codegen_c.[h, cc]` 中：\n",
    "\n",
    "```c++\n",
    "class CodeGenC : public ExprFunctor<void(const PrimExpr&, std::ostream&)>,\n",
    "                 public StmtFunctor<void(const Stmt&)>,\n",
    "                 public CodeGenSourceBase {\n",
    " public:\n",
    "  // expression\n",
    "  void VisitExpr_(const VarNode* op, std::ostream& os) override;         // NOLINT(*)\n",
    "  void VisitExpr_(const LoadNode* op, std::ostream& os) override;        // NOLINT(*)\n",
    "  void VisitExpr_(const BufferLoadNode* op, std::ostream& os) override;  // NOLINT(*)\n",
    "  void VisitExpr_(const LetNode* op, std::ostream& os) override;         // NOLINT(*)\n",
    "  void VisitExpr_(const CallNode* op, std::ostream& os) override;        // NOLINT(*)\n",
    "  void VisitExpr_(const AddNode* op, std::ostream& os) override;         // NOLINT(*)\n",
    "  void VisitExpr_(const SubNode* op, std::ostream& os) override;         // NOLINT(*)\n",
    "  void VisitExpr_(const MulNode* op, std::ostream& os) override;         // NOLINT(*)\n",
    "  void VisitExpr_(const DivNode* op, std::ostream& os) override;         // NOLINT(*)\n",
    "  void VisitExpr_(const ModNode* op, std::ostream& os) override;         // NOLINT(*)\n",
    "  void VisitExpr_(const MinNode* op, std::ostream& os) override;         // NOLINT(*)\n",
    "  void VisitExpr_(const MaxNode* op, std::ostream& os) override;         // NOLINT(*)\n",
    "  void VisitExpr_(const EQNode* op, std::ostream& os) override;          // NOLINT(*)\n",
    "  void VisitExpr_(const NENode* op, std::ostream& os) override;          // NOLINT(*)\n",
    "  void VisitExpr_(const LTNode* op, std::ostream& os) override;          // NOLINT(*)\n",
    "  void VisitExpr_(const LENode* op, std::ostream& os) override;          // NOLINT(*)\n",
    "  void VisitExpr_(const GTNode* op, std::ostream& os) override;          // NOLINT(*)\n",
    "  void VisitExpr_(const GENode* op, std::ostream& os) override;          // NOLINT(*)\n",
    "  void VisitExpr_(const AndNode* op, std::ostream& os) override;         // NOLINT(*)\n",
    "  void VisitExpr_(const OrNode* op, std::ostream& os) override;          // NOLINT(*)\n",
    "  void VisitExpr_(const CastNode* op, std::ostream& os) override;        // NOLINT(*)\n",
    "  void VisitExpr_(const NotNode* op, std::ostream& os) override;         // NOLINT(*)\n",
    "  void VisitExpr_(const SelectNode* op, std::ostream& os) override;      // NOLINT(*)\n",
    "  void VisitExpr_(const RampNode* op, std::ostream& os) override;        // NOLINT(*)\n",
    "  void VisitExpr_(const ShuffleNode* op, std::ostream& os) override;     // NOLINT(*)\n",
    "  void VisitExpr_(const BroadcastNode* op, std::ostream& os) override;   // NOLINT(*)\n",
    "  void VisitExpr_(const IntImmNode* op, std::ostream& os) override;      // NOLINT(*)\n",
    "  void VisitExpr_(const FloatImmNode* op, std::ostream& os) override;    // NOLINT(*)\n",
    "  void VisitExpr_(const StringImmNode* op, std::ostream& os) override;   // NOLINT(*)\n",
    "  // statment\n",
    "  void VisitStmt_(const LetStmtNode* op) override;\n",
    "  void VisitStmt_(const StoreNode* op) override;\n",
    "  void VisitStmt_(const BufferStoreNode* op) override;\n",
    "  void VisitStmt_(const ForNode* op) override;\n",
    "  void VisitStmt_(const WhileNode* op) override;\n",
    "  void VisitStmt_(const IfThenElseNode* op) override;\n",
    "  void VisitStmt_(const AllocateNode* op) override;\n",
    "  void VisitStmt_(const AttrStmtNode* op) override;\n",
    "  void VisitStmt_(const AssertStmtNode* op) override;\n",
    "  void VisitStmt_(const EvaluateNode* op) override;\n",
    "  void VisitStmt_(const SeqStmtNode* op) override;\n",
    "  void VisitStmt_(const AllocateConstNode* op) override;\n",
    "}\n",
    "```\n",
    "\n",
    "可以看到，CodeGenC 会遍历到两种 TIR Node：Expression（表达式） 和 Statement（语句）。Expression（表达式）中包含了常见的变量声明、运算、判断、函数调用，而 Statement（语句）中包含了控制流（if-else，Loop 等）、内存管理、赋值等操作。\n",
    "\n",
    "例如，遇到四则运算的 Expression，CodeGenC 直接翻译为 \" a OP b \"的代码：\n",
    "\n",
    "```c++\n",
    "template <typename T>\n",
    "inline void PrintBinaryExpr(const T* op, const char* opstr,\n",
    "                            std::ostream& os, CodeGenC* p) {\n",
    "  // If both a and b are scalars\n",
    "  if (op->dtype.lanes() == 1) {\n",
    "    // If OP is an alphabet string, then lower it as \"OP(a, b)\"\n",
    "    if (isalpha(opstr[0])) {\n",
    "      os << opstr << '(';\n",
    "      p->PrintExpr(op->a, os);\n",
    "      os << \", \";\n",
    "      p->PrintExpr(op->b, os);\n",
    "      os << ')';\n",
    "    }\n",
    "    // If OP is a symbol, like + - * / %, then lower it as \"a OP b\"\n",
    "    else {\n",
    "      os << '(';\n",
    "      p->PrintExpr(op->a, os);\n",
    "      os << ' ' << opstr << ' ';\n",
    "      p->PrintExpr(op->b, os);\n",
    "      os << ')';\n",
    "    }\n",
    "  }\n",
    "  // If both a and b are vectors\n",
    "  else {\n",
    "    p->PrintVecBinaryOp(opstr, op->dtype, op->a, op->b, os);\n",
    "  }\n",
    "}\n",
    "\n",
    "void CodeGenC::VisitExpr_(const AddNode* op, std::ostream& os) {  // NOLINT(*)\n",
    "  PrintBinaryExpr(op, \"+\", os, this);\n",
    "}\n",
    "void CodeGenC::VisitExpr_(const SubNode* op, std::ostream& os) {  // NOLINT(*)\n",
    "  PrintBinaryExpr(op, \"-\", os, this);\n",
    "}\n",
    "void CodeGenC::VisitExpr_(const MulNode* op, std::ostream& os) {  // NOLINT(*)\n",
    "  PrintBinaryExpr(op, \"*\", os, this);\n",
    "}\n",
    "void CodeGenC::VisitExpr_(const DivNode* op, std::ostream& os) {  // NOLINT(*)\n",
    "  PrintBinaryExpr(op, \"/\", os, this);\n",
    "}\n",
    "```\n",
    "\n",
    "如果遇到选择 SelectNode，CodeGenC 则翻译为 \"(c ? a : b)\" 的代码：\n",
    "\n",
    "```c++\n",
    "void CodeGenC::VisitExpr_(const SelectNode* op, std::ostream& os) {\n",
    "  os << \"(\";\n",
    "  PrintExpr(op->condition, os);\n",
    "  os << \" ? \";\n",
    "  PrintExpr(op->true_value, os);\n",
    "  os << \" : \";\n",
    "  PrintExpr(op->false_value, os);\n",
    "  os << \")\";\n",
    "}\n",
    "```\n",
    "\n",
    "如果遇到 ForNode，CodeGenC 则翻译为\n",
    "\n",
    "```\n",
    "for (DTYPE VID = 0; VID < EXTEND; ++VID) {\n",
    "BODY\n",
    "}\\n\n",
    "```\n",
    "\n",
    "的代码：\n",
    "\n",
    "```c++\n",
    "void CodeGenC::VisitStmt_(const ForNode* op) {\n",
    "  std::string extent = PrintExpr(op->extent);\n",
    "  PrintIndent();\n",
    "  std::string vid = AllocVarID(op->loop_var.get());\n",
    "  ICHECK(is_zero(op->min));\n",
    "  stream << \"for (\";\n",
    "  PrintType(op->loop_var.dtype(), stream);\n",
    "  stream << ' ' << vid << \" = 0; \" << vid << \" < \" << extent << \"; ++\" << vid << \") {\\n\";\n",
    "  int for_scope = BeginScope();\n",
    "  PrintStmt(op->body);\n",
    "  this->EndScope(for_scope);\n",
    "  PrintIndent();\n",
    "  stream << \"}\\n\";\n",
    "}\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28558e8daad512806f5c536a1a04c119185f99f65b79002708a12162d02a79c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
