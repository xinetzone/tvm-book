{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 0
   },
   "source": [
    "(ch_remote)=\n",
    "# 在远程计算机上运行\n",
    "\n",
    "将在各种硬件平台上运行和优化程序。一种方法是使用所需的硬件登录到计算机，安装所需的包，然后在那里运行工作负载。然而，这使得维护源代码和数据变得困难，特别是当目标硬件的功耗最小时。在本节中，我们将描述另一种解决方案：在远程机器上运行守护进程，然后将编译后的模块和输入数据发送给它以供执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "1"
    },
    "origin_pos": 1,
    "tab": [
     "tvm"
    ]
   },
   "outputs": [],
   "source": [
    "from tvm_book.contrib import d2ltvm\n",
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import te, rpc, relay\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "注意，从 TVM 导入 `rpc` 模块。[RPC](https://en.wikipedia.org/wiki/Remote_procedure_call)，即远程过程调用（remote procedure call），允许在远程位置上执行程序。\n",
    "\n",
    "## 设置远程计算机\n",
    "\n",
    "需要在远程机器上安装 TVM `runtime` 模块。安装设置几乎与 TVM 相同（请参阅 {ref}`ch_install`），但只需要构建运行时，即 `make runtime`，而不是整个 TVM 库。运行时大小通常小于 1MB，这使得它适用于具有内存限制的设备。如有必要，还需要启用适当的后端，例如 `CUDA` 或 `OpenCL`。\n",
    "\n",
    "一旦安装了运行时，就可以通过在远程机器上运行以下命令来启动 daemon。\n",
    "\n",
    "```bash\n",
    "python -m tvm.exec.rpc_server --host 0.0.0.0 --port=9090\n",
    "```\n",
    "\n",
    "它将启动 RPC 服务器，该服务器绑定本地 9090 端口进行侦听。应该看到以下输出，表明服务器已经启动。\n",
    "\n",
    "```bash\n",
    "INFO:RPCServer:bind to 0.0.0.0:9090\n",
    "```\n",
    "\n",
    "此外，需要在远程机器上检查两件事情。\n",
    "\n",
    "- 一个是远程机器的 IP。在 Linux 或 macOS 上，你可以通过 `ifconfig  | grep inet` 获取它。如果有防火墙，也要记得打开 9090 端口。\n",
    "- 另一个是目标架构。这对于 GPU 来说很简单，我们稍后会讨论它。对于 CPU，最简单的方法是在远程机器上安装 LLVM，然后检查 `llvm-config --host-target`。我们所使用的远程机器的返回值是 `x86_64-pc-linux-gnu`。"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 2
   },
   "source": [
    "此 target 三元组具有一般格式 `<arch><sub>-<vendor>-<sys>-<abi>`，这里\n",
    "\n",
    "- arch: x86, x86_64, arm, thumb, mips, etc.\n",
    "- sub: for ARM, there are v5, v6m, v7a, v7m, v8, etc.\n",
    "- vendor: pc, apple, nvidia, ibm, etc.\n",
    "- sys: linux, win32, darwin, cuda, none, unknown, etc.\n",
    "- abi: eabi, gnu, android, macho, elf, etc.\n",
    "\n",
    "例如，`x86_64-apple-darwin17.7.0` 即 MacbookPro，而 `armv6k-unknown-linux-gnueabihf` 指的是 Raspberry Pi 4B.\n",
    "\n",
    "\n",
    "## 编译远程计算机的程序\n",
    "\n",
    "在远程机器上运行 {ref}`ch_vector_add_te`。注意，通过 LLVM 的 `-target` 参数指定了远程机器目标。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_demo = True\n",
    "\n",
    "n = 100\n",
    "args = d2ltvm.vector_add(n)\n",
    "\n",
    "if local_demo:\n",
    "    target = \"llvm\"\n",
    "else:\n",
    "    target = \"llvm -target=x86_64-linux-gnu\"\n",
    "s = te.create_schedule(args[-1].op)\n",
    "rt_mod = tvm.build(s, args, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{note}\n",
    "在这里使用 `'llvm'` 来使这个教程可以在网页构建服务器上运行。要在真正的远程设备上运行本教程，请将 `local_demo` 改为 `False`，并将 `target` 改为适合你设备的目标。\n",
    "```\n",
    "\n",
    "然后将编译后的模块保存到磁盘，稍后将其上传到远程计算机。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm.contrib.utils import TempDirectory\n",
    "\n",
    "\n",
    "class TempModule(TempDirectory):\n",
    "    \"\"\"Create temp dir which deletes the contents when exit.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    custom_path : str, optional\n",
    "        Manually specify the exact temp dir path\n",
    "\n",
    "    keep_for_debug : bool\n",
    "        Keep temp directory for debugging purposes\n",
    "    Returns\n",
    "    -------\n",
    "    temp : TempDirectory\n",
    "        The temp directory object\n",
    "    \"\"\"\n",
    "    def export_library(self, module, filename, *args, **kwargs):\n",
    "        \"\"\"将该 module 保存在本地临时文件夹中\n",
    "        \"\"\"\n",
    "        path = self.relpath(filename)\n",
    "        module.export_library(path, *args, **kwargs)\n",
    "        return path\n",
    "\n",
    "    def upload(self, remote, module, filename):\n",
    "        \"\"\"将 module 上传至 remote 并返回远程模块\"\"\"\n",
    "        path = self.export_library(module, filename)\n",
    "        remote.upload(path)\n",
    "        # remote_module\n",
    "        return remote.load_module(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    },
    "origin_pos": 5,
    "tab": [
     "tvm"
    ]
   },
   "outputs": [],
   "source": [
    "temp_module = TempModule()\n",
    "mod_fname = 'vector-add.tar'\n",
    "mod_path = temp_module.export_library(rt_mod, mod_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 6
   },
   "source": [
    "## 在远程计算机上评估\n",
    "\n",
    "使用之前检查的 IP 连接到远程机器。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if local_demo:\n",
    "    remote = rpc.LocalSession()\n",
    "else:\n",
    "    # 将其改为你的目标设备的 IP 地址\n",
    "    host = \"10.77.1.162\"\n",
    "    port = 9090\n",
    "    remote = rpc.connect(host, port)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 8
   },
   "source": [
    "将编译好的库上传至远程机器，并将其加载到远程机器的内存中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "5"
    },
    "origin_pos": 9,
    "tab": [
     "tvm"
    ]
   },
   "outputs": [],
   "source": [
    "remote.upload(mod_path)\n",
    "remote_mod = remote.load_module(mod_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在 `remote_mod` 是远程模块对象。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 10
   },
   "source": [
    "在创建数据时，将设备上下文指定为远程机器上的 CPU。与之前一样，数据将在本地机器上创建，但稍后将发送到远程机器。注意，使用 NumPy 创建数据，但是不需要让远程机器也安装 NumPy。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "19"
    },
    "origin_pos": 11,
    "tab": [
     "tvm"
    ]
   },
   "outputs": [],
   "source": [
    "ctx = remote.cpu()\n",
    "a, b, c = d2ltvm.get_abc(n, lambda x: tvm.nd.array(x, ctx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 12
   },
   "source": [
    "由于数据和库在远程机器上都已经准备好了，让我们也在其上执行程序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "26"
    },
    "origin_pos": 13,
    "tab": [
     "tvm"
    ]
   },
   "outputs": [],
   "source": [
    "remote_mod(a, b, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 14
   },
   "source": [
    "最后，`.numpy` 方法将数据发送回本地机器，并转换为 NumPy 数组。所以可以像之前一样验证结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "origin_pos": 15,
    "tab": [
     "tvm"
    ]
   },
   "outputs": [],
   "source": [
    "np.testing.assert_equal(a.asnumpy()+b.asnumpy(), c.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 16
   },
   "source": [
    "## 运行神经网络推理\n",
    "\n",
    "在远程机器上运行 {mod}`ch_from_mxnet` 中使用的 ResNet-18。和前面一样，加载样本图像和 Imagenet 1K 标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "9"
    },
    "origin_pos": 17,
    "tab": [
     "tvm"
    ]
   },
   "outputs": [],
   "source": [
    "image = Image.open('../data/cat.jpg').resize((224, 224))\n",
    "x = d2ltvm.image_preprocessing(image)\n",
    "with open('../data/imagenet1k_labels.txt') as f:\n",
    "    labels = eval(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 18
   },
   "source": [
    "然后，变换、编译和保存模块。注意，只需要将包含编译的算子共享库保存到磁盘。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "10"
    },
    "origin_pos": 19,
    "tab": [
     "tvm"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/workspace/anaconda3/envs/mxnetx/lib/python3.10/site-packages/tvm/driver/build_module.py:263: UserWarning: target_host parameter is going to be deprecated. Please pass in tvm.target.Target(target, host=target_host) instead.\n",
      "  warnings.warn(\n",
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
     ]
    }
   ],
   "source": [
    "from mxnet.gluon.model_zoo.vision import get_model\n",
    "\n",
    "mod_fname = 'resnet18.tar'\n",
    "model = get_model(\"resnet18_v2\", pretrained=True)\n",
    "relay_mod, relay_params = relay.frontend.from_mxnet(model, {'data': x.shape})\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    rt_mod = relay.build(relay_mod, target, params=relay_params)\n",
    "mod_path = temp_module.export_library(rt_mod, mod_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 20
   },
   "source": [
    "接下来，将保存的库上传到远程机器，并将其加载到内存中。然后，可以使用模型定义、远程库和远程上下文创建运行时。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "14"
    },
    "origin_pos": 21,
    "tab": [
     "tvm"
    ]
   },
   "outputs": [],
   "source": [
    "from tvm.contrib import graph_executor\n",
    "\n",
    "remote.upload(mod_path)\n",
    "remote_mod = remote.load_module(mod_fname)\n",
    "remote_fuc = remote_mod[\"default\"]\n",
    "remote_rt =  graph_executor.GraphModule(remote_fuc(ctx))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 22
   },
   "source": [
    "其中参数和输入都在本地机器上。运行时将正确地将它们 upload 到远程计算机。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "15"
    },
    "origin_pos": 23,
    "tab": [
     "tvm"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tiger cat', 'Egyptian cat')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_rt.run(data=tvm.nd.array(x))\n",
    "scores = remote_rt.get_output(0).asnumpy()[0]\n",
    "scores.shape\n",
    "a = np.argsort(scores)[-1:-5:-1]\n",
    "labels[a[0]], labels[a[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "origin_pos": 24
   },
   "source": [
    "## 小结\n",
    "\n",
    "- 可以在远程机器上安装 TVM 运行时来启动 RPC 服务器，以接受要运行的工作负载。\n",
    "- 通过指定远程机器的 architecture target（称为交叉编译（cross-compilation）），可以在本地编译程序，然后通过 RPC 在远程机器上运行。\n",
    "\n",
    "## [讨论](https://discuss.tvm.ai/t/getting-started-running-on-a-remote-machine/4709)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Nov 24 2022, 14:13:03) [GCC 11.2.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "d0d307675f12182d62ca143bf4e5db321e57c24ab1edf40ce60a9751b29adda0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
