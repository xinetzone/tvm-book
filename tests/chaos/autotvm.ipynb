{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relay 下的 AutoTVM\n",
    "\n",
    "参考：[autotvm_relay](https://daobook.github.io/tvm/docs/tutorial/autotvm_relay_x86.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tvm\n",
    "from tvm import relay\n",
    "from tvm.contrib.download import download_testdata\n",
    "from tvm.contrib import graph_executor\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载前端模型和数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "\n",
    "def get_model(model_name = \"resnet50\", pretrained=True):\n",
    "    model = getattr(models, model_name)(pretrained=pretrained)\n",
    "    return model\n",
    "\n",
    "torch_model = get_model(\"resnet50\", pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载图片："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = \"https://s3.amazonaws.com/model-server/inputs/kitten.jpg\"\n",
    "img_path = download_testdata(img_url, \"imagenet_cat.png\", module=\"data\")\n",
    "\n",
    "# resize 到 224x224\n",
    "with Image.open(img_path) as im:\n",
    "    resized_image = im.resize((224, 224))\n",
    "\n",
    "# 转换为 float32\n",
    "img_data = np.asarray(resized_image).astype(\"float32\")\n",
    "\n",
    "# 输入图像是在 HWC 布局，而 MXNet 期望 CHW 输入\n",
    "img_data = np.transpose(img_data, (2, 0, 1))\n",
    "\n",
    "# 根据 ImageNet 输入规范进行 Normalize\n",
    "imagenet_mean = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))\n",
    "imagenet_stddev = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))\n",
    "norm_img_data = (img_data / 255 - imagenet_mean) / imagenet_stddev\n",
    "\n",
    "# 添加批处理维度，设置数据为 4 维 输入：NCHW\n",
    "img_data = np.expand_dims(norm_img_data, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前端模型转换为 Relay 表示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tvm.relay.frontend.pytorch import from_pytorch\n",
    "\n",
    "dshape = 1, 3, 224, 224\n",
    "model = get_model().eval()\n",
    "random_input = torch.randn(dshape)\n",
    "trace_module = torch.jit.trace(model, random_input).eval()\n",
    "mod, params = from_pytorch(trace_module, [(\"data\", dshape)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编译"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "One or more operators have not been tuned. Please tune your model for better performance. Use DEBUG logging level to see more details.\n"
     ]
    }
   ],
   "source": [
    "target = \"llvm\"\n",
    "\n",
    "with tvm.transform.PassContext(opt_level=3):\n",
    "    lib = relay.build(mod, target=target, params=params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 运行时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = tvm.device(str(target), 0)\n",
    "module = graph_executor.GraphModule(lib[\"default\"](dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行时推理："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dtype = \"float32\"\n",
    "input_name = \"data\"\n",
    "module.set_input(input_name, img_data)\n",
    "module.run()\n",
    "output_shape = (1, 1000)\n",
    "tvm_output = module.get_output(0).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 性能评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean': 73.69392811204307, 'median': 77.21288839820772, 'std': 11.900445828441978}\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "timing_number = 10\n",
    "timing_repeat = 10\n",
    "unoptimized = (\n",
    "    np.array(timeit.Timer(lambda: module.run()).repeat(repeat=timing_repeat, number=timing_number))\n",
    "    * 1000\n",
    "    / timing_number\n",
    ")\n",
    "unoptimized = {\n",
    "    \"mean\": np.mean(unoptimized),\n",
    "    \"median\": np.median(unoptimized),\n",
    "    \"std\": np.std(unoptimized),\n",
    "}\n",
    "\n",
    "print(unoptimized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 后处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class='tiger cat' with probability=0.476104\n",
      "class='tabby, tabby cat' with probability=0.466828\n",
      "class='Egyptian cat' with probability=0.046270\n",
      "class='plastic bag' with probability=0.002098\n",
      "class='carton' with probability=0.000687\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "from gluoncv.data.imagenet.classification import ImageNet1kAttr\n",
    "\n",
    "# 获取 ImageNet 标签列表\n",
    "imagenet_1k_attr = ImageNet1kAttr()\n",
    "labels = imagenet_1k_attr.classes_long\n",
    "# 获取输出张量\n",
    "scores = softmax(tvm_output)\n",
    "scores = np.squeeze(scores)\n",
    "ranks = np.argsort(scores)[::-1]\n",
    "for rank in ranks[0:5]:\n",
    "    print(f\"class='{labels[rank]}' with probability={scores[rank]:f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型调优\n",
    "\n",
    "TVM 中的调优是指对模型进行优化以在给定目标上更快地运行的过程。这与训练或微调不同，因为它不影响模型的准确性，而只影响运行时的性能。作为调优过程的一部分，TVM 将尝试运行许多不同的算子实现变体，以观察哪些算子表现最佳。这些运行的结果被储存在调优记录文件中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tvm import auto_scheduler\n",
    "from tvm.autotvm.tuner import XGBTuner\n",
    "from tvm import autotvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为运行器设置一些基本参数。运行器采用一组特定参数生成的编译代码，并测量其性能。`number` 指定将测试的不同配置的数量，而 `repeat` 指定将对每个配置进行多少次测量。`min_repeat_ms` 是一个值，指定需要多长时间运行配置测试。如果重复次数低于这个时间，它将被增加。这个选项对于在 GPU 上进行精确的调优是必要的，而对于 CPU 的调优则不需要。把这个值设置为 `0` 可以禁用它。`timeout` 为每个测试的配置运行训练代码的时间设置了上限。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 10\n",
    "repeat = 1\n",
    "min_repeat_ms = 0  # since we're tuning on a CPU, can be set to 0\n",
    "timeout = 10  # in seconds\n",
    "\n",
    "# create a TVM runner\n",
    "runner = autotvm.LocalRunner(\n",
    "    number=number,\n",
    "    repeat=repeat,\n",
    "    timeout=timeout,\n",
    "    min_repeat_ms=min_repeat_ms,\n",
    "    enable_cpu_cache_flush=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 XGBoost 算法来指导搜索。对于生产作业来说，你会想把试验的数量设置得比这里使用的 `10` 的值大。对于 CPU，推荐 `1500`，对于 GPU，推荐 `3000-4000`。所需的试验次数可能取决于特定的模型和处理器，因此值得花一些时间来评估各种数值的性能，以找到调整时间和模型优化之间的最佳平衡。`early_stopping` 参数是在应用提前停止搜索的条件之前，要运行的最小轨数。`measure` 选项表示将在哪里建立试验代码，以及将在哪里运行。在这种情况下，使用刚刚创建的 `LocalRunner` 和 `LocalBuilder`。`tuning_records` 选项指定了文件来写入调整数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_option = {\n",
    "    \"tuner\": \"xgb\",\n",
    "    \"trials\": 1500,\n",
    "    \"early_stopping\": 100,\n",
    "    \"measure_option\": autotvm.measure_option(\n",
    "        builder=autotvm.LocalBuilder(build_func=\"default\"), runner=runner\n",
    "    ),\n",
    "    \"tuning_records\": \"resnet-50-autotuning.json\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运行调优："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Task  1/25]  Current/Best:  120.51/ 307.69 GFLOPS | Progress: (144/1500) | 59.15 s Done.\n",
      "[Task  2/25]  Current/Best:   92.82/ 251.66 GFLOPS | Progress: (288/1500) | 88.11 s Done.\n",
      "[Task  3/25]  Current/Best:   70.36/ 392.87 GFLOPS | Progress: (288/1500) | 94.46 s Done.\n",
      "[Task  4/25]  Current/Best:  128.78/ 355.21 GFLOPS | Progress: (336/1500) | 123.97 s Done.\n",
      "[Task  5/25]  Current/Best:  211.86/ 330.45 GFLOPS | Progress: (240/1500) | 82.58 s Done.\n",
      "[Task  6/25]  Current/Best:  109.52/ 314.38 GFLOPS | Progress: (288/1500) | 104.54 s Done.\n",
      "[Task  7/25]  Current/Best:  206.38/ 316.17 GFLOPS | Progress: (240/1500) | 80.51 s Done.\n",
      "[Task  8/25]  Current/Best:  187.30/ 281.83 GFLOPS | Progress: (336/1500) | 137.05 s Done.\n",
      "[Task 10/25]  Current/Best:  105.97/ 280.33 GFLOPS | Progress: (48/1500) | 13.52 s s Done.\n",
      "[Task 10/25]  Current/Best:  123.63/ 421.92 GFLOPS | Progress: (240/1500) | 76.72 s Done.\n",
      "[Task 11/25]  Current/Best:  127.37/ 289.90 GFLOPS | Progress: (144/1500) | 53.38 s Done.\n",
      "[Task 12/25]  Current/Best:  151.26/ 366.24 GFLOPS | Progress: (240/1500) | 87.67 s Done.\n",
      "[Task 13/25]  Current/Best:  122.90/ 267.76 GFLOPS | Progress: (240/1500) | 87.20 s Done.\n",
      "[Task 14/25]  Current/Best:  176.50/ 287.42 GFLOPS | Progress: (240/1500) | 96.73 s Done.\n",
      "[Task 16/25]  Current/Best:  188.01/ 347.64 GFLOPS | Progress: (240/1500) | 75.60 ss Done.\n",
      "[Task 17/25]  Current/Best:   82.98/ 308.11 GFLOPS | Progress: (288/1500) | 96.49 s Done.\n",
      "[Task 18/25]  Current/Best:  166.62/ 326.18 GFLOPS | Progress: (336/1500) | 120.89 s Done.\n",
      "[Task 19/25]  Current/Best:   71.27/ 200.95 GFLOPS | Progress: (288/1500) | 131.17 s Done.\n",
      "[Task 21/25]  Current/Best:   48.98/ 238.22 GFLOPS | Progress: (48/1500) | 22.34 s s Done.\n",
      "[Task 22/25]  Current/Best:  110.02/ 247.39 GFLOPS | Progress: (192/1500) | 70.46 ss Done.\n",
      "[Task 23/25]  Current/Best:  150.97/ 215.42 GFLOPS | Progress: (144/1500) | 69.49 s Done.\n",
      "[Task 25/25]  Current/Best:    4.18/  23.26 GFLOPS | Progress: (48/1500) | 25.32 ss Done.\n",
      "[Task 25/25]  Current/Best:    5.14/  28.02 GFLOPS | Progress: (240/1500) | 112.76 s Done.\n"
     ]
    }
   ],
   "source": [
    "# begin by extracting the tasks from the onnx model\n",
    "tasks = autotvm.task.extract_from_program(mod[\"main\"], target=target, params=params)\n",
    "\n",
    "# Tune the extracted tasks sequentially.\n",
    "for i, task in enumerate(tasks):\n",
    "    prefix = \"[Task %2d/%2d] \" % (i + 1, len(tasks))\n",
    "    tuner_obj = XGBTuner(task, loss_type=\"rank\")\n",
    "    tuner_obj.tune(\n",
    "        n_trial=min(tuning_option[\"trials\"], len(task.config_space)),\n",
    "        early_stopping=tuning_option[\"early_stopping\"],\n",
    "        measure_option=tuning_option[\"measure_option\"],\n",
    "        callbacks=[\n",
    "            autotvm.callback.progress_bar(tuning_option[\"trials\"], prefix=prefix),\n",
    "            autotvm.callback.log_to_file(tuning_option[\"tuning_records\"]),\n",
    "        ],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 用调优数据编译优化后的模型\n",
    "\n",
    "上述调优过程的输出存储在 `resnet-50-autotuning.json` 的调优记录。编译器将使用这些结果，在你指定的目标上为模型生成高性能代码。\n",
    "\n",
    "现在，模型的调优数据已经收集完毕，可以使用优化的算子重新编译模型，以加快计算速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Done.\n",
      " Done.\n"
     ]
    }
   ],
   "source": [
    "with autotvm.apply_history_best(tuning_option[\"tuning_records\"]):\n",
    "    with tvm.transform.PassContext(opt_level=3, config={}):\n",
    "        lib = relay.build(mod, target=target, params=params)\n",
    "\n",
    "dev = tvm.device(str(target), 0)\n",
    "module = graph_executor.GraphModule(lib[\"default\"](dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "验证优化后的模型是否运行并产生相同的结果："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class='tiger cat' with probability=0.476103\n",
      "class='tabby, tabby cat' with probability=0.466829\n",
      "class='Egyptian cat' with probability=0.046270\n",
      "class='plastic bag' with probability=0.002098\n",
      "class='carton' with probability=0.000687\n"
     ]
    }
   ],
   "source": [
    "dtype = \"float32\"\n",
    "module.set_input(input_name, img_data)\n",
    "module.run()\n",
    "output_shape = (1, 1000)\n",
    "tvm_output = module.get_output(0, tvm.nd.empty(output_shape)).numpy()\n",
    "\n",
    "scores = softmax(tvm_output)\n",
    "scores = np.squeeze(scores)\n",
    "ranks = np.argsort(scores)[::-1]\n",
    "for rank in ranks[0:5]:\n",
    "    print(\"class='%s' with probability=%f\" % (labels[rank], scores[rank]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 比较已调谐和未调谐的模型\n",
    "\n",
    "收集一些与这个优化模型相关的基本性能数据，将其与未优化的模型进行比较。根据你的底层硬件、迭代次数和其他因素，你应该看到优化后的模型与未优化的模型相比有性能的提高。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimized: {'mean': 45.72459139046259, 'median': 42.24954635137692, 'std': 6.151925270695667}\n",
      "unoptimized: {'mean': 73.69392811204307, 'median': 77.21288839820772, 'std': 11.900445828441978}\n"
     ]
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "timing_number = 10\n",
    "timing_repeat = 10\n",
    "optimized = (\n",
    "    np.array(timeit.Timer(lambda: module.run()).repeat(repeat=timing_repeat, number=timing_number))\n",
    "    * 1000\n",
    "    / timing_number\n",
    ")\n",
    "optimized = {\"mean\": np.mean(optimized), \"median\": np.median(optimized), \"std\": np.std(optimized)}\n",
    "\n",
    "\n",
    "print(\"optimized: %s\" % (optimized))\n",
    "print(\"unoptimized: %s\" % (unoptimized))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('py38': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28558e8daad512806f5c536a1a04c119185f99f65b79002708a12162d02a79c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
